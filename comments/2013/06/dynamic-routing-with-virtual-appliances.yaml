comments:
- date: 10 June 2013 09:48
  html: Looks a lot like what Microsoft will propably use in their BGP only DC when
    their own NVGRE GW /w built-in BGP on the outside comes out later this year.<br
    /><br />http://www.nanog.org/meetings/nanog55/presentations/Monday/Lapukhov.pdf<br
    /><br />http://channel9.msdn.com/Events/TechEd/NorthAmerica/2013/MDC-B351
  id: '8937435849007505646'
  image: https://resources.blogblog.com/img/blank.gif
  name: Stefan de Kooter
  profile: http://twitter.com/sdktr
  pub: '2013-06-10T09:48:34.436+02:00'
  ref: '8265110730467011952'
  type: comment
- comments:
  - date: 10 June 2013 16:03
    html: Large networks prefer BGP over IGP because it&#39;s easier to control/filter.
    id: '3733190610998358546'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2013-06-10T16:03:25.347+02:00'
    ref: '3981023155593021904'
    type: comment
  - date: 10 June 2013 18:38
    html: Thanks! You&#39;re awesome.
    id: '6438366846278757966'
    image: https://resources.blogblog.com/img/blank.gif
    name: Anonymous
    profile: null
    pub: '2013-06-10T18:38:24.270+02:00'
    ref: '3981023155593021904'
    type: comment
  date: 10 June 2013 15:03
  html: Maybe I&#39;m dense, but are you saying that it should use BGP because the
    datacenters that the virtual network might roam through might be in different
    AS&#39;s? Is there any reason that a service provider couldn&#39;t use an IGP
    if the DC&#39;s were in the same AS?
  id: '3981023155593021904'
  image: https://resources.blogblog.com/img/blank.gif
  name: Anonymous
  profile: null
  pub: '2013-06-10T15:03:50.066+02:00'
  ref: '8265110730467011952'
  type: comment
- date: 10 June 2013 15:53
  html: i think you can use OSPF and stub zones for this kind of setup - <br />it&#39;s
    less work todo and we can eliminate  extra router and run <br />ospf right on
    the virtual firewall - not all vendors support bgp.<br />Unless extensive route
    filetring required (like corporate datacenter)<br />this should work.<br /><br
    />Going to extreme (or simple) even RIPv2 with tweaked timers and distribution<br
    />lists will work fine - this virtual silo needs default route to the core<br
    />and core needs only route from the virtual firewall about the network<br />behind
    it. So block all RIPv2 updates on the core with distribution lists, allocate <br
    />/24 for the firewalled silo and core will receive 1 /24 block per silo. That&#39;s
    it.<br />All vendors support RIP, no much CPU power needed in this case.<br />
  id: '1888894265516116592'
  image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
  name: Dmitriy Fedorov
  profile: https://www.blogger.com/profile/00215952350534860438
  pub: '2013-06-10T15:53:03.278+02:00'
  ref: '8265110730467011952'
  type: comment
- date: 10 June 2013 15:54
  html: forgot to say, you can redistribute all this into BGP or whatever if needed
    to propagate to the WAN...
  id: '6293674242121651380'
  image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
  name: Dmitriy Fedorov
  profile: https://www.blogger.com/profile/00215952350534860438
  pub: '2013-06-10T15:54:56.873+02:00'
  ref: '8265110730467011952'
  type: comment
- comments:
  - date: 12 June 2013 15:23
    html: This is not exactly what NVO3 is talking about - this is user-mode BGP run
      between VM at the edge of the app stack (on the border of physical/VLAN and
      virtual/overlay worlds) and the physical network.<br /><br />The other BGP proposed
      in NVO3 is hypervisor-mode MP-BGP transporting VPNv4 and EVPN prefixes. I thought
      MPLS in the hypervisors (or something equivalent) was a good idea a long time
      ago, got persuaded in less than 5 minutes that it&#39;s not by people who actually
      run large-scale cloud data centers, and haven&#39;t changed my mind since.
    id: '6449786074072260551'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2013-06-12T15:23:30.124+02:00'
    ref: '3562759421717701731'
    type: comment
  - date: 12 June 2013 23:23
    html: OK -- I thought that&#39;s what you meant until I saw the part with vrouter
      peering with ToR.  At that point I was thinking PaaS DC vs IaaS DC.  I probably
      shouldn&#39;t have rushed my reading.<br /><br />I agree that using MPLS for
      the transport tunnel is not ideal for the DC.  Implementations of EVPN and VPNv4
      in the works for the DC will let the NVE advertise the set of encapsulations
      that it supports.  This allows gradual migration from one encap to another as
      encaps themselves might evolve.  This also makes it much more possible for seamless
      network virtualization across different NVO3 domains so long as both ends support
      the address family and have a supported encap in common.<br /><br />I&#39;m
      a proponent of MPLS over GRE where an NVE advertises via MP-BGP locally significant
      MPLS labels per context or even per NLRI.  These labels can be used to identify
      local tenant context or apply whatever special action the egress NVE wishes
      to apply against an advertised label.   With locally significant labels the
      context ID is not condemned forever to the one role of creating a flat virtual
      network.  Locally significant context ID also enables very flexible topologies,
      and even takes the number of virtual networks from 24M to something that is
      a function of the size of BGP route targets and the number of NVE.  If route
      target size increases, so does the number of virtual networks, without any change
      to the data plane.  You could choose to fix use globally significant labels
      or even split the label space into local and globally significant.<br /><br
      />What did the folk at the large-scale cloud DC tell you that convinced you?  I&#39;d
      like to believe as well, but haven&#39;t seen anything that works for everyone
      versus just for monolithic large cloud DC.<br /><br />On a different note, if
      BGP is not ideal for service location and mobility in the service provider infrastructure,
      why would we want customers to use it for that purpose in tenant space?
    id: '6362158213820263755'
    image: https://lh6.googleusercontent.com/-q1TWPY_Z2vM/AAAAAAAAAAI/AAAAAAAAD80/2ypzZxc5Qbc/s32-c/photo.jpg
    name: Aldrin Isaac
    profile: https://www.blogger.com/profile/15493370358037866116
    pub: '2013-06-12T23:23:01.467+02:00'
    ref: '3562759421717701731'
    type: comment
  date: 12 June 2013 04:56
  html: 'I wouldn&#39;t have expected Brad to suggest such an approach -- a pleasant
    surprise.  But now that you have BGP into the hypervisor, why stop at basic IP
    connectivity using BGP when you can get network virtualization as well with IP-VPN
    and E-VPN address families?<br /><br />The idea of running BGP to a vrouter/vswitch
    on the hypervisor has been what many in the decentralized control-plane camp have
    been pushing for quite some time and some vendors are actively building in one
    form or other.  Proposals to BGP peer with the ToR dynamically on DHCP offer and
    other ways have been floated in NVO3 mailing list from early on. '
  id: '3562759421717701731'
  image: https://lh6.googleusercontent.com/-q1TWPY_Z2vM/AAAAAAAAAAI/AAAAAAAAD80/2ypzZxc5Qbc/s32-c/photo.jpg
  name: Aldrin Isaac
  profile: https://www.blogger.com/profile/15493370358037866116
  pub: '2013-06-12T04:56:38.816+02:00'
  ref: '8265110730467011952'
  type: comment
- comments:
  - date: 12 June 2013 15:24
    html: No, we don&#39;t do OC12 any more. It&#39;s 10GE or 40GE ;)
    id: '9051674839814598592'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2013-06-12T15:24:25.829+02:00'
    ref: '4255591357516646175'
    type: comment
  - date: 12 June 2013 20:13
    html: To be clear we are on the same page, I was alluding to terminating WAN connectivity
      in the virtual hypervisor space. <br /><br />If you have 10G/40GE WAN links,
      I am jealous...
    id: '6123272669614410128'
    image: https://resources.blogblog.com/img/blank.gif
    name: Anonymous
    profile: null
    pub: '2013-06-12T20:13:40.535+02:00'
    ref: '4255591357516646175'
    type: comment
  - date: 13 June 2013 07:58
    html: We usually have Ethernet handoff to ISPs these days (at least where I live).
      Interface is usually FE/GE (or sometimes 10GE) with actual delivered speed based
      on how much you&#39;re willing to pay.
    id: '7477570025367983718'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2013-06-13T07:58:37.092+02:00'
    ref: '4255591357516646175'
    type: comment
  date: 12 June 2013 14:46
  html: So, I just need an OC12 line card for my virtual server farm...
  id: '4255591357516646175'
  image: https://resources.blogblog.com/img/blank.gif
  name: Anonymous
  profile: null
  pub: '2013-06-12T14:46:59.650+02:00'
  ref: '8265110730467011952'
  type: comment
- comments:
  - date: 13 June 2013 08:03
    html: If your application advertises just a single /32, then you can move the
      whole stack across data centers without changing the outside IP address of the
      application, but you can&#39;t advertise the new location of that IP address
      to the Internet at large (only within your WAN network).<br /><br />If the application
      has a whole IPv4 /24 (or IPv6 /48) assigned to it, then you can advertise its
      new location to the Internet at large.<br /><br />Finally, you can always use
      LISP and deploy xTR on the virtual appliance ;)
    id: '1863359086895403570'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2013-06-13T08:03:26.103+02:00'
    ref: '3016280418879830065'
    type: comment
  date: 12 June 2013 19:24
  html: 'Ivan<br /><br />This sounds very interesting, but could you expand on the
    bigger picture?  I don&#39;t follow the comment about a /32.  Was the intent to
    adv the virtual subnet (subnet behind fw) out to the ISP?  How would this work
    with a /32? '
  id: '3016280418879830065'
  image: https://resources.blogblog.com/img/blank.gif
  name: Anonymous
  profile: null
  pub: '2013-06-12T19:24:12.641+02:00'
  ref: '8265110730467011952'
  type: comment
- comments:
  - date: 13 June 2013 08:06
    html: iLand seems to be a &quot;VMware provider&quot; (public cloud running on
      VMware) using SRM for disaster recovery. You can use them instead of deploying
      a second data center. Nothing new there (although I sure wish I&#39;d have something
      similar close to some of my customers).
    id: '2133993658360777344'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2013-06-13T08:06:06.555+02:00'
    ref: '2254175017482569968'
    type: comment
  date: 12 June 2013 19:26
  html: Ivan<br /><br />Could you take a look at what iLand is doing for disaster
    recovery? They work closely VMware and it seemed very promising to us.  I would
    be interested in knowing where some of your models differ form theirs. Perhaps
    you could cover this is in your upcoming webinar. thank you
  id: '2254175017482569968'
  image: https://resources.blogblog.com/img/blank.gif
  name: Anonymous
  profile: null
  pub: '2013-06-12T19:26:29.055+02:00'
  ref: '8265110730467011952'
  type: comment
- comments:
  - date: 13 July 2013 08:49
    html: 'I believe vPE is an overkill, but of course the &quot;MPLS is the answer,
      what was the question?&quot; crowd won&#39;t listen.<br /><br />We need to make
      the networks SIMPLER, not more complex. That also means dropping some borderline
      use cases and focusing on 95% of the problems.<br /><br />There are plenty of
      virtual appliances you can use today. Keep in mind the use case: separating
      an app stack from the outside world, which implies FW or LB functionality, so
      don&#39;t look at traditional router vendors.'
    id: '7269162218079744613'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2013-07-13T08:49:59.050+02:00'
    ref: '2402757133943441336'
    type: comment
  date: 12 July 2013 20:16
  html: I believe what Ivan is describing is also very well explained in this draft
    ( http://tools.ietf.org/html/draft-fang-l3vpn-virtual-pe-02 ).  Such design associated
    with Segment Routing (http://tools.ietf.org/html/draft-previdi-filsfils-isis-segment-routing-02)
    to simplify the core would be a very nice solution. <br /><br />But what are the
    existing virtual PE? The cisco CSR1000, quagga, vayatta....Junos olive?<br />
  id: '2402757133943441336'
  image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
  name: Asterix49
  profile: https://www.blogger.com/profile/13057510108070271921
  pub: '2013-07-12T20:16:06.107+02:00'
  ref: '8265110730467011952'
  type: comment
- comments:
  - date: 11 March 2014 19:52
    html: You have to advertise an &quot;internal&quot; prefix (think loopback interface
      on a router) or the mobility won&#39;t work ... and you need external VLAN to
      link the virtual world with the physical (where you might find most of the clients).
    id: '3866441102844660138'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2014-03-11T19:52:04.818+01:00'
    ref: '7702020674287154107'
    type: comment
  date: 11 March 2014 19:01
  html: Hi Ivan,<br /><br />I don&#39;t seem to get the nugget here. If i understand
    right, client facing IP address could either be /32 or dhcp generated on that
    DC. This address is advertized to the external world thro&#39; a virtual router
    running BGP. This ip address is unique to an application stack, so there is one-one
    mapping between application stack and this ip-address. By having such a model,
    it is easy to move the application stack from One DC to another DC ?. If /32 is
    used, it is just a BGP update. If DHCP is used, it is going to be DNS update ?.
    Is this a fair summarization of this post ?. <br /><br />BTW, why do i need an
    external VLAN as depicted in the picture but not explained in the post ?. Is it
    for overlay address space to be masked from underlay network (BGP session between
    Virtual router and BGP router ?)<br /><br />-Bhargav<br />
  id: '7702020674287154107'
  image: https://resources.blogblog.com/img/blank.gif
  name: Bhargav
  profile: null
  pub: '2014-03-11T19:01:01.315+01:00'
  ref: '8265110730467011952'
  type: comment
count: 21
id: '8265110730467011952'
type: post
url: 2013/06/dynamic-routing-with-virtual-appliances.html
