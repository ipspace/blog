<div class="comments post" id="comments">
  <h4>16 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="423165518476593273">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/18136855206137771382" rel="nofollow">Vince</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c423165518476593273" href="#423165518476593273">05 September 2013 16:20</a>
              </span>
            </div>
            <div class="comment-content">AMEN!<br /></div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="3049094941770409691">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3049094941770409691" href="#3049094941770409691">08 November 2013 21:43</a>
              </span>
            </div>
            <div class="comment-content">Not to mention the ever accumulating operational and security deficiencies of LISP (e.g., see http://tools.ietf.org/html/draft-saucez-lisp-impact-02 and http://tools.ietf.org/html/draft-ietf-lisp-threats-08).</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2439172564462727022">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/04982620456797894645" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2439172564462727022" href="#2439172564462727022">05 September 2013 19:58</a>
              </span>
            </div>
            <div class="comment-content">Agree completely... I thought their comments in the podcast about how &#39;DNS was fast enough now&#39; for LISP was pretty telling too.  Application resiliency and performance is the goal here.  Why not go with what&#39;s already working in that space.<br /><br />Pay more than $.02 to run your DNS. Protect your DNS from DDoS. Control your own dynamic DNS with a GSLB product that gives granular control and allows you to group FQDNs together to encompass all the required services which make up an application. Include solid IP intelligence (like GeoIP) and reputation based scoring of LDNS or client resolvers. Now we have some BC knobs.   <br /><br />Advanced GSLB is a time proven mechanism for Internet commerce. Turns out it works on the Intranet too. And..look ma.. no new switches needed. </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7370560468853407673">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/08914689992468372696" rel="nofollow">Simon Hamilton-Wilkes</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7370560468853407673" href="#7370560468853407673">06 September 2013 00:30</a>
              </span>
            </div>
            <div class="comment-content">Your final paragraph hits the nail on the head though - everyone wants the latest toys and too few CxO level folks are technical enough to call them out.  There are too many specialists and too few architects these days, where by my definition those would be the people with a sufficiently high altitude view to dismiss all the vendor marketing.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1050929321482935486">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.riw.us" rel="nofollow">Russ White</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1050929321482935486" href="#1050929321482935486">06 September 2013 03:02</a>
              </span>
            </div>
            <div class="comment-content">One of the problems we have in the networking industry is just layering protocol on protocol, technology on technology, to solve a problem. It&#39;s like realizing your brakes are too hard to push, so you add a contraption that sits over the brake pedal to make it easier. Then you realize this device interferes with steering, so you add a steering extension to move the control to the other seat. Then you realize you can&#39;t roll the driver&#39;s side window down, so you add a long stick that allows you to manipulate the little switch.<br /><br />Each contraption you add, your friends ooh and ah over the beauty and complexity of the new idea. And all the while, your car is actually becoming undrivable. So you add a car management system... <br /><br />Okay, so I probably shouldn&#39;t be saying these things after just recording a show on LISP, but... There it is. I&#39;ve said it! <br /><br />(An no, I&#39;m not fond of LISP)</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1891105015412484100">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.amilabs.com" rel="nofollow">jsicuran</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1891105015412484100" href="#1891105015412484100">06 September 2013 18:04</a>
              </span>
            </div>
            <div class="comment-content">Here here! Good post. Too many overlays/abstractions and tagging/tunneling.. <br /><br /></div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="248713628042214545">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/14364645178881348283" rel="nofollow">Andrew Yourtchenko</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c248713628042214545" href="#248713628042214545">12 September 2013 15:39</a>
              </span>
            </div>
            <div class="comment-content">If you engineer your application in such a way that you have multiple machines in multiple data centers... you do not need migrating anything anywhere anymore. You shut down one and bring up another. DNS may or may not be a solution. It depends on the app. <br /><br />The tricky part is of course that designing with the distributed architecture in mind from the start is way harder than taking a single-box architecture, and bolting on the migration later on.<br /><br />It&#39;s a question if different trade-offs at different times.<br /><br />When/if the frameworks emerge that allow easy development of the distributed applications, and the programmers grow that will grok that (this is not too far away - 256-core CPUs pose very similar problems!), this problem will be solved in a cleaner way. Till then we need a few hacks.<br /><br />--a<br /><br />ps. Completely agree with Russ about layering. </div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="7521400960283703138">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7521400960283703138" href="#7521400960283703138">12 September 2013 15:49</a>
              </span>
            </div>
            <div class="comment-content">Completely agree. Unfortunately we were more than happy (and oh-so proud of ourselves) to provide too many hack for too long instead of forcing the programmers (and framework developers) to learn what needs to be done.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3967036314788881323">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/14364645178881348283" rel="nofollow">Andrew Yourtchenko</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3967036314788881323" href="#3967036314788881323">12 September 2013 17:42</a>
              </span>
            </div>
            <div class="comment-content">[repasting with hopefully correct parent comment :-)] <br /><br />It&#39;s all a collection of tradeoffs. Much like time/space in programming, you have control/cost and many other axis. This is the &quot;engineering&quot; portion of our job - and I do not think that there is a single silver bullet. <br /><br />Today is the &quot;interesting times&quot; between the generations of different paradigms, where we&#39;d like to already be in the new world - but the stuff that pays the bills today is all this cruft covered with warts, which creates a market for maintaining the relative health of the warts, which results in interesting interactions between the &quot;new&quot; and &quot;old&quot;.<br /><br />And the speed with which the &quot;new&quot; becomes &quot;old&quot; keeps increasing. <br /><br />Think puppet is cool ? Wrong. Docker is the new black, apparently. And, interestingly, these &quot;newest&quot; concepts do add the &quot;distributed&quot; nature again. (cf: coreos.com). Welcome back to peer to peer world :-)</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="565739594233833169">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/06090398639164774159" rel="nofollow">Dmitriy</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c565739594233833169" href="#565739594233833169">18 September 2013 22:06</a>
              </span>
            </div>
            <div class="comment-content">Ivan, there&#39;s one point you could be missing.<br /><br />Applications could be extremely expensive and extremely crappy at the same time. There&#39;s not always an option to make them better, you just have to live with them, purchase expensive high-end servers instead of loads of cheap machines like Google does etc. These are mission critical applications. You can choose others from the competitors, but they would be the same crap from the admin&#39;s perspective. <br /><br />And so, one day you may realize that implementing OTV with a stretched inter-DC HA cluster at application level could be an option that could once save your business itself. Yes, I know you hate this, but if a meteorite hits one of the DCs and all data inside it is gone forever (that&#39;s probably unlikely, but it has the potential to be fatal for the company), the other DC would continue working almost as if nothing happened. And there could be no other options to replicate data sort-of realtime except for low-level SAN replication which is expensive, kludgy and also dangerous. Consistency is not guaranteed with such techniques.<br /><br />Issues with the stretched clustering itself (split brain caused by loss of the inter-DC link and so on) could be painful, but not fatal. They happen rarely. They could be tolerated - considering them as side effects of the ability to survive the destruction of any DC without having to roll back to nightly backups (which could also be fatal - imagine financial companies).</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="7552888157357424296">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7552888157357424296" href="#7552888157357424296">19 September 2013 14:48</a>
              </span>
            </div>
            <div class="comment-content">Hi Dmitriy,<br /><br />If I understand it correctly, you&#39;re saying there&#39;s an application out there that<br /><br />A) Uses some **** that cannot be routed with today&#39;s gear (example: unicorns over LAT)<br />B) Uses application-level data replication which is better than storage replication.<br /><br />I&#39;m positive you can find something like that out there in the wild; if you can, do share what this monstrosity is.<br /><br />However, in most cases it all comes down to building your network based on information gleaned from vendors&#39; whitepapers (because paying for a proper design and architecture obviously doesn&#39;t make sense). No wonder you get the network you deserve ;))<br /><br />Finally, I haven&#39;t heard of a data center being hit by a meteorite, but I do know of several organizations that experienced total meltdown of multiple data centers due to a bridging loop. Now they know better ...<br /><br />Kind regards,<br />Ivan</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7207735151105607813">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/06090398639164774159" rel="nofollow">Dmitriy</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7207735151105607813" href="#7207735151105607813">19 September 2013 16:43</a>
              </span>
            </div>
            <div class="comment-content">Hi Ivan,<br /><br />&quot;B&quot; is closer to reality. These days almost everything is IP, and even broadcasts are used just for ARPs, so no rainbows and unicorns.<br /><br />Those are mostly monstrous financial applications that already cost millions to support. They usually do support clustering, but it could be impossible to hold multiple clusters sharing some common resources, with failover.<br /><br />And storage replication is as low-level as it gets. You always say that problems shouldn&#39;t be moved a couple of layers down the stack. If you&#39;re unlucky, you could get corrupt file systems when doing storage replication at the event of an outage, because it works on block level, it doesn&#39;t even know file systems exist. But link loss during application level replication usually causes loss of only a negligible amount of data. It doesn&#39;t cause corruption.<br /><br />And as I already said, a bridging loop between DCs is painful (although less likely with modern kludges like OTV if implemented properly), it costs money, but if it happens rarely enough, it doesn&#39;t pose a threat to the business itself. A meteorite (fire and malfunctioning extinguishers, loaded truck crashing into the datacenter building, thermonuclear explosion, zombie ourbreak or anything else) does.<br /><br />The tradeoff is &quot;more small incidents&quot; vs &quot;less small incidents, but risk of going out of business after unlikely, but still plausible disasters&quot;.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3026882343296192919">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3026882343296192919" href="#3026882343296192919">19 September 2013 18:15</a>
              </span>
            </div>
            <div class="comment-content">... and you&#39;re saying that these applications cannot work across L3 subnets?</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4914859755405652808">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/06090398639164774159" rel="nofollow">Dmitriy</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4914859755405652808" href="#4914859755405652808">20 September 2013 11:49</a>
              </span>
            </div>
            <div class="comment-content">Imagine VRRP or something analogous. L2 multicast session replication (some fancy tech for those dinosaurs). SLB using ACE/F5/whatever wouldn&#39;t allow that session replication between nodes. And even if the nodes can communicate via routed L3: you still have a single cluster with nodes in different DCs, with the usual potential caveats like split brain. It just wouldn&#39;t force you to have all the nodes L2 adjacent (but you have to purchase an SLB device).<br /><br />You have to face it: a cluster with nodes spread across DCs, even with L2 DCI, may sometimes be the neatest and safest architecture if you&#39;re considering business survival. And yes, you should probably try to avoid such applications. Life is simpler without them. Most businesses don&#39;t use them, which allows them to avoid complexity and run routing everywhere.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="8634917364869828535">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8634917364869828535" href="#8634917364869828535">20 September 2013 15:12</a>
              </span>
            </div>
            <div class="comment-content">Now I guess we&#39;re close to being in agreement ;) <br /><br />BTW, there are other hacks out there that can create floating IP address for clustering needs without L2 interconnect.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2081436763077025932">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/06090398639164774159" rel="nofollow">Dmitriy</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2081436763077025932" href="#2081436763077025932">20 September 2013 16:52</a>
              </span>
            </div>
            <div class="comment-content">Which brings us to the initial point: those are the kludges you have to pay for. Sure you can even do proxy arp to simulate L2 connections (you lose some features such as L2 multicast, you can&#39;t forward packets with TTL 1). It&#39;s probably safer than interconnecting DCs with VPLS, but it&#39;s still an extremely dirty hack. Personally I would always prefer any encapsulation mechanisms carrying L2 traffic to proxy arp.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
