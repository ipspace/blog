comments:
- comments:
  - date: 08 November 2013 21:43
    html: Not to mention the ever accumulating operational and security deficiencies
      of LISP (e.g., see http://tools.ietf.org/html/draft-saucez-lisp-impact-02 and
      http://tools.ietf.org/html/draft-ietf-lisp-threats-08).
    id: '3049094941770409691'
    image: https://resources.blogblog.com/img/blank.gif
    name: Anonymous
    profile: null
    pub: '2013-11-08T21:43:54.908+01:00'
    ref: '423165518476593273'
    type: comment
  date: 05 September 2013 16:20
  html: AMEN!<br />
  id: '423165518476593273'
  image: https://1.bp.blogspot.com/-o5pimHPV2zQ/VRm7GMzxHoI/AAAAAAAABrU/xgdHDsgUk1Q/s32/VinsWorld%2BAvatar%2B64x64.GIF
  name: Vince
  profile: https://www.blogger.com/profile/18136855206137771382
  pub: '2013-09-05T16:20:32.045+02:00'
  ref: '3718489426056265435'
  type: comment
- date: 05 September 2013 19:58
  html: 'Agree completely... I thought their comments in the podcast about how &#39;DNS
    was fast enough now&#39; for LISP was pretty telling too.  Application resiliency
    and performance is the goal here.  Why not go with what&#39;s already working
    in that space.<br /><br />Pay more than $.02 to run your DNS. Protect your DNS
    from DDoS. Control your own dynamic DNS with a GSLB product that gives granular
    control and allows you to group FQDNs together to encompass all the required services
    which make up an application. Include solid IP intelligence (like GeoIP) and reputation
    based scoring of LDNS or client resolvers. Now we have some BC knobs.   <br /><br
    />Advanced GSLB is a time proven mechanism for Internet commerce. Turns out it
    works on the Intranet too. And..look ma.. no new switches needed. '
  id: '2439172564462727022'
  image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
  name: Unknown
  profile: https://www.blogger.com/profile/04982620456797894645
  pub: '2013-09-05T19:58:05.111+02:00'
  ref: '3718489426056265435'
  type: comment
- date: 06 September 2013 00:30
  html: Your final paragraph hits the nail on the head though - everyone wants the
    latest toys and too few CxO level folks are technical enough to call them out.  There
    are too many specialists and too few architects these days, where by my definition
    those would be the people with a sufficiently high altitude view to dismiss all
    the vendor marketing.
  id: '7370560468853407673'
  image: //images-blogger-opensocial.googleusercontent.com/gadgets/proxy?url=http://2.bp.blogspot.com/-ZU9eH2Y8aXg/VIF-fOAS8qI/AAAAAAAABCw/ZECKfweqOws/s113/*&container=blogger&gadget=a&rewriteMime=image/*
  name: Simon Hamilton-Wilkes
  profile: https://www.blogger.com/profile/08914689992468372696
  pub: '2013-09-06T00:30:15.319+02:00'
  ref: '3718489426056265435'
  type: comment
- date: 06 September 2013 03:02
  html: One of the problems we have in the networking industry is just layering protocol
    on protocol, technology on technology, to solve a problem. It&#39;s like realizing
    your brakes are too hard to push, so you add a contraption that sits over the
    brake pedal to make it easier. Then you realize this device interferes with steering,
    so you add a steering extension to move the control to the other seat. Then you
    realize you can&#39;t roll the driver&#39;s side window down, so you add a long
    stick that allows you to manipulate the little switch.<br /><br />Each contraption
    you add, your friends ooh and ah over the beauty and complexity of the new idea.
    And all the while, your car is actually becoming undrivable. So you add a car
    management system... <br /><br />Okay, so I probably shouldn&#39;t be saying these
    things after just recording a show on LISP, but... There it is. I&#39;ve said
    it! <br /><br />(An no, I&#39;m not fond of LISP)
  id: '1050929321482935486'
  image: https://resources.blogblog.com/img/blank.gif
  name: Russ White
  profile: http://www.riw.us
  pub: '2013-09-06T03:02:15.060+02:00'
  ref: '3718489426056265435'
  type: comment
- date: 06 September 2013 18:04
  html: Here here! Good post. Too many overlays/abstractions and tagging/tunneling..
    <br /><br />
  id: '1891105015412484100'
  image: https://resources.blogblog.com/img/blank.gif
  name: jsicuran
  profile: http://www.amilabs.com
  pub: '2013-09-06T18:04:37.474+02:00'
  ref: '3718489426056265435'
  type: comment
- comments:
  - date: 12 September 2013 15:49
    html: Completely agree. Unfortunately we were more than happy (and oh-so proud
      of ourselves) to provide too many hack for too long instead of forcing the programmers
      (and framework developers) to learn what needs to be done.
    id: '7521400960283703138'
    image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2013-09-12T15:49:44.149+02:00'
    ref: '248713628042214545'
    type: comment
  - date: 12 September 2013 17:42
    html: '[repasting with hopefully correct parent comment :-)] <br /><br />It&#39;s
      all a collection of tradeoffs. Much like time/space in programming, you have
      control/cost and many other axis. This is the &quot;engineering&quot; portion
      of our job - and I do not think that there is a single silver bullet. <br /><br
      />Today is the &quot;interesting times&quot; between the generations of different
      paradigms, where we&#39;d like to already be in the new world - but the stuff
      that pays the bills today is all this cruft covered with warts, which creates
      a market for maintaining the relative health of the warts, which results in
      interesting interactions between the &quot;new&quot; and &quot;old&quot;.<br
      /><br />And the speed with which the &quot;new&quot; becomes &quot;old&quot;
      keeps increasing. <br /><br />Think puppet is cool ? Wrong. Docker is the new
      black, apparently. And, interestingly, these &quot;newest&quot; concepts do
      add the &quot;distributed&quot; nature again. (cf: coreos.com). Welcome back
      to peer to peer world :-)'
    id: '3967036314788881323'
    image: https://3.bp.blogspot.com/-ZKjhsxXiyuY/TkHGaTqGWPI/AAAAAAAAALY/6QMk05Zz4T4/s32/ayourtch-surf-square.png
    name: Andrew Yourtchenko
    profile: https://www.blogger.com/profile/14364645178881348283
    pub: '2013-09-12T17:42:58.520+02:00'
    ref: '248713628042214545'
    type: comment
  date: 12 September 2013 15:39
  html: 'If you engineer your application in such a way that you have multiple machines
    in multiple data centers... you do not need migrating anything anywhere anymore.
    You shut down one and bring up another. DNS may or may not be a solution. It depends
    on the app. <br /><br />The tricky part is of course that designing with the distributed
    architecture in mind from the start is way harder than taking a single-box architecture,
    and bolting on the migration later on.<br /><br />It&#39;s a question if different
    trade-offs at different times.<br /><br />When/if the frameworks emerge that allow
    easy development of the distributed applications, and the programmers grow that
    will grok that (this is not too far away - 256-core CPUs pose very similar problems!),
    this problem will be solved in a cleaner way. Till then we need a few hacks.<br
    /><br />--a<br /><br />ps. Completely agree with Russ about layering. '
  id: '248713628042214545'
  image: https://3.bp.blogspot.com/-ZKjhsxXiyuY/TkHGaTqGWPI/AAAAAAAAALY/6QMk05Zz4T4/s32/ayourtch-surf-square.png
  name: Andrew Yourtchenko
  profile: https://www.blogger.com/profile/14364645178881348283
  pub: '2013-09-12T15:39:12.706+02:00'
  ref: '3718489426056265435'
  type: comment
- comments:
  - date: 19 September 2013 14:48
    html: 'Hi Dmitriy,<br /><br />If I understand it correctly, you&#39;re saying
      there&#39;s an application out there that<br /><br />A) Uses some **** that
      cannot be routed with today&#39;s gear (example: unicorns over LAT)<br />B)
      Uses application-level data replication which is better than storage replication.<br
      /><br />I&#39;m positive you can find something like that out there in the wild;
      if you can, do share what this monstrosity is.<br /><br />However, in most cases
      it all comes down to building your network based on information gleaned from
      vendors&#39; whitepapers (because paying for a proper design and architecture
      obviously doesn&#39;t make sense). No wonder you get the network you deserve
      ;))<br /><br />Finally, I haven&#39;t heard of a data center being hit by a
      meteorite, but I do know of several organizations that experienced total meltdown
      of multiple data centers due to a bridging loop. Now they know better ...<br
      /><br />Kind regards,<br />Ivan'
    id: '7552888157357424296'
    image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2013-09-19T14:48:21.115+02:00'
    ref: '565739594233833169'
    type: comment
  - date: 19 September 2013 16:43
    html: Hi Ivan,<br /><br />&quot;B&quot; is closer to reality. These days almost
      everything is IP, and even broadcasts are used just for ARPs, so no rainbows
      and unicorns.<br /><br />Those are mostly monstrous financial applications that
      already cost millions to support. They usually do support clustering, but it
      could be impossible to hold multiple clusters sharing some common resources,
      with failover.<br /><br />And storage replication is as low-level as it gets.
      You always say that problems shouldn&#39;t be moved a couple of layers down
      the stack. If you&#39;re unlucky, you could get corrupt file systems when doing
      storage replication at the event of an outage, because it works on block level,
      it doesn&#39;t even know file systems exist. But link loss during application
      level replication usually causes loss of only a negligible amount of data. It
      doesn&#39;t cause corruption.<br /><br />And as I already said, a bridging loop
      between DCs is painful (although less likely with modern kludges like OTV if
      implemented properly), it costs money, but if it happens rarely enough, it doesn&#39;t
      pose a threat to the business itself. A meteorite (fire and malfunctioning extinguishers,
      loaded truck crashing into the datacenter building, thermonuclear explosion,
      zombie ourbreak or anything else) does.<br /><br />The tradeoff is &quot;more
      small incidents&quot; vs &quot;less small incidents, but risk of going out of
      business after unlikely, but still plausible disasters&quot;.
    id: '7207735151105607813'
    image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
    name: Dmitriy
    profile: https://www.blogger.com/profile/06090398639164774159
    pub: '2013-09-19T16:43:19.877+02:00'
    ref: '565739594233833169'
    type: comment
  - date: 19 September 2013 18:15
    html: '... and you&#39;re saying that these applications cannot work across L3
      subnets?'
    id: '3026882343296192919'
    image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2013-09-19T18:15:07.220+02:00'
    ref: '565739594233833169'
    type: comment
  - date: 20 September 2013 11:49
    html: 'Imagine VRRP or something analogous. L2 multicast session replication (some
      fancy tech for those dinosaurs). SLB using ACE/F5/whatever wouldn&#39;t allow
      that session replication between nodes. And even if the nodes can communicate
      via routed L3: you still have a single cluster with nodes in different DCs,
      with the usual potential caveats like split brain. It just wouldn&#39;t force
      you to have all the nodes L2 adjacent (but you have to purchase an SLB device).<br
      /><br />You have to face it: a cluster with nodes spread across DCs, even with
      L2 DCI, may sometimes be the neatest and safest architecture if you&#39;re considering
      business survival. And yes, you should probably try to avoid such applications.
      Life is simpler without them. Most businesses don&#39;t use them, which allows
      them to avoid complexity and run routing everywhere.'
    id: '4914859755405652808'
    image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
    name: Dmitriy
    profile: https://www.blogger.com/profile/06090398639164774159
    pub: '2013-09-20T11:49:09.283+02:00'
    ref: '565739594233833169'
    type: comment
  - date: 20 September 2013 15:12
    html: Now I guess we&#39;re close to being in agreement ;) <br /><br />BTW, there
      are other hacks out there that can create floating IP address for clustering
      needs without L2 interconnect.
    id: '8634917364869828535'
    image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2013-09-20T15:12:37.002+02:00'
    ref: '565739594233833169'
    type: comment
  - date: 20 September 2013 16:52
    html: 'Which brings us to the initial point: those are the kludges you have to
      pay for. Sure you can even do proxy arp to simulate L2 connections (you lose
      some features such as L2 multicast, you can&#39;t forward packets with TTL 1).
      It&#39;s probably safer than interconnecting DCs with VPLS, but it&#39;s still
      an extremely dirty hack. Personally I would always prefer any encapsulation
      mechanisms carrying L2 traffic to proxy arp.'
    id: '2081436763077025932'
    image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
    name: Dmitriy
    profile: https://www.blogger.com/profile/06090398639164774159
    pub: '2013-09-20T16:52:37.149+02:00'
    ref: '565739594233833169'
    type: comment
  date: 18 September 2013 22:06
  html: Ivan, there&#39;s one point you could be missing.<br /><br />Applications
    could be extremely expensive and extremely crappy at the same time. There&#39;s
    not always an option to make them better, you just have to live with them, purchase
    expensive high-end servers instead of loads of cheap machines like Google does
    etc. These are mission critical applications. You can choose others from the competitors,
    but they would be the same crap from the admin&#39;s perspective. <br /><br />And
    so, one day you may realize that implementing OTV with a stretched inter-DC HA
    cluster at application level could be an option that could once save your business
    itself. Yes, I know you hate this, but if a meteorite hits one of the DCs and
    all data inside it is gone forever (that&#39;s probably unlikely, but it has the
    potential to be fatal for the company), the other DC would continue working almost
    as if nothing happened. And there could be no other options to replicate data
    sort-of realtime except for low-level SAN replication which is expensive, kludgy
    and also dangerous. Consistency is not guaranteed with such techniques.<br /><br
    />Issues with the stretched clustering itself (split brain caused by loss of the
    inter-DC link and so on) could be painful, but not fatal. They happen rarely.
    They could be tolerated - considering them as side effects of the ability to survive
    the destruction of any DC without having to roll back to nightly backups (which
    could also be fatal - imagine financial companies).
  id: '565739594233833169'
  image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
  name: Dmitriy
  profile: https://www.blogger.com/profile/06090398639164774159
  pub: '2013-09-18T22:06:35.982+02:00'
  ref: '3718489426056265435'
  type: comment
count: 16
id: '3718489426056265435'
type: post
url: 2013/09/sooner-or-later-someone-will-pay-for.html
