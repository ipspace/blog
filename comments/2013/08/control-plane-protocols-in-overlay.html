<div class="comments post" id="comments">
  <h4>8 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="1378406203250152152">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://jedelman.com" rel="nofollow">Jason Edelman (@jedelman8)</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1378406203250152152" href="#1378406203250152152">14 August 2013 16:19</a>
              </span>
            </div>
            <div class="comment-content">After reading this, I figured I&#39;d look at the 1000V configuration guide.  Some things I found interesting.<br /><br />(1) - &quot;MAC distribution works only for static MAC addresses. If dynamic MAC addresses are found on ports that use VXLANs that operate in MAC distribution mode, syslogs are generated to indicate that MAC distribution does not work with dynamic MAC addresses.&quot;<br /><br />(2) - MAC distribution mode is a feature under Unicast-only mode.<br /><br />(3) - ASA 1KV, vShield, and VXLAN GW are the only three supported gateways.  This is oddly interesting since the first two (or any other L3 VM) should be able to be used as a L3 VXLAN gateway.  What are your thoughts on this?<br /><br />(4) For those who only preach VXLAN for scalability above 4k VLANs: &quot;The Cisco Nexus 1000V supports a total of 4096 VLANs or VXLANs (or a maximum of 2048 VLANs or 2048 VXLANs in any combination that totals 4096).&quot;<br /><br />-Jason (@jedelman8)</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="574953517558091764">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c574953517558091764" href="#574953517558091764">14 August 2013 16:52</a>
              </span>
            </div>
            <div class="comment-content">(1) That&#39;s pretty reasonable. NVP has similar limitations, as does Hyper-V. Using a proper control plane to emulate dynamic MAC learning (as caused by a bridge connecting VLAN to VXLAN) defeats the purpose of the control plane, does it not?<br /><br />(3) The keyword is &quot;supported&quot;. You can do anything you like as long as you don&#39;t expect TAC to fix your stupidity.<br /><br />(4) Yeah, I&#39;m well aware of that ... but even I tend to be semi-diplomatic sometimes ;) Anyhow, as NX1KV supports up to 128 hosts, that&#39;s a few thousand VMs, so 2000 VXLANs should be enough.<br /><br />Thanks!<br />Ivan</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="5476004278322528656">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/17332987438325943763" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5476004278322528656" href="#5476004278322528656">14 August 2013 16:53</a>
              </span>
            </div>
            <div class="comment-content">Ivan,<br /><br />I think you very clearly made the point that overlay networks are in their infancy when it comes to actually deploy them at true production scale. There is a huge amount of growing up that needs to happen, which as always will happen with small incremental deployments that will ultimately shape what the (set of?) control plane mechanisms will become the industry or defacto standard for overlay networks. It is a shame however that as an industry we once again promised the world in what overlay networks can solve, but kind of forgot it needs a very robust and scalable control plane to go along with it. Transport is always much easier than control.<br /><br />@mbushong has written about vendor lock on the Plexxi blog this week, and everyone reading the above should carefully consider the current &#39;open-ness&#39; of overlay solutions.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="5931846479815379501">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5931846479815379501" href="#5931846479815379501">14 August 2013 22:07</a>
              </span>
            </div>
            <div class="comment-content">Marten, overlay networks are NOT in their infancy (you don&#39;t believe Amazon VPC runs on VLANs, do you?), implementations from certain vendors clearly are.<br /><br />Also, some commercially available solutions have impressive scalability: http://networkheresy.com/2013/05/30/scale-sdn-and-network-virtualization/<br /><br />As for shameful practices of marketing departments ... well, I guess you know my opinion on those, starting with switching versus bridging.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="9193757544016984208">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/17332987438325943763" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c9193757544016984208" href="#9193757544016984208">15 August 2013 15:28</a>
              </span>
            </div>
            <div class="comment-content">You are right, I should have been a bit more selective in my wording.<br /><br />Overlay networks are not new and certainly some large providers have constructed large scale server based overlay solutions to provide VPC like services, but every enterprise customer I talk to (many of them very large and very progressive) does not believe there exist a truly viable solution for them at this time. Part of that is the lack of hw based gateways (very few vendors have that today) and no clear control plane that can manage the multitude of devices, OS&#39;s and hypervisors they have in place...<br /></div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1433203600399458262">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://bradhedlund.com" rel="nofollow">Brad Hedlund</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1433203600399458262" href="#1433203600399458262">18 August 2013 17:22</a>
              </span>
            </div>
            <div class="comment-content">&quot;lack of hw based gateways&quot;<br /><br />Another one bites the dust..<br /><br />http://networkheresy.com/2013/08/15/network-virtualization-gets-physical/<br /><br /></div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="8298463126777596941">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anees Shaikh</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8298463126777596941" href="#8298463126777596941">21 August 2013 21:52</a>
              </span>
            </div>
            <div class="comment-content">Ivan, small correction on the IBM solution -- it&#39;s called SDN-VE (SDN for Virtual Environments), and the first edition that came out in June is for VMWare hypervisors (using the IBM DVS-5000V dist. virtual switch).  It does allow clustering of the controller to support scale-out, with different controllers able to manage different sets of vswitches.  Address resolution and policy dissemination is handled centrally (similar to NVP, as you said) and communicated to vswitches and the gateway nodes using an internal protocol.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="9030223885501367848">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c9030223885501367848" href="#9030223885501367848">22 August 2013 14:50</a>
              </span>
            </div>
            <div class="comment-content">Thank you. Fixed.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
