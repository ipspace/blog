{
  "comments": [
    {
      "comments": [
        {
          "date": "02 June 2012 21:00",
          "html": "With 5msec RTT and almost no loss, the theoretical TCP throughput is above 200 GBps. http://www.switch.ch/network/tools/tcp_throughput/index.html<br /><br />I had 15 Gbps iperf flow between two VMs in the same hypervisor host, and the limit was the CPU/vSwitch, not the TCP performance.",
          "id": "994278485489008901",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2012-06-02T21:00:04.703+02:00",
          "ref": "8264047289516075398",
          "type": "comment"
        }
      ],
      "date": "31 May 2012 09:02",
      "html": "One question: is it possible to have a 30gbps TCP flow? (not unidirectionally generated with a packet generator, but an actual flow). Wouldn&#39;t RTT/Windowsize limitations kick in, even with minimal delay between hosts?",
      "id": "8264047289516075398",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Anonymous",
      "profile": null,
      "pub": "2012-05-31T09:02:47.505+02:00",
      "ref": "8444132166482539462",
      "type": "comment"
    },
    {
      "comments": [
        {
          "date": "02 June 2012 21:01",
          "html": "There&#39;s absolutely nothing special (apart from the secret-sauce load balancing on a single port group), the point of the second half of the post is that you can&#39;t win against a broken design no matter what you do.",
          "id": "3866413214956546336",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2012-06-02T21:01:04.919+02:00",
          "ref": "3396614571522013469",
          "type": "comment"
        }
      ],
      "date": "31 May 2012 19:58",
      "html": "Well, just raise the costs between A-C-D, so it will take the route A-B-D...? There\u00b4s nothing special about this ECMP behavior with Brocade,too.",
      "id": "3396614571522013469",
      "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
      "name": "Michael67",
      "profile": "https://www.blogger.com/profile/03014282355010119539",
      "pub": "2012-05-31T19:58:27.617+02:00",
      "ref": "8444132166482539462",
      "type": "comment"
    },
    {
      "comments": [
        {
          "date": "02 June 2012 20:46",
          "html": "According to Linux documentation, you should be able to get more than 10 Gbps over a pair of 10 Gbps uplinks. Not tested by yours truly though.",
          "id": "716405022861014844",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2012-06-02T20:46:58.024+02:00",
          "ref": "719878750354843289",
          "type": "comment"
        }
      ],
      "date": "01 June 2012 01:29",
      "html": "&quot;You need a server with multiple NICs configured in round-robin bonding mode to generate a TCP flow larger than 10Gbps.&quot;<br /><br />You may have just blown my mind....Even if the server has a 10Gb uplink?",
      "id": "719878750354843289",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Will",
      "profile": null,
      "pub": "2012-06-01T01:29:59.572+02:00",
      "ref": "8444132166482539462",
      "type": "comment"
    },
    {
      "date": "01 June 2012 03:09",
      "html": "I&#39;m with Will.  Mind blown.  Need to think about this one.",
      "id": "5751725432966214212",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Jason Edelman (@jedelman8)",
      "profile": "http://jedelman.com",
      "pub": "2012-06-01T03:09:59.109+02:00",
      "ref": "8444132166482539462",
      "type": "comment"
    },
    {
      "comments": [
        {
          "date": "02 June 2012 20:47",
          "html": "Brocade has solved that problem. See the &quot;proprietary perfect load balancing&quot; link in the article.",
          "id": "8371023605413450720",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2012-06-02T20:47:22.851+02:00",
          "ref": "5527058897654538497",
          "type": "comment"
        },
        {
          "date": "03 June 2012 06:13",
          "html": "Thanks for the pointer. I hope that&#39;s not a new trend -- having to read patents for documentation :-) The described solution of measuring link skew to do perfect transmit scheduling and thereby avoiding the need for receiver-side re-ordering seems almost too good to be true. Kudos to them if they really pulled than one off.",
          "id": "8630691396096194284",
          "image": "https://resources.blogblog.com/img/blank.gif",
          "name": "Anonymous",
          "profile": null,
          "pub": "2012-06-03T06:13:32.528+02:00",
          "ref": "5527058897654538497",
          "type": "comment"
        },
        {
          "date": "04 June 2012 16:02",
          "html": "Anonymous, we&#39;ve been doing it for over 10 years in the Fibre Channel space, there&#39;s really no new revolutionary technology in the way we do frame-based load balancing in VCS... :)",
          "id": "4056492448296018261",
          "image": "https://resources.blogblog.com/img/blank.gif",
          "name": "Juan Tarrio BROCADE",
          "profile": "http://www.twitter.com/jtarrioBRCD",
          "pub": "2012-06-04T16:02:53.083+02:00",
          "ref": "5527058897654538497",
          "type": "comment"
        }
      ],
      "date": "01 June 2012 15:25",
      "html": "If you configure the three links in round-robin mode, wouldn&#39;t you run the risk of packet re-ordering issues (see http://kb.pert.geant.net/PERTKB/PacketReordering)",
      "id": "5527058897654538497",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Anonymous",
      "profile": null,
      "pub": "2012-06-01T15:25:44.248+02:00",
      "ref": "8444132166482539462",
      "type": "comment"
    },
    {
      "comments": [
        {
          "date": "03 June 2012 19:57",
          "html": "Funny ... the documentation is mentioning &quot;per-packet&quot; load sharing, but no command to configure it. I would guess it&#39;s another mismatch between marketing and reality.",
          "id": "7808359526746143019",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2012-06-03T19:57:28.263+02:00",
          "ref": "8622077699231176439",
          "type": "comment"
        },
        {
          "date": "04 June 2012 21:04",
          "html": "Seems to be a copy and paste typo. The higher ones support this: http://bizsupport2.austin.hp.com/bc/docs/support/SupportManual/c02767753/c02767753.pdf<br /><br />&quot;per-packet: Performs load sharing in load-sharing link aggregation groups for each packet.&quot;",
          "id": "448277983047408184",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Michael67",
          "profile": "https://www.blogger.com/profile/03014282355010119539",
          "pub": "2012-06-04T21:04:51.250+02:00",
          "ref": "8622077699231176439",
          "type": "comment"
        }
      ],
      "date": "03 June 2012 18:23",
      "html": "Does anyone have something like that &quot;ethernet frame load sharing&quot;? H3C talks about &quot;per-packet&quot; load sharing, but seems something else: http://www.h3c.com/portal/download.do?id=1274015",
      "id": "8622077699231176439",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Anonymous",
      "profile": null,
      "pub": "2012-06-03T18:23:37.703+02:00",
      "ref": "8444132166482539462",
      "type": "comment"
    },
    {
      "date": "08 June 2012 07:09",
      "html": "Perhaps this could also be solved using OpenFlow and a different algorithm?",
      "id": "3703192292683965440",
      "image": "https://farm1.static.flickr.com/79/226353356_3c5a53d1a7_s.jpg",
      "name": "Fred Hsu",
      "profile": "https://www.blogger.com/profile/01605944565710444887",
      "pub": "2012-06-08T07:09:14.269+02:00",
      "ref": "8444132166482539462",
      "type": "comment"
    }
  ],
  "count": 15,
  "id": "8444132166482539462",
  "type": "post",
  "url": "2012/05/equal-cost-multipath-in-brocades-vcs.html"
}