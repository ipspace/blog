<div class="comments post" id="comments">
  <h4>4 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="6123768104244965992">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/02692959370712732451" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6123768104244965992" href="#6123768104244965992">17 May 2012 09:08</a>
              </span>
            </div>
            <div class="comment-content">Very nice presentations and discussions (3rd video), your first question with regarding to how to distribute traffic over fatter pipes, I think VCS control plane only has knowledge of individual links, i.e. there is no LAG/EthernetChannel pe se inside the fabric, so traffic will be hashed to all available links regardless whether the link is to the same next hop switch or different nexthop switch. Regarding your second question about vPC/vLAG toward split fabric, I don&#39;t think fabric itself has mechanism to decide which fabric should take over when this happens, if other side vPC/vLAG device can not detect the fabric failure (most likely they cannot), then there will be a broken L2.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="2517437595402897448">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/02692959370712732451" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2517437595402897448" href="#2517437595402897448">17 May 2012 09:26</a>
              </span>
            </div>
            <div class="comment-content">I did not quite get what Chip said that when 2 10G links are in the same ASIC port group, then VCS can essentially make it a 20G bandwidth link and do per-packet load balancing, in this case how VCS control plane is going to treat this 20G link for SPF calculation and how to ECMP traffic over this 20G link?</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7758022023867864118">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.twitter.com/jtarrioBRCD" rel="nofollow">Juan Tarr√≠o</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7758022023867864118" href="#7758022023867864118">17 May 2012 16:07</a>
              </span>
            </div>
            <div class="comment-content">VCS treats a per-packet trunk as a single physical link. Think about it as a L1 LAG. Any protocol running on top of that will treat it as a single link.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4548060288463765277">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">me@home.com</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4548060288463765277" href="#4548060288463765277">18 May 2012 14:52</a>
              </span>
            </div>
            <div class="comment-content">Actually, that&#39;s DR. Chip Copper to be politically correct :)<br /><br /><br />I just wrote up a long drawn out explanation of the questions above, but decided it was way too much info.<br /><br />Let&#39;s just say, ECMP takes care of getting from switch to switch and Brocade&#39;s fantastic hashing algorithm takes care of the load balancing. <br /><br />This technology works. I have this implemented in large production data centers and is supporting tens of thousands of VMs, physical servers, and entire tier 1 applications. <br /><br />The only thing I wish Brocade would do is document the increased performance just about all customers have seen using VDX switches in the SAME TOPOLOGY as their older 10g ethernet gear. <br /><br />VDX has increased performance 3x-4x on applications and NAS clusters just based on the losslessness and load balancing inherent to the system in the SAME EXACT TOPOLOGY as the older gear with no secret sauce at all!!!! These have been documented by my customers, and it&#39;s my customers that are evangelizing this technology for me!<br /><br />Next 2 years should be GREAT with VDX!!!</div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
