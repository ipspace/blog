<div class="comments post" id="comments">
  <h4>27 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="1193851848527917209">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1193851848527917209" href="#1193851848527917209">28 May 2012 07:59</a>
              </span>
            </div>
            <div class="comment-content">...and, because it&#39;s a widely recognized problem, work is being done on putting up some kludges to make it better. Some examples from ALU land:<br /><br />STP Loop guard: http://www.alcatelunleashed.com/viewtopic.php?f=190&amp;t=18462&amp;start=20#p66200<br /><br />MAC Move: http://lucent-info.com/html/93-0107-08-04-H/7450%20Services%20Guide/wwhelp/wwhimpl/common/html/wwhelp.htm#href=services_con_vpls.12.20.html&amp;single=true<br /><br />I bet other Vendors have something similar. ;)</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="6635134934681662641">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6635134934681662641" href="#6635134934681662641">28 May 2012 08:22</a>
              </span>
            </div>
            <div class="comment-content">Sure they do and a lot of people bet such features always work flawlessly ;)</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3748241874493946305">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3748241874493946305" href="#3748241874493946305">28 May 2012 12:49</a>
              </span>
            </div>
            <div class="comment-content">Everything is a compromise - you don&#39;t have to solve the problem to solve the problem. You only need to get it to where the risk is acceptable.<br /><br />Sometimes, when your faith in your Vendor&#39;s new features is somewhat shaky, that can mean &quot;just run spanning tree and be cautious&quot;. ;)</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1654008037151910281">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/16576239659380574562" rel="nofollow">Sam Stickland</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1654008037151910281" href="#1654008037151910281">28 May 2012 10:21</a>
              </span>
            </div>
            <div class="comment-content">I wonder if we&#39;ll ever be able to modify Ethernet to make hosts register their MAC/IP entries and just remove broadcast.<br /><br />http://www.cs.cmu.edu/~acm/papers/myers-hotnetsIII.pdf<br /><br />Does IPv6 with IGMP snooping switches require flooding or could it be removed?</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="283886526857555668">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c283886526857555668" href="#283886526857555668">28 May 2012 15:22</a>
              </span>
            </div>
            <div class="comment-content">IGMP snooping (actually, MLD) reduces the flooding scope for multicast destination MAC addresses. Broadcast and unknown unicast flooding is not affected.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6482434627160671206">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/16576239659380574562" rel="nofollow">Sam Stickland</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6482434627160671206" href="#6482434627160671206">11 June 2012 12:00</a>
              </span>
            </div>
            <div class="comment-content">Yes, but my point was does an IPv6 only network with MLD need broadcast and unknown unicast flooding enabled at all? Or could those functions be disabled?</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7649848775288230625">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7649848775288230625" href="#7649848775288230625">11 June 2012 12:26</a>
              </span>
            </div>
            <div class="comment-content">There might still be applications using broadcast. Assuming those eventually become extinct and you&#39;re running IPv6-only network, you could still experience TCAM overflows that would then require unicast flooding to ensure end-station reachability. Also, you&#39;d have to ensure the IPv6 ND timeouts are lower than the MAC aging timeouts ... but in theory, it could be done.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7357087412911131530">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/04661928787006765039" rel="nofollow">Ian Castleman</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7357087412911131530" href="#7357087412911131530">28 May 2012 17:27</a>
              </span>
            </div>
            <div class="comment-content">Sounds familiar ;-) <br /><br />That picture is right up there with the swiss army knife!</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6748464688103977494">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6748464688103977494" href="#6748464688103977494">28 May 2012 17:57</a>
              </span>
            </div>
            <div class="comment-content">Ivan,<br /><br />As usual, quality post but regarding your statement, &quot;...then you simple have to split it up into multiple layer-2 domains connected through layer-3 switches&quot;, would you care to elaborate?  I work in datacenters but on the facilities side and I have been burned many times by industrial devices that have poor/limited tcp/ip stack or in some cases, devices not able to route back to their server leaving me with having to span layer two across a couple switches.  I have implemented storm control but as you mentioned, that may not be enough to stop a meltdown.  I&#39;m curious how I can overcome that hurdle while maintaining your recommendation about splitting the layer-2 domain through layer-3 switches.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="2166101525791839740">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2166101525791839740" href="#2166101525791839740">29 May 2012 19:19</a>
              </span>
            </div>
            <div class="comment-content">The answer is there is no way to overcome the hurdle.  Create several interfaces on the server each interface on its own vlan.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1957668514226599600">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://bing.com" rel="nofollow">Petr Lapukhov</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1957668514226599600" href="#1957668514226599600">28 May 2012 19:50</a>
              </span>
            </div>
            <div class="comment-content">Well, I don&#39;t quite get something. So we state that L2 network is a single failure domain. Alright. But now we get the same L2 network wrapped and tunneled over IP, and it&#39;s no longer a single failure domain? :) Have we magically agreed on fixing the flooding behavior, which is the actual root cause of L2 scalability limitation, in any of these standards?</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="1574875269892286373">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Ofer</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1574875269892286373" href="#1574875269892286373">28 May 2012 22:25</a>
              </span>
            </div>
            <div class="comment-content">My thoughts exactly ... :)</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="9089731848125618367">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c9089731848125618367" href="#9089731848125618367">29 May 2012 08:12</a>
              </span>
            </div>
            <div class="comment-content">L2 network is still a single failure domain, even if it&#39;s wrapped in IP (that&#39;s why using VXLAN or NVGRE for long-distance stretched clusters makes no sense), but at least the underlying transport is not.<br /><br />As for &quot;fixing the flooding behavior&quot;, Nicira got pretty far (VXLAN and NVGRE have just inserted another layer of abstraction and resurrected IP MC) and can do either headend replication or replication in dedicated nodes. <br /><br />The only one that decided to go all the way and kill flooding was Amazon; everyone else is too concerned about precious enterprise craplications that rely on L2 flooding in one stupid way or another.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="990911636418079558">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Ofer</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c990911636418079558" href="#990911636418079558">29 May 2012 09:27</a>
              </span>
            </div>
            <div class="comment-content">I can see how VXLAN/NVGRE may *narrow* flooding, but can you really kill it? e.g. VM instantiation still involves G-ARP AFAIK...</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="5646580510760879723">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5646580510760879723" href="#5646580510760879723">29 May 2012 14:15</a>
              </span>
            </div>
            <div class="comment-content">VXLAN or NVGRE cannot kill flooding because they have no control plane (although Dell did announce an ARP helper appliance @ Interop, so who knows what will happen to NVGRE).<br /><br />Nicira&#39;s NVP is a totally different story. They might not be totally there yet, but the architecture does allow that.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6872176489045036587">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6872176489045036587" href="#6872176489045036587">28 May 2012 19:58</a>
              </span>
            </div>
            <div class="comment-content">As a reminder, routing is not a magic solution. IGP is also single fault domain, just wait until you hit bug in IS-IS implementation or have bad luck with packet corruption. Been there, done that.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="5332980133630756741">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://bing.com" rel="nofollow">Petr Lapukhov</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5332980133630756741" href="#5332980133630756741">28 May 2012 20:44</a>
              </span>
            </div>
            <div class="comment-content">The difference is that routing control plane is, well, more controlled with regards to information flooding :)  So in theory, you could reduce the disruption risks, if designed and operated properly. <br /><br />This being said, control plain failure examples are always epic. Especially at the Internet scale :)</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2273933611413130659">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Will</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2273933611413130659" href="#2273933611413130659">29 May 2012 06:57</a>
              </span>
            </div>
            <div class="comment-content">I&#39;m not sure I agree anymore.  I run a single tenant data center for a huge company (60K plus users)<br /><br />I can have a huge network that is broken up into a huge amount of small L2 broadcast domains all connected to the same core switch pair (or aggregate if you&#39;re a Cisco guy)<br /><br />If one of those tiny L2 broadcast domains loop, then your core switches lock up, and your whole network goes down.  &quot;single circulating broadcast packet (and its infinite copies) will trigger storm control on ALL SWITCHES, and prevent other valid broadcasts&quot;<br /><br />I&#39;ve tested various loops scenarios in a large scale network (300+ TOR switches and a pair of Cisco 7Ks).  I&#39;ve found storm control doesn&#39;t work in 10Gb networks with Cisco FEX.  I&#39;ve found port-security does work well although increases trouble ticets(opex).  I&#39;ve found that default COPP works awesomely in keeping your Nexus 7Ks alive so you can find the loop. I&#39;ve found my best bet is to configure the network to prevent loops and not try and configure around loops.  And screw the ideals of preventing loops by telling your cabling crew to cable properly!!  That will work for 6 months or a year until they forget again.<br /><br />So who cares how big your L2 domains are?  And if you have the same aggregate switch pair (everyone does) then it doesnt matter how many load balanceers or firewall instances you have. I&#39;d say your chances are equally the same taking out your data center.  In fact....if you cable differently for smaller L2 domains then I&#39;d say your chances go up!  But You do lose mobility and scalability the smaller you make your L2 domains.<br /><br />I dont even want to talk about mac-in-mac or mac-in-multicast.  No one is there yet.<br /><br />I dont even want to talk about STP replacement.  No one is there yet.<br /><br />I&#39;d perhaps consider multiple aggregate layer switches (if the 7Ks had the capacity for more than four VDC).  That limitation makes VDC useless except for your Development instance.<br /><br />Ivan, btw, will you be in San Diego this month?</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="8902480159303701581">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8902480159303701581" href="#8902480159303701581">30 May 2012 15:04</a>
              </span>
            </div>
            <div class="comment-content">Would A cheat to win solution to the cable guy problem be to leave unused ports disabled?</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="5471141425059842562">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/07558728700926286196" rel="nofollow">Jeremy Filliben</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5471141425059842562" href="#5471141425059842562">07 June 2012 16:30</a>
              </span>
            </div>
            <div class="comment-content">Will,<br /><br />Perhaps if you use different core switch pairs for each L2 domain, you&#39;ll be able to avoid fate-sharing in this case. It&#39;s more expensive, and not as fancy as VDCs, but it should meet your requirements.<br /><br />I personally don&#39;t have the budget to implement multiple N7K pairs in my DC, so I can&#39;t take this advice either :(<br /><br />Jeremy</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7392665028352334953">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7392665028352334953" href="#7392665028352334953">30 May 2012 14:58</a>
              </span>
            </div>
            <div class="comment-content">pbb-te / pbt avoid these problems by turning off broadcasts (all, including unknown mac flooding) and forcing the switches to use an outboard control plane to provision all mac forwarding tables.<br /><br />I&#39;m sure openflow has a similar magic unicorn fart type answer to this problem....<br /><br />Now if only someone could solve the problem in practice as well as theory.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="4490554774536154513">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/06975038984318901369" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4490554774536154513" href="#4490554774536154513">19 June 2012 01:19</a>
              </span>
            </div>
            <div class="comment-content">If I understood this right, it is not about Broadcast alone.<br /><br />Its about errors which may occur (software or manual or just race conditions), that can cause loops.<br /><br />-Vishwas</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="421886107361628056">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/06646973209424821070" rel="nofollow">chris marget</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c421886107361628056" href="#421886107361628056">03 June 2012 01:37</a>
              </span>
            </div>
            <div class="comment-content">Ivan,<br /><br />Thanks for calling out storm control as the preemptive DoS attack that it is.<br /><br />That feature is just a turd in my opinion:<br /><br />1) The granularity is terrible - it&#39;s not a throttle, it just counts bytes over a 1 second (I think?) interval, and then throws data away for the remainder of the second once the threshold has been hit. Awful, unless you set it to 10% with the expectation that your server ports will be deaf to some protocols for 90% of every second...<br /><br />2) Who am I (as the network admin) to decide when a server has sent &quot;too many&quot; broadcast or multicast frames? I&#39;ve never seen anything along these lines codified in an SLA given to the user/server/application community. Accordingly, if a craplousy business application is built to work exclusively with broadcast frames, and it runs into storm control, guess what feature is going to be switched off?</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="7098900407026887003">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7098900407026887003" href="#7098900407026887003">06 June 2012 06:14</a>
              </span>
            </div>
            <div class="comment-content">2) when they take out a data center</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2182244395018940205">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/06975038984318901369" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2182244395018940205" href="#2182244395018940205">19 June 2012 00:52</a>
              </span>
            </div>
            <div class="comment-content">Ivan, <br /><br />I agree with most of what you say.<br /><br />TRILL does have loop prevention by adding a Hop Count, as the last measure of breaking loops.<br /><br />Tunneling can cause loops too BTW. This is something that has been raised with IPv6. Have a look at:<br />http://tools.ietf.org/html/rfc6324<br /><br />-Vishwas</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="3776314869924927243">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://stormcontrol.tumblr.com" rel="nofollow">Pablo Carlier</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3776314869924927243" href="#3776314869924927243">17 July 2012 10:43</a>
              </span>
            </div>
            <div class="comment-content">Exactly my thinking.<br /><br />TRILL is actually closer to routing than to bridging, therefore it&#39;s a L2 protocol that incorporates most of the benefits of L3 protocols. TTLs prevent infinite loops, and in Cisco&#39;s FabricPath you get conversational MAC learning, which eases the burden of having to learn all addresses in your L2 domain.<br /><br />Still, I wonder how is it that SAN admins got away with deploying two independent and separate networks, and LAN admins did not. It is evident that the first hop L2 connection is a single failure domain, no matter how resilient it is. <br /><br />It&#39;s time Operating Systems and applications start supporting dual LAN designs so we can effectively protect this single failure domain.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7451885924019137893">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7451885924019137893" href="#7451885924019137893">18 July 2012 08:11</a>
              </span>
            </div>
            <div class="comment-content">@Pablo: You can have dual LAN design any time you want - just configure a loopback interface on the server and run a routing protocol with the network ... or configure the load balancer with both server addresses in the server pool. <br /><br />There&#39;s no technological reason you can&#39;t do it ... apart from the limitations of broken socket API and missing session layer in TCP stack ;)</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
