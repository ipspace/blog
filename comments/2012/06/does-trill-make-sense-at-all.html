<div class="comments post" id="comments">
  <h4>17 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="1882018091514073324">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/07558728700926286196" rel="nofollow">Jeremy Filliben</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1882018091514073324" href="#1882018091514073324">21 June 2012 15:06</a>
              </span>
            </div>
            <div class="comment-content">Ivan,<br /><br />You touched on something I&#39;ve been thinking about recently... Cisco hasn&#39;t provided any interesting proprietary &#39;hooks&#39; in the DC environment in several years for mid-sized customers. The only two that come to mind are OTV (ugh) and now LISP. LISP is intriguing, but its also an open technology.<br /><br />Without a doubt I prefer standards-based technologies, so I shouldn&#39;t be complaining. But it will be interesting to see Cisco competing on price in this space. And maybe not great for the industry, if it shrinks Cisco&#39;s R&amp;D budget.<br /><br />Jeremy</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1711485784403187292">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1711485784403187292" href="#1711485784403187292">21 June 2012 16:11</a>
              </span>
            </div>
            <div class="comment-content">Ivan - <br /><br />Great insights and a wonderful morning read as always.  <br /><br />You specifically mention both Cisco and Brocade in the context of MLAG and STP/TRILL feature support and behaviour; I&#39;m curious if you have any similar reference or insights on Juniper&#39;s EX 4200/4500 and their Virtual Chassis.  <br /><br />While I don&#39;t believe there is currently anything TRILL-like outside a single VC stack (which under-the-hood is running IS-IS to create a &quot;somewhat-routed network transporting MAC frames&quot;, as it were), there is certainly MLAG as well as STP for server/vswitch facing ports.<br /><br />Curious on your thoughts where (if?) EX fits into the mid to high range DC switching game; QFabric seems to get all the attention but, as you&#39;ve alluded to a number of times, remains out of reach (or just out of scope) for most.  <br /><br />I believe a combination of EX 4200/4500 VC stacks could be a great fit (price/performance) for the CLOS design you laid out in your first diagram, or another right-sized variant.<br /><br />There are those of us who will never see or touch FabricPath or QFabric, but still have a keen interest in the options and features available to our market segment and how we can use them effectively to create an effecient, redundant, robust layer 2 switching environment, even if we don&#39;t get to call it a &quot;fabric&quot; :)<br /><br />Cheers!<br /><br />-Chris</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="2824410952474923517">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://twitter.com/#!/LiorLive" rel="nofollow">Lior Cohen</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2824410952474923517" href="#2824410952474923517">24 June 2012 12:54</a>
              </span>
            </div>
            <div class="comment-content">In the Juniper EX Case you can use the Virtual Chassis (VC) technology, which as you had mentioned eliminates any need for STP throughout the VC. <br />Additionally you can use MLAG between different VC&#39;s, i.e. an EX3200/EX4200 Access switch (stack) connected up-to different Core/Agg EX8200 Switches running as a VC.<br /><br />Alternately you can use the &quot;closed&quot; option being Juniper QFabric based switching (IMO FabricPath is also closed - it won&#39;t work with brocade, or anyone else) effectively take a QFX3500 turn it on as a std. switch up-to multiple EX8200&#39;s with MLAG, or connect turn it on as a QFabric node and connect it up-to a QFabric Interconnect getting rid of any need to configure protocols.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7692620520106798532">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/12788603393681012943" rel="nofollow">krisiasty</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7692620520106798532" href="#7692620520106798532">21 June 2012 21:29</a>
              </span>
            </div>
            <div class="comment-content">You wrote &quot;stuck with VPC&quot; many times, but what is wrong with VPC (and VPC+ if we are talking about using it with FabricPath) ?</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3367107628651117274">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3367107628651117274" href="#3367107628651117274">22 June 2012 21:41</a>
              </span>
            </div>
            <div class="comment-content">I agree with krisiasty, the recent improvements made to VPC with VPC+ and FabricPath eliminate the split brain problem that happens with MLAG/STP.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="8917340433079987117">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/08806122907850134756" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8917340433079987117" href="#8917340433079987117">02 July 2012 00:29</a>
              </span>
            </div>
            <div class="comment-content">Thank you Ivan for another of your enlightening articles. I was wondering why everyone is just talking about moving VMs within a cluster. I think there are a lost of cases were you need to move a VM accross two sepparate clusters in different locations or DCs for example. Now in some cases these different locations or DCs don&#39;t have L2 connectivity. In those cases overlay networks (VXLAN, NVGRE, STT, etc.) have a clear advantage over TRILL. With overlay network you can extent the &quot;virtual segment&quot; accross L3 domains and move the VMs (non-live migration) transparent to the OS/Application on the VM. This is the decoupling between networking and application logic that is required so that the &quot;networks doesn&#39;t in the way&quot;. I know you&#39;ll say that you can setup a new subnet, route it between the two locations/DCs, reconfigure the application in the VM and all is well, but as anyone working at a mid to large scale shop will tell you this coordination between application admins and the networking department is going to take time and probably not work the first time round.<br /><br />One other thing I&#39;ve not seen anyone talking about is MTU in regards to network overlays. I&#39;m curious if anyone has encountered issues with fragmentation when implementing overlay networks and how they have solved these.<br /><br />BTW krisiasty, a particular nuisance with VPC is that you need a link between the VPC peers. Spine-leaf topologies (clos networks) don&#39;t require such connectivity but if you need VPC for say switch-server LAG you&#39;ll have to add that VPC peer link.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="718672545544497119">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c718672545544497119" href="#718672545544497119">08 July 2012 20:25</a>
              </span>
            </div>
            <div class="comment-content">#1 - Stretched L2 subnet over VXLAN is still a stretched L2 subnet. Apart from getting rid of the STP problems, you haven&#39;t solved a thing. See:<br /><br />http://blog.ioshints.info/2011/11/busting-layer-2-data-center.html<br />http://blog.ioshints.info/2012/03/stretched-layer-2-subnets-server.html<br /><br />#2 - You have to have jumbo frames in the transport network to run L2-over-IP. There are ways around this requirement (reduce MTU size on vNIC), but you wouldn&#39;t want to use them.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2278924218157701024">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.atc.unican.es/~enrique/" rel="nofollow">Enrique</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2278924218157701024" href="#2278924218157701024">18 July 2012 02:45</a>
              </span>
            </div>
            <div class="comment-content">Hi Ivan,<br /><br />I am really enjoying your blog. I have read some of your posts about TRILL, some info from vendors and even the IEEE standard, and there is still one thing I fail to understand. I hope you can provide some light here.<br /><br />I believe there are two important problems solved with STP: (i) broadcast storms and (ii) deadlock. Broadcast storms (i) are solved in TRILL by using a hop count, so that part is clear. Deadlock (ii) requires network loops to happen (so the STP prevents it), and it is irrelevant on lossy networks such as (classical) Ethernet since frame discarding also prevents it.<br /><br />However, since TRILL is allowing for loops in the network, how are circular data dependency chains prevented, considering a lossless network (implementing 802.1Qbb, for example) with PAUSE frames? I believe that, in such case, a cycle might arise and the network might get blocked. I really fail to understand how such loops are prevented to happen (and thus block the network). The standard does not mention it at all, and no relevant info is found on the development group documents, vendors info or other sites.<br /><br />Hope you can give some insight!! Thanks in advance, <br /><br />Enrique</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="3359799954828930666">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3359799954828930666" href="#3359799954828930666">18 July 2012 08:01</a>
              </span>
            </div>
            <div class="comment-content">In theory, you&#39;re right. In a totally lossless network, you might get deadlocks under really weird set of circumstances. However, I don&#39;t see any reasonable real-life scenario where they&#39;d occur.<br /><br />And no, I haven&#39;t seen this problem being addressed in any of the standards.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1467534208521809877">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.atc.unican.es/~enrique/" rel="nofollow">Enrique</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1467534208521809877" href="#1467534208521809877">18 July 2012 09:26</a>
              </span>
            </div>
            <div class="comment-content">Well, certainly this is not a problem if you still rely on a fat-tree or Clos-based physical topology (access, distribution and core) which imposes an up-down routing, but employing TRILL to allow for multipathing (instead of a VSS-based solution, for example).<br /><br />But assume that, since TRILL allows for multipath forwarding (erm... switching), you employ an alternative topology that does not rely on up-down routing. This is the case of the 2D or 3D torus (e.g., the Infiniband-based 3D torus in the Gordon Supercomputer at SDSC) or a flattened-butterfly (Kim et al, ISCA&#39;07), for example. What do you think about those cases?<br /><br />Thanks</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="860311242203655824">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c860311242203655824" href="#860311242203655824">18 July 2012 09:35</a>
              </span>
            </div>
            <div class="comment-content">As for generic multipathing, monkey design was never a good idea ;) http://blog.ioshints.info/2012/04/monkey-design-still-doesnt-work-well.html<br /><br />I am positive the topologies you&#39;ve mentioned have some interesting implications ... but so does the black hole evaporation ;))</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1610278424220742826">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.atc.unican.es/~enrique/" rel="nofollow">Enrique</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1610278424220742826" href="#1610278424220742826">18 July 2012 11:12</a>
              </span>
            </div>
            <div class="comment-content">Thanks!! :)</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4715135981579453073">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.it20.info" rel="nofollow">Massimo Re Ferre'</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4715135981579453073" href="#4715135981579453073">20 July 2012 10:07</a>
              </span>
            </div>
            <div class="comment-content">Alexander Papantonatos hits the nail on the head. <br />Ivan I think we are talking a lot about vMotion but the &quot;issue&quot; is larger than that. Other than cold moving a VM from one cluster to another and keep its personality (for the reasons Alexander was mentioning) fast forward to where we are going to with this notion of a &quot;virtual data center&quot; (or &quot;software defined data center&quot;). We want to take a shared infrastructure (compute, network, storage) and carve it up into multiple independent entities (which contains virtual instances of those elements) where users can deploy workloads. So there may be some 3,5,10,40 clusters (depending on the size of the company) where you want to carve out those virtual elements and you can&#39;t do this if you have network constraints. You need to be able to deploy two workloads on a layer 2 segment and you also need to have the flexibility to allow those two workloads to be deployed one on cluster 3 and the other on cluster 36 (for example). <br /><br />This has nothing to do with &quot;new applications&quot; type of things. I do agree completely that new workloads, new techniques, new best practices will allow (in the mid-long run) organizations to adapt to a cleaner / more simple L3 approach. This is about trying to fix a problem for &quot;current workloads&quot; that do require legacy techniques/best practices in the short-mid run. <br /><br />At age 40 I think I won&#39;t have a chance to see those &quot;new workloads&quot; going mainstream just to give you a flavor of what I think is the pace the industry is moving. Imagine the opportunity. <br /><br />Massimo Re Ferre&#39; (VMware).</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4770152415401462935">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/02412389441399574027" rel="nofollow">Ilja</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4770152415401462935" href="#4770152415401462935">20 July 2012 11:04</a>
              </span>
            </div>
            <div class="comment-content">In the internet app space load balancing coupled with deployment automation frameworks has largely eliminated IP address preservation requirement for workload moves. I think Massimo will see these going mainstream. My unscientific argument is based on reduction of the time it takes open source approach to move from bleeding edge to mainstream (Linux 7+ years, Hadoop 4-5 years, Openstack/Eucalyptus 3?). By mainstream I mean traditional IT shops in medium to large companies actually rolling out for part of the infrastructure.<br />Deployment automation frameworks (Puppet, Chef etc) are pretty much a requirement for large public cloud deployments too so you would expect these to become mainstream in next couple of years. Once your organisation (the server guys) knows how to do this, there&#39;s a lot less need for large scale IP address preservation.<br />You still need to move VMs, but you can do it in more sensible scale and have network that is simple(r) to deploy and troubleshoot.<br /><br />Ilja</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3531472491145709709">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.it20.info" rel="nofollow">Massimo Re Ferre'</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3531472491145709709" href="#3531472491145709709">20 July 2012 11:23</a>
              </span>
            </div>
            <div class="comment-content">Ilja, I believe it boils down to the meaning we associate to the word &quot;mainstream&quot;. If you are saying OpenStack/Eucalyptus took three years to go mainstream... (implying they are *now* mainstream) we do have different meanings of the term ;) <br /><br />As far as the 7+ years for Linux... It was circa 1998/1999 when IBM started to back it and it was around for much longer. It is indeed mainstream no doubt about it but it&#39;s (still) roughly 1/4th of the  traditional Windows legacy market. <br /><br />I don&#39;t know if I can define AWS as mainstream. Probably yes, although if I ask 100 &quot;IT&quot; people over here in Italy what Amazon does most of them would say they sell books online). They seem to be making 1B$ a year on it ... roughly what IBM still make with the AS/400. <br /><br />Do you see what I mean when I say &quot;opportunity&quot; talking about VXLAN? <br /><br />Last but not least I divide the world in three geographies: Silicon Valley, US, World. <br /><br />Depending on where you are and the market you watch you may see different behaviors and what you see mainstream in a GEO it&#39;s not mainstream in another  ;) <br /><br />Massimo.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="5305883488120845352">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/02412389441399574027" rel="nofollow">Ilja</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5305883488120845352" href="#5305883488120845352">20 July 2012 14:05</a>
              </span>
            </div>
            <div class="comment-content">Yes I do get the point - in particular in the world of Windows (it&#39;s architecture kind of always assumed L2 network even without vmotion-at least no firewall between hosts). I was expecting you have still many years of caree ahead of you :=).  Market size does not equal deployment sizes in Linux though(?). With OpenStack the mainstream is of course service providers - would not expect end user companies to deploy it - it&#39;s too much today. What I was referring also is how long it takes to have a commercially viable market around an open source product. I remember when Hadoop became public Teradata guys were saying it will never be used in enterprises....<br /><br />Interesting point about GEOs. On cloud I am assuming that in order to stop AWS et al HP, Dell and everyone else will start selling cloud F2F to companies of all sizes in next couple of years. That will bring rest of the world closer to Silicon Valley.<br /><br />Additionally to support the vxlan opportunity it has to be said that is somewhat easier to build large L2 fault zone than migrate out of it in most cases. Paint and corner.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6225925484007120189">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.it20.info" rel="nofollow">Massimo Re Ferre'</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6225925484007120189" href="#6225925484007120189">20 July 2012 15:34</a>
              </span>
            </div>
            <div class="comment-content">Now now... don&#39;t make me feel like I am working on old stuff. I still have former colleagues at IBM doing Cobol.....  For many of them VXLAN is &quot;the future&quot; :) <br /><br />Having this said I don&#39;t think I am spending all of my career on this. I wouldn&#39;t mind working on (even more) leading edge stuff.... but I think it&#39;s good not to be too far ahead :) <br /><br />Massimo.</div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
