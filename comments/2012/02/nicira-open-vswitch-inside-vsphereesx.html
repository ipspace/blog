<div class="comments post" id="comments">
  <h4>21 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="7222783992569460667">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Kurt Bales</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7222783992569460667" href="#7222783992569460667">09 February 2012 11:50</a>
              </span>
            </div>
            <div class="comment-content">Amazing insights here Ivan.<br /><br />You mention a limit of 409x ports in the port-group, tho I assume that this is a limit per Host/OVS? Now for sensible designs 409x hosts is more than enough, let alone 409x multiplied by a max of 32 hosts in a cluster, tho I can picture some instances where this may be beneficial.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1162605474426709770">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1162605474426709770" href="#1162605474426709770">09 February 2012 12:00</a>
              </span>
            </div>
            <div class="comment-content">That&#39;s the total number of VMs you can connect to the port group (across all hosts with the same vDS). They need per-VM VLAN to create a P2P link between VM and OVS-VM, and you only have 4K VLANs (and you can&#39;t recycle them because someone could vMotion a VM to another host).</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4438330385911839197">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Loren Gordon</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4438330385911839197" href="#4438330385911839197">09 February 2012 13:04</a>
              </span>
            </div>
            <div class="comment-content">Do you have a source for this claim? &quot;(you canâ€™t push more than a few Gbps through userland).&quot; My understanding and experience has been that ESX can push as much as the OS can handle, and easily saturates 10Gpbs with things like vMotion if the physical network can handle it. Obviously, different interfaces and kernels here. I&#39;m just wondering if perhaps you might be underestimating or downplaying the potential capabilities...</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="9190931295733821752">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anton Marchenko</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c9190931295733821752" href="#9190931295733821752">09 February 2012 14:12</a>
              </span>
            </div>
            <div class="comment-content">In my understanding and according to your previous blog post (http://blog.ioshints.info/2011/06/test-your-vmware-networking-skills.html ) we can&#39;t reuse VLANs even across different port groups, because port groups don&#39;t provide isolation.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3101750156308528300">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3101750156308528300" href="#3101750156308528300">09 February 2012 14:12</a>
              </span>
            </div>
            <div class="comment-content">I don&#39;t (yet) have a consistent theory behind anecdotal evidence and a few data points ... and the fact that every time someone describes a VM-based networking appliance solution to me I ask &quot;and the performance is around a few Gbps&quot; ... and get &quot;yeah&quot; as an answer.<br /><br />Two data points I already wrote about:<br />http://blog.ioshints.info/2011/11/junipers-virtual-gateway-virtual.html<br />http://www.ipspace.net/Embrane_heleos:_scale-out_distributed_virtual_appliance</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1979265374259469218">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1979265374259469218" href="#1979265374259469218">09 February 2012 14:14</a>
              </span>
            </div>
            <div class="comment-content">... also, please note that the &quot;few Gbps&quot; applies to VMs doing network-layer packet forwarding. Server VMs can easily saturate 10 Gbps uplink without consuming a whole core.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3550732108206638851">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3550732108206638851" href="#3550732108206638851">09 February 2012 14:19</a>
              </span>
            </div>
            <div class="comment-content">Good one. Absolutely true. You can however reuse them across different vSwitches/vDS (because they are independent bridging domains).<br /><br />Summary: create a totally new vDS for Nicira&#39;s needs.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="5807267127922175894">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anton Marchenko</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5807267127922175894" href="#5807267127922175894">09 February 2012 14:59</a>
              </span>
            </div>
            <div class="comment-content">Actually it means that to scale to more than 4K VMs you have create several vDS. Does it also mean that you have to provision a different OVS VM per vDS on the same ESX host or you can reuse the same VLANs across different vNIC trunks coming from different vDS to the same OVS VM?</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7101374179710136821">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">wmf</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7101374179710136821" href="#7101374179710136821">09 February 2012 18:35</a>
              </span>
            </div>
            <div class="comment-content">A traditional vSwitch is just as much a SPOF, right? In fact it&#39;s worse if it runs inside the VMkernel.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1284421911644474340">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Tommy P</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1284421911644474340" href="#1284421911644474340">09 February 2012 20:04</a>
              </span>
            </div>
            <div class="comment-content">Very Impressive break-down Ivan  ;)</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7670120774594923262">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">DanielG</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7670120774594923262" href="#7670120774594923262">09 February 2012 21:12</a>
              </span>
            </div>
            <div class="comment-content">Thanks for this clarification, it wasn&#39;t until I read this that it clicked about the VLAN usage and p2p to the OVS VM. Originally I was thinking like Kurt if this was per host. But per 32 host cluster/VDS makes sense and does scale pretty well. ~126-7 VMs per host isn&#39;t too shabby.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="188939034988149998">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Brad Hedlund</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c188939034988149998" href="#188939034988149998">10 February 2012 02:04</a>
              </span>
            </div>
            <div class="comment-content">Nicira + Open vSwitch + VMware = DOA (unfortunately)</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="66805272231077057">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">cloudtoad</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c66805272231077057" href="#66805272231077057">10 February 2012 02:39</a>
              </span>
            </div>
            <div class="comment-content">Agree 100%.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="11482377547165107">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">David Le Goff</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c11482377547165107" href="#11482377547165107">10 February 2012 09:12</a>
              </span>
            </div>
            <div class="comment-content">This was true until x86 leaders came with new data plane architecture. We are a proved example that you can deliver dozens of Gbps with virtual networking appliance on userland. also very important, independent from he packet size (so consider the pps benchmarks!). We delivered all around the world high performance SDN for mobile core network and are ramping up now on the Cloud space...</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2992628193466207124">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2992628193466207124" href="#2992628193466207124">10 February 2012 09:43</a>
              </span>
            </div>
            <div class="comment-content">Sounds absolutely interesting. If you&#39;re willing to tell me more, please contact me directly:<br /><br />http://www.ipspace.net/Contact</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7632673379150605779">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">David Le Goff</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7632673379150605779" href="#7632673379150605779">10 February 2012 10:01</a>
              </span>
            </div>
            <div class="comment-content">done  :)</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7304362985981442708">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Loren Gordon</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7304362985981442708" href="#7304362985981442708">10 February 2012 13:58</a>
              </span>
            </div>
            <div class="comment-content">I wish I had 10GbE to the servers in my lab...this would be a dead simple test. Set up a test VM configured as a router and see what we get!</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1881158899704955857">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">David Le Goff</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1881158899704955857" href="#1881158899704955857">10 February 2012 14:14</a>
              </span>
            </div>
            <div class="comment-content">VM userland &gt; dozens Mpps with 2vCPU (L3 forwarding), dozens Gbps with 2vCPU (IPsec).  Scales linearly with number of cores assigned, no crypto engine, pure software.  8-) we have a booth at MWC (Hall 2 - 2B122)</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6681750003884305057">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Brent Salisbury</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6681750003884305057" href="#6681750003884305057">14 February 2012 05:34</a>
              </span>
            </div>
            <div class="comment-content">Great post! Love the graphics. I labbed up GRE tunnels on a couple OpenVswitch boxes with KVM to test out some V-2-V migrations. Still trying to wrap my head around scale and op management.<br />Notes from the setup for anyone needing a primer to test themselves in their environment.<br />http://wp.me/p1AOVJ-2O</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4677800369073856731">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4677800369073856731" href="#4677800369073856731">05 May 2014 18:15</a>
              </span>
            </div>
            <div class="comment-content">Hi<br /><br />Haven&#39;t tested but i think you can tag all the vlans to a VM in a standard virtual switch (not distributed)<br /><br />look here<br /><br />http://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=1004252<br /><br />Regards,</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="3579452442629709205">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3579452442629709205" href="#3579452442629709205">05 May 2014 18:22</a>
              </span>
            </div>
            <div class="comment-content">You can use VLAN tagging in vSwitch and vDS, but what we need here is the ability to have every port within a single port group in a different VLAN, and port attributes are only available in vDS (vSwitch has only port group attributes).</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
