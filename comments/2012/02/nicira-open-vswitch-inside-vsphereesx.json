{
  "comments": [
    {
      "date": "09 February 2012 11:50",
      "html": "Amazing insights here Ivan.<br /><br />You mention a limit of 409x ports in the port-group, tho I assume that this is a limit per Host/OVS? Now for sensible designs 409x hosts is more than enough, let alone 409x multiplied by a max of 32 hosts in a cluster, tho I can picture some instances where this may be beneficial.",
      "id": "7222783992569460667",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Kurt Bales",
      "profile": null,
      "pub": "2012-02-09T11:50:57.724+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "09 February 2012 12:00",
      "html": "That&#39;s the total number of VMs you can connect to the port group (across all hosts with the same vDS). They need per-VM VLAN to create a P2P link between VM and OVS-VM, and you only have 4K VLANs (and you can&#39;t recycle them because someone could vMotion a VM to another host).",
      "id": "1162605474426709770",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Ivan Pepelnjak",
      "profile": null,
      "pub": "2012-02-09T12:00:35.789+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "09 February 2012 13:04",
      "html": "Do you have a source for this claim? &quot;(you can\u2019t push more than a few Gbps through userland).&quot; My understanding and experience has been that ESX can push as much as the OS can handle, and easily saturates 10Gpbs with things like vMotion if the physical network can handle it. Obviously, different interfaces and kernels here. I&#39;m just wondering if perhaps you might be underestimating or downplaying the potential capabilities...",
      "id": "4438330385911839197",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Loren Gordon",
      "profile": null,
      "pub": "2012-02-09T13:04:34.539+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "09 February 2012 14:12",
      "html": "In my understanding and according to your previous blog post (http://blog.ioshints.info/2011/06/test-your-vmware-networking-skills.html ) we can&#39;t reuse VLANs even across different port groups, because port groups don&#39;t provide isolation.",
      "id": "9190931295733821752",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Anton Marchenko",
      "profile": null,
      "pub": "2012-02-09T14:12:48.251+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "09 February 2012 14:12",
      "html": "I don&#39;t (yet) have a consistent theory behind anecdotal evidence and a few data points ... and the fact that every time someone describes a VM-based networking appliance solution to me I ask &quot;and the performance is around a few Gbps&quot; ... and get &quot;yeah&quot; as an answer.<br /><br />Two data points I already wrote about:<br />http://blog.ioshints.info/2011/11/junipers-virtual-gateway-virtual.html<br />http://www.ipspace.net/Embrane_heleos:_scale-out_distributed_virtual_appliance",
      "id": "3101750156308528300",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Ivan Pepelnjak",
      "profile": null,
      "pub": "2012-02-09T14:12:54.866+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "09 February 2012 14:14",
      "html": "... also, please note that the &quot;few Gbps&quot; applies to VMs doing network-layer packet forwarding. Server VMs can easily saturate 10 Gbps uplink without consuming a whole core.",
      "id": "1979265374259469218",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Ivan Pepelnjak",
      "profile": null,
      "pub": "2012-02-09T14:14:50.534+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "09 February 2012 14:19",
      "html": "Good one. Absolutely true. You can however reuse them across different vSwitches/vDS (because they are independent bridging domains).<br /><br />Summary: create a totally new vDS for Nicira&#39;s needs.",
      "id": "3550732108206638851",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Ivan Pepelnjak",
      "profile": null,
      "pub": "2012-02-09T14:19:49.673+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "09 February 2012 14:59",
      "html": "Actually it means that to scale to more than 4K VMs you have create several vDS. Does it also mean that you have to provision a different OVS VM per vDS on the same ESX host or you can reuse the same VLANs across different vNIC trunks coming from different vDS to the same OVS VM?",
      "id": "5807267127922175894",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Anton Marchenko",
      "profile": null,
      "pub": "2012-02-09T14:59:57.495+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "09 February 2012 18:35",
      "html": "A traditional vSwitch is just as much a SPOF, right? In fact it&#39;s worse if it runs inside the VMkernel.",
      "id": "7101374179710136821",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "wmf",
      "profile": null,
      "pub": "2012-02-09T18:35:00.135+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "09 February 2012 20:04",
      "html": "Very Impressive break-down Ivan  ;)",
      "id": "1284421911644474340",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Tommy P",
      "profile": null,
      "pub": "2012-02-09T20:04:24.528+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "09 February 2012 21:12",
      "html": "Thanks for this clarification, it wasn&#39;t until I read this that it clicked about the VLAN usage and p2p to the OVS VM. Originally I was thinking like Kurt if this was per host. But per 32 host cluster/VDS makes sense and does scale pretty well. ~126-7 VMs per host isn&#39;t too shabby.",
      "id": "7670120774594923262",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "DanielG",
      "profile": null,
      "pub": "2012-02-09T21:12:01.580+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "10 February 2012 02:04",
      "html": "Nicira + Open vSwitch + VMware = DOA (unfortunately)",
      "id": "188939034988149998",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Brad Hedlund",
      "profile": null,
      "pub": "2012-02-10T02:04:29.211+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "10 February 2012 02:39",
      "html": "Agree 100%.",
      "id": "66805272231077057",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "cloudtoad",
      "profile": null,
      "pub": "2012-02-10T02:39:12.241+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "10 February 2012 09:12",
      "html": "This was true until x86 leaders came with new data plane architecture. We are a proved example that you can deliver dozens of Gbps with virtual networking appliance on userland. also very important, independent from he packet size (so consider the pps benchmarks!). We delivered all around the world high performance SDN for mobile core network and are ramping up now on the Cloud space...",
      "id": "11482377547165107",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "David Le Goff",
      "profile": null,
      "pub": "2012-02-10T09:12:13.661+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "10 February 2012 09:43",
      "html": "Sounds absolutely interesting. If you&#39;re willing to tell me more, please contact me directly:<br /><br />http://www.ipspace.net/Contact",
      "id": "2992628193466207124",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Ivan Pepelnjak",
      "profile": null,
      "pub": "2012-02-10T09:43:02.240+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "10 February 2012 10:01",
      "html": "done  :)",
      "id": "7632673379150605779",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "David Le Goff",
      "profile": null,
      "pub": "2012-02-10T10:01:36.101+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "10 February 2012 13:58",
      "html": "I wish I had 10GbE to the servers in my lab...this would be a dead simple test. Set up a test VM configured as a router and see what we get!",
      "id": "7304362985981442708",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Loren Gordon",
      "profile": null,
      "pub": "2012-02-10T13:58:44.076+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "10 February 2012 14:14",
      "html": "VM userland &gt; dozens Mpps with 2vCPU (L3 forwarding), dozens Gbps with 2vCPU (IPsec).  Scales linearly with number of cores assigned, no crypto engine, pure software.  8-) we have a booth at MWC (Hall 2 - 2B122)",
      "id": "1881158899704955857",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "David Le Goff",
      "profile": null,
      "pub": "2012-02-10T14:14:06.283+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "date": "14 February 2012 05:34",
      "html": "Great post! Love the graphics. I labbed up GRE tunnels on a couple OpenVswitch boxes with KVM to test out some V-2-V migrations. Still trying to wrap my head around scale and op management.<br />Notes from the setup for anyone needing a primer to test themselves in their environment.<br />http://wp.me/p1AOVJ-2O",
      "id": "6681750003884305057",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Brent Salisbury",
      "profile": null,
      "pub": "2012-02-14T05:34:53.393+01:00",
      "ref": "4582942090096066804",
      "type": "comment"
    },
    {
      "comments": [
        {
          "date": "05 May 2014 18:22",
          "html": "You can use VLAN tagging in vSwitch and vDS, but what we need here is the ability to have every port within a single port group in a different VLAN, and port attributes are only available in vDS (vSwitch has only port group attributes).",
          "id": "3579452442629709205",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2014-05-05T18:22:59.767+02:00",
          "ref": "4677800369073856731",
          "type": "comment"
        }
      ],
      "date": "05 May 2014 18:15",
      "html": "Hi<br /><br />Haven&#39;t tested but i think you can tag all the vlans to a VM in a standard virtual switch (not distributed)<br /><br />look here<br /><br />http://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=1004252<br /><br />Regards,",
      "id": "4677800369073856731",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Anonymous",
      "profile": null,
      "pub": "2014-05-05T18:15:04.892+02:00",
      "ref": "4582942090096066804",
      "type": "comment"
    }
  ],
  "count": 21,
  "id": "4582942090096066804",
  "type": "post",
  "url": "2012/02/nicira-open-vswitch-inside-vsphereesx.html"
}