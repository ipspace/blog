<div class="comments post" id="comments">
  <h4>18 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="120678451599516821">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Dirk</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c120678451599516821" href="#120678451599516821">03 July 2012 10:17</a>
              </span>
            </div>
            <div class="comment-content">I haven&#39;t deepdived into this topic, so i&#39;m probably throwing something around here, but couldn&#39;t MPLS-TP be used to emulate a VNI? Also mVPN technology is evolving. If mLDP is used, a MP2MP can be setup and no IP Multicast is required for L2 flooding. Also PBB-EVPN could solve the multihoming?</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6463523361620286365">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6463523361620286365" href="#6463523361620286365">03 July 2012 13:34</a>
              </span>
            </div>
            <div class="comment-content">Why not just do plain MPLS?<br /><br />D</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="3539306931579037157">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3539306931579037157" href="#3539306931579037157">06 July 2012 19:45</a>
              </span>
            </div>
            <div class="comment-content">See the &quot;scalability&quot; paragraph in this blog post: http://blog.ioshints.info/2012/03/mplsvpn-in-data-center-maybe-not-in.html</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="721984996959291129">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://thewisdomofkingbob.com/" rel="nofollow">Eugene</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c721984996959291129" href="#721984996959291129">11 July 2012 12:23</a>
              </span>
            </div>
            <div class="comment-content">Thank you for redirecting</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7377394828445673952">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/02281533787106135974" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7377394828445673952" href="#7377394828445673952">03 July 2012 14:12</a>
              </span>
            </div>
            <div class="comment-content">Hi Dirk,<br />Interesting points. I agree mLDP can potentially perform a similar role with a L3 VPN setup. VMkernel in a host can act as a PE router with the IP network running LDP. However, it will also require the VMkernel to run BGP. I think even PBB-VPLS would be a viable option. We are running PBB-VPLS in a service provider environment.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3306564081004765235">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/15412047994121954944" rel="nofollow">Derick Winkworth</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3306564081004765235" href="#3306564081004765235">04 July 2012 13:56</a>
              </span>
            </div>
            <div class="comment-content">The benefit of doing MPLS is obvious:  Immediate unification of virtual compute and networking using a standard, mature and fairly well understood protocol.  <br /><br />Also, you don&#39;t have to run LDP or VPNv4 on the hypervisor, a controller could do that.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="19136036538687269">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c19136036538687269" href="#19136036538687269">06 July 2012 19:46</a>
              </span>
            </div>
            <div class="comment-content">Totally agree. As I wrote &quot;Nicira could do it pretty quickly should they find a customer who would be willing to pay for it&quot; ... maybe I was not explicit enough ;)</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4380249832267425376">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4380249832267425376" href="#4380249832267425376">08 July 2012 15:18</a>
              </span>
            </div>
            <div class="comment-content">Nice job Ian of extracting out the benefits and challenges of the RFC4023 solutions that exist, and are being deployed today, which I am a fan of, especially in the WAN for branch back-haul.<br /><br />A very good add-on discussion to the post would be looking at LISP, and the abstracted control-plane it offers.  Once multicast is supported, there is no reason why L2-over-IP could not be leveraged.  It natively uses IP-over-IP (UDP), and has the control-plane to scale (analogous to DNS).  An interesting topic for sure as LISP evolves.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3812932304135234188">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/15493370358037866116" rel="nofollow">Aldrin</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3812932304135234188" href="#3812932304135234188">06 August 2012 04:06</a>
              </span>
            </div>
            <div class="comment-content">As far as I understand, VXLAN, NVGRE and any tunneling protocol that use global ID in the data plane cannot support PVLAN functionality. I&#39;m told the way to solve this issue is to use edge virtual firewall (like iptables or vGW) which can be difficult if the subnet address space isn&#39;t carved up in maskable blocks (or ranges) by user groups.<br /><br />Furthermore, if edge virtual firewalls are inevitably required to do basic network-level segmentation, then I see no reason why a private cloud with no overlapping address space needs any more than a single all spanning virtual network with edge virtual firewalls to implement all segmentation (network and application level granularity).</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="8287743209286994892">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8287743209286994892" href="#8287743209286994892">06 August 2012 09:10</a>
              </span>
            </div>
            <div class="comment-content">Ouch. Good one. Let me mull this one over.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2918777399110938105">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2918777399110938105" href="#2918777399110938105">21 August 2012 16:42</a>
              </span>
            </div>
            <div class="comment-content">Another avenue to pursue regarding virtualized resources, OTV.<br />It&#39;s a rather interesting time to see progression and maturity of network technology to create new solutions to the virtualized data centers.<br /><br />http://blog.ine.com/2012/08/17/otv-decoded-a-fancy-gre-tunnel/<br /><br />...&quot;From a high level overview, OTV is basically a layer 2 over layer 3 tunneling protocol. In essence OTV accomplishes the same goal as other L2 tunneling protocols such as L2TPv3, Any Transport over MPLS (AToM), or Virtual Private LAN Services (VPLS). For OTV specifically this goal is to take Ethernet frames from an end station, like a virtual machine, encapsulate them inside IPv4, transport them over the Data Center Interconnect (DCI) network, decapsulate them on the other side, and out pops your original Ethernet frame.&quot;</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="1888351339359719497">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1888351339359719497" href="#1888351339359719497">21 August 2012 17:13</a>
              </span>
            </div>
            <div class="comment-content">OTV is interconnecting two L2 networks, not providing virtual networks like VXLAN or NVGRE. It does not fit into the same picture.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3116496573805093979">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/05212570875946340082" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3116496573805093979" href="#3116496573805093979">01 September 2012 08:22</a>
              </span>
            </div>
            <div class="comment-content">I prefer <br />1/offload the network function from hypervisor to physical access switch, as what VM-FEX does<br />2/ physical access switch support VXLAN<br />3/ decouple the control plane layer to manage VXLAN.<br /><br />it&#39;ll solve the VM to VM, VM to physical, physical to physical traffic, and VLAN limitations for the whole data center, and decrease quantities of VXLAN switches.<br /><br />Cooper Wu/http://www.linkedin.com/pub/cooper-wu/4b/79a/bb</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="3919607317128529381">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3919607317128529381" href="#3919607317128529381">01 September 2012 09:44</a>
              </span>
            </div>
            <div class="comment-content">While this makes sense from network architecture perspective, it tightly couples hypervisor and ToR switches and makes deployment/orchestration way more complex, so I don&#39;t expect to see this architecture widely deployed.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2335152974764986757">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/05212570875946340082" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2335152974764986757" href="#2335152974764986757">01 September 2012 12:19</a>
              </span>
            </div>
            <div class="comment-content">This comment has been removed by the author.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3021237158728991411">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/05212570875946340082" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3021237158728991411" href="#3021237158728991411">01 September 2012 12:20</a>
              </span>
            </div>
            <div class="comment-content">Thank you Ivan , <br /><br />From cloud perspective , you&#39;ll disagree with my option, I believe you prefer putting all service within the virtualization framework ,nothing to do with physical network infrastructure. <br /><br />Network admin will be going mad , since all they can see are tunnel packets , they are of no help if there is problem.<br /><br />It&#39;s true that at current stage, there are limitations and complex to orchestrate and tightly couple hypervisor with ToR. : )<br /><br />If combining with O/F , hypervisor tightly couples with control plane servers/clusters , not ToR switch. it&#39;ll be more reasonable.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="5650763962106122937">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5650763962106122937" href="#5650763962106122937">13 June 2016 07:19</a>
              </span>
            </div>
            <div class="comment-content">Much water has flown under the bridge since you wrote this but given the direction (think VXLAN GPE, multiple control planes, etc), how about simply using GRE+UDP ? At the very least, it would look and feel familiar for everyone involved (developers, operators, etc) and one less encap format to learn!</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="7841687338527914817">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7841687338527914817" href="#7841687338527914817">13 June 2016 09:00</a>
              </span>
            </div>
            <div class="comment-content">VXLAN has a slight advantage over GRE (or NVGRE) - it can use the source UDP port to improve load balancing across leaf-and-spine fabrics.<br /><br />Whatever the reason, the whole industry has standardized on VXLAN (even Microsoft will support it in the next Hyper-V release... or maybe it&#39;s already shipping?), so we better get used to it ;)</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
