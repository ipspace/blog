<div class="comments post" id="comments">
  <h4>9 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="5071868212298393725">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://packetpushers.net/author/siveson" rel="nofollow">Steven Iveson</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5071868212298393725" href="#5071868212298393725">06 November 2014 10:59</a>
              </span>
            </div>
            <div class="comment-content">Ah, a subject close to my heart. Load balancing isn&#39;t for the server guys now is it? And we all know how conservative those network guys are. <br /><br />In all seriousness, this really is a matter of fear of the unknown and an unwillingness to learn about the possibilities and then trust them in production. I hope this changes as network engineers are further exposed to both Linux and virtual appliances in general.<br /><br />Other products you could add to your list are;<br /><br />* Zen Load Balancer<br />* Balance<br />* Pound</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7998832387488193601">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/04540820319538497395" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7998832387488193601" href="#7998832387488193601">06 November 2014 11:02</a>
              </span>
            </div>
            <div class="comment-content">Hi Ivan.<br /><br />I donÂ´t agree 100% ...  Here in denmark, nginx and haproxy is used ALOT.<br /><br />So the company i work in we do shared hosting apache,iis etc. All of our competitors also use some sort of opensource load balancing ( mostly nginx )<br /><br />We try to not use netscaler, f5 etc. Because of price but also creating a dedicated hardware/vm loadbalancer moves configuration away from the APP people to the network people :)<br />Trust me the APP people way! better at load balancing their own APP.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="5066483775213852900">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5066483775213852900" href="#5066483775213852900">06 November 2014 12:47</a>
              </span>
            </div>
            <div class="comment-content">Yeah, I would expect to see plenty of open-source load balancing solutions in ISP/hosting environments. Commercial load balancers are just too expensive to be justified there.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="8667394081059218921">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8667394081059218921" href="#8667394081059218921">06 November 2014 12:52</a>
              </span>
            </div>
            <div class="comment-content">Last time I looked, VMware vShield Edge (got to love that capitalisation!) is in fact HAProxy under the hood. I learnt this when raising a support case and watching VMware troubleshoot it. So, more people are using it than may realise they are!</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="5088228601170908238">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/04441771667073544925" rel="nofollow">Anders</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5088228601170908238" href="#5088228601170908238">06 November 2014 18:23</a>
              </span>
            </div>
            <div class="comment-content">I personally do favor both IPVS and nginx, but both in their respective fields and taking their respective strengths and weaknesses into account.<br /><br />Commercial load balancers also often just don&#39;t offer exactly what&#39;s needed. For example, we&#39;re running loadbalancers who do perform highlevel backend availability checks and accordingly announce (or withdraw) a specific route for internal anycasted IP addresses. By installing those systems in multiple data centers, this results in a very high availability and low-latency. At worst, a failed service in one DC is automatically provided by the same service from a different DC - at some additional latency, but still accessible.<br />Most commercial loadbalancers in such a situation simply would like to pretend to be a DNS server and reply with low-TTL DNS-RRs - which consistently fails with Java applications (who ignored DNS-TTLs for years now), let alone give no solution if the service you&#39;re trying to load balance is your DNS service.<br /><br />Please also don&#39;t forget about IPVS: Linux IP Virtual Server does look more like &quot;typical&quot; L2/L3-level load balancers and uses techniques like direct server return (&quot;gatewaying&quot; or &quot;direct routing&quot; in IPVS lingo). A smallish box with a 100 Mbit network connection can easily handle Gbits of traffic with dozens of backend servers - as any outgoing traffic (replies) doesn&#39;t pass the loadbalancer at all.<br /><br />Proxy-based systems like nginx and haproxy are also very capable in terms of accepting thousands of connections in parallel, which may give you some relief if you&#39;re accustomed to an web servers who are easily taken by slowloris-attacks. nginx/haproxy do also terminate and create new backend connections, making them extremely flexible on your network: your backend servers cound be anywhere, there are no restrictions Have your balancer on your network, some backend nodes on AWS, some backend nodes in a colo somewhere around your corner, it doesn&#39;t matter (ignoring latency). Nginx/haproxy also do offer tons of L7-features which may result in a more complex configuration, but a very high benefit on the actual application. For example, static content could be served from a specifically tuned backend farm, while dynamic content is served by a different farm.<br />However, doing so does have impact on deployment and where or how to debug errors. If operations and development are a close team and share their knowledge, such setups do work out fine - otherwise, it may be hard to draw a line where and how some issue is going to be addressed. And some implementation and design issues do open up new questions.<br /><br />Most interesting projects are where multiple balancing solutions needed to be united: proxy-based systems couldn&#39;t handle the bandwidth, packet-based systems couldn&#39;t deliver the needed features. Trying to to that with a commercial load balancer can be a task of its own.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3163603297389174052">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3163603297389174052" href="#3163603297389174052">06 December 2014 16:52</a>
              </span>
            </div>
            <div class="comment-content">(At the risk of necroposting...)<br /><br />The place I currently work in would likely count as an &quot;open source shop&quot; but sends the bulk of its traffic through a commercial load balancer.  However, most of the *new* traffic on the network is going through HAProxy.  New *clients* get HAProxy installed on them - the servers run health checks locally that write status to ZooKeeper, the clients discover what services are available by reading from ZooKeeper and configure HAProxy; they then connect to HAProxy on localhost to reach the servers.<br /><br />HAProxy also has the advantage of better health checks for PostgreSQL than our commercial load balancer, but that&#39;s an aside.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="107815357502593932">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c107815357502593932" href="#107815357502593932">06 December 2014 17:06</a>
              </span>
            </div>
            <div class="comment-content">Fantastic - just the right way to go ;)) Thanks for sharing!</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7443871311565701089">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7443871311565701089" href="#7443871311565701089">18 January 2015 13:42</a>
              </span>
            </div>
            <div class="comment-content">IÂ´m just curious. What kind of firewalls are being used in your datacenters? Is it the usual pair of Cisco/Fortigate/PaloAlto/Checkpoint/wahtever devices or does anyone take something like pfsense?</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="5422413964140233201">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5422413964140233201" href="#5422413964140233201">06 February 2015 10:55</a>
              </span>
            </div>
            <div class="comment-content">Typically from what I have seen:<br /><br />-ASA as internal FW, SRX for external network... sometimes DMZ are protected by checkpoint or SRX.<br />-Fortigate for branch or regional offices<br />-PA haven&#39;t seen in my enterprise NW experience of 6 years ^_^</div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
