<div class="comments post" id="comments">
  <h4>16 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="7611221732328654710">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7611221732328654710" href="#7611221732328654710">19 February 2014 14:15</a>
              </span>
            </div>
            <div class="comment-content">For WAN edge, and in fact any routers short of those needing a full table (or to be fair, MPLS, but that&#39;s a software problem) why not just use those same L3 switches. In many cases these days the large routers are almost the same silicon, just with external lookup RAM, and sometimes buffer RAM.<br />Zero watts is a lot cheaper than any Intel server.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="4842559229262938517">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4842559229262938517" href="#4842559229262938517">19 February 2014 16:47</a>
              </span>
            </div>
            <div class="comment-content">I&#39;d imagine there&#39;s an assumption that you&#39;d have the servers there already to run/serve applications.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="8942436087298746511">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8942436087298746511" href="#8942436087298746511">19 February 2014 17:04</a>
              </span>
            </div>
            <div class="comment-content">If those same L3 switches support all the WAN edge functionality you need, you&#39;re absolutely right.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7480389381020060038">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7480389381020060038" href="#7480389381020060038">19 February 2014 14:38</a>
              </span>
            </div>
            <div class="comment-content">This would mostly fall under the psychological category, but I prefer to keep my network eggs out of the server administrator&#39;s basket.  It&#39;s not that this can&#39;t work technically, but I&#39;ve seen storage and configuration issues take down virtual clusters more than once.<br />So far, it has been better for me to really on my network team to maintain network hardware than to transfer responsibility to another team.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="3241878881185335386">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3241878881185335386" href="#3241878881185335386">19 February 2014 17:05</a>
              </span>
            </div>
            <div class="comment-content">I did mention in one of the previous posts (follow the links) that you SHOULD use a dedicated network services cluster.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="707098758507305045">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c707098758507305045" href="#707098758507305045">19 February 2014 17:07</a>
              </span>
            </div>
            <div class="comment-content">I&#39;m sure they could say the same about the network. I&#39;d jump at the chance to learn some of their skills and pass on some of mine. Think like that for too much longer and you&#39;ll be limiting your career.<br /><br />Steven Iveson</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="398869920276958768">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c398869920276958768" href="#398869920276958768">20 February 2014 14:37</a>
              </span>
            </div>
            <div class="comment-content">Ivan, why use a dedicated cluster? So long the guest has sufficient resources, it shouldn&#39;t really matter on which cluster it runs.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1322587809847609069">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1322587809847609069" href="#1322587809847609069">20 February 2014 18:13</a>
              </span>
            </div>
            <div class="comment-content">You _might_ need a dedicated cluster for layer 8-10 reasons (see above).<br /><br />You _should_ consider a dedicated cluster (if the size of the cloud warrants it) because there&#39;s a significant difference between network services workloads and traditional server workloads, potentially requiring different virtualization ratio or server configuration.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4866356914983677577">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/06036116499201821433" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4866356914983677577" href="#4866356914983677577">20 February 2014 19:54</a>
              </span>
            </div>
            <div class="comment-content">DevOps has broken down sysadmin silos in at least some organizations and I think the same will happen on the NetOps side.  Service agility and automation is going to override the traditional Network/Server/etc. roles especially if the network functions become virtualized and commoditized.  It&#39;s all about coming up with proper templates and methods defined by the networking guys.  <br /><br />Now whether it can be done on x86 hardware or not really just comes down to bandwidth needs.   <br /><br />There are some interesting devices out there now like the Pluribus server/switch thing which kind of blur the lines by integrating a wire speed backplane/switch with actual server hardware and making it open and extensible.  Could be a great NFV platform.  </div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="8805873146427157762">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8805873146427157762" href="#8805873146427157762">19 February 2014 16:43</a>
              </span>
            </div>
            <div class="comment-content">I know the answer but anyway, why isn&#39;t this what everyone is doing? The benefits are manyfold, the drawbacks are almost non-existant. Throw in a virtualised firewall, load balancer etc and the savings and simplification are enormous. <br /><br />Steven Iveson</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="8903037105220432783">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8903037105220432783" href="#8903037105220432783">19 February 2014 17:30</a>
              </span>
            </div>
            <div class="comment-content">&quot;My stuff!&quot; Unfortunately, too many still hold that their niche or technology is what is important. Rather, the delivery of services in the most streamlined, secure, and available method is the key. <br /><br />If you can have an honest discussion (w/o the turf wars), our datacenters would shrink dramatically along with the operational overhead. </div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4653704278009087102">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/08303297647166529377" rel="nofollow">Wick</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4653704278009087102" href="#4653704278009087102">20 February 2014 10:32</a>
              </span>
            </div>
            <div class="comment-content">Putting all eggs into one basket would be unwise in this case.<br />The chances of a large scale impact of a common-mode is too big a risk for many organisations which rely on the network as a critical service.<br /><br />Imagine the virtualised edge router, or edge firewall encountering the hypervisor bug which would bring down not just the virtualised servers, but bring the network to its knees.<br />I can think of a few such bugs - VMware&#39;s e1000 high-load crash bug, VMXNet3 inability to initiate pptp tunnels, Win2k12R2 purple screen of death (doesn&#39;t mean it won&#39;t happen to other new network OS) , to name just a few.<br /></div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6434067340223069848">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6434067340223069848" href="#6434067340223069848">20 February 2014 17:46</a>
              </span>
            </div>
            <div class="comment-content">&quot;If everything is getting virtualized, why do I have to put in more physical hours each day to keep up with the complexity created by it.&quot; - Old jungle saying.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="7139169981274657833">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7139169981274657833" href="#7139169981274657833">21 February 2014 15:19</a>
              </span>
            </div>
            <div class="comment-content">Because your doing it wrong.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1529102841952236452">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/08239425502968031861" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1529102841952236452" href="#1529102841952236452">21 February 2014 15:35</a>
              </span>
            </div>
            <div class="comment-content">Most of what I&#39;m seeing in the field when I propose this idea is outright resistance; most of the reasons are related to exposing the hypervisor directly to the Internet and receiving a malformed packet. The scenario mentioned in the article, where one uses the PCI-passthrough feature to give a VM direct access to a NIC, should provide more security. The downside is that something like the CSR may not have drivers for the physical NIC.<br /><br />One thing I haven&#39;t considered is the security consequence of the PCI-passthrough method. Does the hypervisor still have some kind of wedge in there? We should definitely talk about it!</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="4251580393025726383">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4251580393025726383" href="#4251580393025726383">24 February 2014 20:09</a>
              </span>
            </div>
            <div class="comment-content">I have heard that L3 switches and software/vm-based routers do not have as robust queueing on their interfaces when compared to a dedicated hardware router. FWIW, this information came from a vendor of those dedicated hardware routers, so there may be some sales hype in there. But they said if you have an elaborate QOS policy, some policy-based routing, some intricate ACLs, and other features, you will not be happy with the vm or the software solution. We haven&#39;t had an opportunity to test this statement</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
