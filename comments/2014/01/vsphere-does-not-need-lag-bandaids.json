{
  "comments": [
    {
      "date": "20 January 2014 14:08",
      "html": "Hi Ivan,<br /><br />What&#39;s the max reasonable oversubscription you recommend? Would Chassis Trunking from Brocade be interesting as Aggregation L3 Switch Solution ?<br /><br />Thanks",
      "id": "5123359976800585243",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Pirmin",
      "profile": "http://easyipv6.wordpress.com",
      "pub": "2014-01-20T14:08:17.252+01:00",
      "ref": "8227426513243649953",
      "type": "comment"
    },
    {
      "date": "20 January 2014 14:57",
      "html": "There&#39;s no &quot;reasonable&quot; number - you should know your traffic (and use 1:3 when you&#39;re clueless).",
      "id": "348926353743044565",
      "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
      "name": "Ivan Pepelnjak",
      "profile": "https://www.blogger.com/profile/13457151406311272386",
      "pub": "2014-01-20T14:57:51.575+01:00",
      "ref": "8227426513243649953",
      "type": "comment"
    },
    {
      "comments": [
        {
          "date": "20 January 2014 16:40",
          "html": "... and waste half the ports and half the switching bandwidth. Congratulations.",
          "id": "7631628414466800032",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2014-01-20T16:40:36.830+01:00",
          "ref": "7878373539733058427",
          "type": "comment"
        }
      ],
      "date": "20 January 2014 16:16",
      "html": "Okay, so just set all hosts to prefer port 1, problem solved..",
      "id": "7878373539733058427",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Anonymous",
      "profile": null,
      "pub": "2014-01-20T16:16:31.796+01:00",
      "ref": "8227426513243649953",
      "type": "comment"
    },
    {
      "date": "22 January 2014 06:32",
      "html": "Thanks for taking the time to go deeper into this topic, Ivan. Your 5K/2K architecture seems most common in the field, although many 10 Gb installs opt to use a 5K as the ToR switch. Perhaps this gives a further nod to the 1000v&#39;s vPC pinning using the &quot;free&quot; edition?",
      "id": "4537489837977934845",
      "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
      "name": "Unknown",
      "profile": "https://www.blogger.com/profile/07527433803679583114",
      "pub": "2014-01-22T06:32:53.614+01:00",
      "ref": "8227426513243649953",
      "type": "comment"
    },
    {
      "date": "26 January 2014 11:30",
      "html": "LACP is included in the free edition ov Nexus 1000v. There is no reason NOT to use LACP for your vhost uplinks except if you &quot;hate&quot; Cisco, which isn&#39;t an argument.<br /><br />Personally I would much happier if the Nexus 1000v implemented Fabricpath alleviating the need for any kind of LAG on the vhost uplinks. But this is a logical and efficient way to connect vhosts to a network so I&#39;m not expecting Cisco to go that way!",
      "id": "2505230899539614160",
      "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
      "name": "Unknown",
      "profile": "https://www.blogger.com/profile/08806122907850134756",
      "pub": "2014-01-26T11:30:31.539+01:00",
      "ref": "8227426513243649953",
      "type": "comment"
    },
    {
      "comments": [
        {
          "date": "28 January 2014 07:22",
          "html": "That&#39;s perfectly fine - as long as the 40 Gbps E-W bandwidth is enough, and you have the extra ports. Once you get closer to the physical limits, optimization becomes more important.",
          "id": "8698079283562739308",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2014-01-28T07:22:07.223+01:00",
          "ref": "382747200525489610",
          "type": "comment"
        }
      ],
      "date": "28 January 2014 07:17",
      "html": "The ToRs can get connected with a cheap 40 Gbps twinax cable. The extra switch hop is less than a microsecond of latency.  Who cares about obtimizing that?",
      "id": "382747200525489610",
      "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
      "name": "Edmund Roche-Kelly",
      "profile": "https://www.blogger.com/profile/17478248609388388279",
      "pub": "2014-01-28T07:17:22.017+01:00",
      "ref": "8227426513243649953",
      "type": "comment"
    },
    {
      "comments": [
        {
          "date": "29 January 2014 07:21",
          "html": "Thanks for sharing this one. You need &quot;portfast&quot; or an equivalent on the switch to prevent the ports from going through the &quot;listening&quot; phase.",
          "id": "6397986783108811953",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2014-01-29T07:21:27.975+01:00",
          "ref": "8550192354905795378",
          "type": "comment"
        },
        {
          "date": "09 February 2014 20:05",
          "html": "Pieter check your vSwitch Failback setting. To avoid such failure scenario you may want to set it to No.<br /><br />To understand the issue, you may want to read this blog post: http://frankdenneman.nl/2010/10/22/vswitch-failover-and-high-availability/",
          "id": "8303561524363499497",
          "image": "https://resources.blogblog.com/img/blank.gif",
          "name": "Anonymous",
          "profile": null,
          "pub": "2014-02-09T20:05:46.409+01:00",
          "ref": "8550192354905795378",
          "type": "comment"
        }
      ],
      "date": "28 January 2014 21:48",
      "html": "We bumped into a problem that cause 30 second outage, probably spanning tree. <br />Vswitch dual connected to N4k&#39;s that have multiple up links to vpc N5k pair. <br /><br />When we reload a N4k, the VM fail over is perfect, but when the N4k comes back we lose half the VM&#39;s for  30th. <br /><br />My understanding is that Vswitch starts using  new up link immediately as physical port comes up but spanning tree on unlink ports is still learning topology. <br />",
      "id": "8550192354905795378",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Pieter E Smit",
      "profile": null,
      "pub": "2014-01-28T21:48:36.018+01:00",
      "ref": "8227426513243649953",
      "type": "comment"
    },
    {
      "comments": [
        {
          "date": "29 January 2014 07:22",
          "html": "MPIO is definitely better than LACP. Separate (logical) interfaces with Adapter FEX might be the answer.",
          "id": "8281641123265870614",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2014-01-29T07:22:18.006+01:00",
          "ref": "1124482280152160521",
          "type": "comment"
        }
      ],
      "date": "28 January 2014 23:01",
      "html": "What about iSCSI traffic?<br />Isn&#39;t MPIO to be preferred over LACP since MPIO can use all the links simultaneously?",
      "id": "1124482280152160521",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Anonymous",
      "profile": null,
      "pub": "2014-01-28T23:01:12.536+01:00",
      "ref": "8227426513243649953",
      "type": "comment"
    },
    {
      "comments": [
        {
          "date": "12 September 2014 15:31",
          "html": "Dual-homed FEX-es might be the best option, as they ensure the load from server uplinks is (somewhat) evenly distributed across both switches.<br /><br />Never went into the details of how dual-homed FEXes handle upstream switch failure, but AFAIK it&#39;s not a SPOF.",
          "id": "8554885826838975374",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2014-09-12T15:31:47.479+02:00",
          "ref": "4270154820213061423",
          "type": "comment"
        }
      ],
      "date": "11 September 2014 19:17",
      "html": "Hi Ivan,<br /><br />I&#39;m currently working on an environment where VMware ESXi servers are dual-homed (and statically LAGged) to a pair of FEX 2232. These extenders are currently single-homed to a pair of Nexus 5548 on vPC. I want to move away from the LAGs at the server level but by doing this I&#39;ll start running into the problems you describe above (potential over-subscription of the vPC peer-link, etc.). So, dual-homing the FEXes seems like the logical thing to do.<br /><br />I&#39;ve been doing some research into the reasons why I would like to avoid dual-homing the FEXes and so far I&#39;ve come up with three: <br /><br />a) Config of the FEX&#39;s interfaces need to be defined in both Nexus... for instance port 100/1/25 exists in both parent Nexus, so the config needs to be consistent across both --&gt; not a big deal in my book... plus using config-sync and switch profiles should help simplify or avoid this problem<br /><br />b) The total limit of FEXes supported by the vPC is cut in half, since every Nexus parent switch will be connected to all the FEXes --&gt; not a big deal either for the environment I&#39;m working on<br /><br />c) On a single-homed deployment every FEX is dependant upon a single parent Nexus. If the parent Nexus &quot;A&quot; fails or crashes, only the &quot;A&quot; FEXes will be affected. On a dual-homed deployment all the FEXes are dependant upon both parent Nexus... under certain circumstances this could be defined as a SPOF. Of course an argument could be had regarding the vPC concept as being a SPOF itself... at some point you have to trust the vendor and its code, right?<br /><br />What&#39;s your take on these problems, particularly on the third one. Do you think there are any other limitations worth considering before migrating from a single-homed to a dual-homed config?<br /><br />Thanks!",
      "id": "4270154820213061423",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Alberto",
      "profile": null,
      "pub": "2014-09-11T19:17:10.028+02:00",
      "ref": "8227426513243649953",
      "type": "comment"
    }
  ],
  "count": 15,
  "id": "8227426513243649953",
  "type": "post",
  "url": "2014/01/vsphere-does-not-need-lag-bandaids.html"
}