comments:
- comments:
  - date: 20 August 2014 12:05
    html: 'Unicast-mode VXLAN has centralized control plane (VSM) and thus represents
      an interesting failure scenario: what happens if the DCI link fails? <br /><br
      />There are only two alternatives:<br />* You eventually lose half of the VXLAN
      subnet (because VEMs lose connectivity to VSM) - best case its topology would
      be frozen;<br />* You have redundant VSMs and they go into split-brain mode.<br
      /><br />Not fun.'
    id: '6764555675324079286'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2014-08-20T12:05:11.816+02:00'
    ref: '3318923527079971901'
    type: comment
  - date: 20 August 2014 15:49
    html: I think thats only partly true though. In the event the VSM goes away the
      VEMs still have their mapping (for at least some time). I suspect BUM traffic
      would be broken, but normal unicast would live on, assuming you don&#39;t need
      to change any port-profiles or bring up new hosts etc.! I agree, its certainly
      not good for DCI, just playing devils advocate for fun!<br /><br />One last
      question -- assuming you did deploy redundant VSMs in each of two data centers,
      if the DCI link fails is it really that big of a deal for the VSMs to go split-brained?
      If they can maintain operations within each DC that would be better than being
      totally broken I would think.
    id: '5229283044506288672'
    image: https://resources.blogblog.com/img/blank.gif
    name: Carl
    profile: http://comeroutewithme.com
    pub: '2014-08-20T15:49:00.712+02:00'
    ref: '3318923527079971901'
    type: comment
  - date: 20 August 2014 15:52
    html: '&quot;normal unicast would live on, assuming you don&#39;t need to change
      any port-profiles or bring up new hosts etc.&quot; ... or move a VM or use DRS
      or HA or ...<br /><br />&quot; is it really that big of a deal for the VSMs
      to go split-brained&quot; ... and what happens when the DCI link comes back?'
    id: '4635450117407435160'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2014-08-20T15:52:38.658+02:00'
    ref: '3318923527079971901'
    type: comment
  - date: 20 August 2014 17:16
    html: Hah yeah, again, not saying it would be a good idea :)<br /><br />I have
      no idea how a split brained VSM would react (failure of a single VSM and re-joining
      is pretty smooth though), perhaps I&#39;ll have and excuse to lab it up now!
    id: '8981021158448189615'
    image: https://resources.blogblog.com/img/blank.gif
    name: Carl
    profile: http://comeroutewithme.com
    pub: '2014-08-20T17:16:26.709+02:00'
    ref: '3318923527079971901'
    type: comment
  date: 19 August 2014 16:06
  html: Interesting to read the comments in the &#39;VXLAN is not a Data Center Interconnect&#39;
    post from 2012 :)<br />Still no control-plane, still basically the same landscape
    with maybe just a bit broader support. <br /><br />I&#39;d be interested to hear
    your thoughts on unicast-mode VXLAN vs &#39;standard&#39; (draft) VXLAN when it
    comes to layer 2 extension (while I&#39;m 100% with you that the &#39;requirement&#39;
    for layer 2 extension is a mostly/entirely BS requirement). I&#39;m not fully
    versed in how all the magic happens, but I would assume that the VSM acts as some
    sort of control plane, and helps to create the VTEP to MAC mappings... I would
    suspect that this would help to alleviate some of the MAC flooding issues that
    aren&#39;t (adequately) addressed in multicast mode? As a further bandaid (definitely
    not a &#39;real&#39; solution) I wonder about the effectiveness of implementing
    storm-control on port-profiles in the 1000v as an extra method to limit broadcast
    storm type traffic within the bridge-domain. <br /><br />Of course none of this
    addresses the traffic trombone issues, or lack of active/active gateway type functionality
    (outside of NSX I guess? Also to an extent ACI I suppose). Of course there are
    also some scale limitations to consider with unicast-mode VXLAN -- particularly
    surrounding the gateway functionality.<br /><br />Lastly, although this would
    *never* fly in a production environment, for kicks you could deploy a CSR with
    an interface in a VXLAN, and use it to extend the VXLAN to a VLAN in another data-center...
    its filthy, but it works... in a lab... :)<br /><br />Carl
  id: '3318923527079971901'
  image: https://resources.blogblog.com/img/blank.gif
  name: Carl
  profile: https://comeroutewithme.wordpress.com
  pub: '2014-08-19T16:06:32.826+02:00'
  ref: '9134711645352440280'
  type: comment
- comments:
  - date: 19 August 2014 19:54
    html: I&#39;d hazard a guess that OTV may well be better. However, IIRC it&#39;s
      only supported on Nexus 7000s and requires both licenses for the VDC option
      as well as OTV (last time I looked - it might have changed) so if you&#39;re
      not a Cisco shop, or you don&#39;t have Nexus 7000s, then VXLAN may well be
      the least horrible option. There are plenty of things that support VXLAN (if
      you&#39;re using VMware then the Nexus 1000v, or VCNS or NSX would all do the
      job)
    id: '4183754916558271601'
    image: https://resources.blogblog.com/img/blank.gif
    name: Paul H
    profile: null
    pub: '2014-08-19T19:54:06.696+02:00'
    ref: '3225945583309424804'
    type: comment
  - date: 19 August 2014 20:10
    html: 'ASR 1ks  and the virtual CSRs also support OTV, and are way cheaper than
      the M cards on the 7ks. If you went the VXLAN route, and have bare metal servers
      (or maybe other VMs that don&#39;t live in ESX) that need access to the servers
      on the VXLAN segment, they have to go through the VXLAN gateway which might
      be on the opposite side of the DCI, resulting in tromboning. <br /><br />I wonder
      if what the cost of the added latency and bandwidth usage of the DCI is, and
      if it would be offset by just purchasing something that supports OTV.<br /><br
      />Semi-related fun fact: OTV has an RFC draft (currently expired though) out
      there so it looks like the intention is to let anyone use OTV. <br />http://www.ietf.org/archive/id/draft-hasmit-otv-04.txt'
    id: '5778666566286458194'
    image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
    name: Randall Greer
    profile: https://www.blogger.com/profile/08517209064574010376
    pub: '2014-08-19T20:10:05.520+02:00'
    ref: '3225945583309424804'
    type: comment
  date: 19 August 2014 16:25
  html: '&quot;VXLAN is the least horrible technology&quot;<br /><br />Could you please
    elaborate on how VXLAN is a better option than OTV? As far as I can see, OTV doesn&#39;t
    suffer from the traffic tromboning you get from VXLAN. Sure you have to stretch
    your VLANs, but you&#39;re protected from bridging failures going over your DCI.
    OTV is also able to have multiple edge devices per site, so there&#39;s no single
    failure domain. It&#39;s even integrated with LISP to mitigate any sub-optimal
    traffic flows.<br /><br />If I simply misinterpreted your post, I apologize.'
  id: '3225945583309424804'
  image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
  name: Randall Greer
  profile: https://www.blogger.com/profile/08517209064574010376
  pub: '2014-08-19T16:25:33.877+02:00'
  ref: '9134711645352440280'
  type: comment
- date: 20 August 2014 03:00
  html: Why wouldn&#39;t first hop filtering work as well on vxlan ?<br />make the
    mac address the same .
  id: '2084061393133298242'
  image: https://resources.blogblog.com/img/blank.gif
  name: Anonymous
  profile: null
  pub: '2014-08-20T03:00:07.869+02:00'
  ref: '9134711645352440280'
  type: comment
- comments:
  - date: 05 September 2014 11:02
    html: http://blog.ipspace.net/2011/04/distributed-firewalls-how-badly-do-you.html<br
      /><br />See also RFC 1925, sections 2.5, 2.6 and 2.11 ;)
    id: '1836050456143869443'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2014-09-05T11:02:18.111+02:00'
    ref: '6686014385275127274'
    type: comment
  date: 04 September 2014 22:11
  html: Will traffic trombones generated by stateful appliances be resolved with ASA
    clustering in ver 9.x? I understand that the ASA clustering feature will soon
    be supported over OTV LAN extensions. Maybe VXLAN in the near future?? Any thoughts
  id: '6686014385275127274'
  image: https://resources.blogblog.com/img/blank.gif
  name: Matt Conran
  profile: http://network-insight.net/
  pub: '2014-09-04T22:11:28.288+02:00'
  ref: '9134711645352440280'
  type: comment
- date: 05 September 2014 17:17
  html: mm much clearer now...<br />so lets wait for this to be a Cisco Validated
    Design before we recommend to clients :)<br /><br />
  id: '8839242577121434912'
  image: https://resources.blogblog.com/img/blank.gif
  name: Matt Conran
  profile: http://network-insight.net/
  pub: '2014-09-05T17:17:20.250+02:00'
  ref: '9134711645352440280'
  type: comment
- comments:
  - date: 15 September 2014 19:19
    html: 'Short answer: it depends.<br /><br />Assuming you&#39;re using vSphere
      5.5 or earlier, you have to have a vDS that spans both data centers, which means
      that hypervisors in the second data center automatically have the same port
      groups (and VNIs) as those in the first data center.'
    id: '4843623861824476806'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2014-09-15T19:19:00.060+02:00'
    ref: '5016470524725184048'
    type: comment
  date: 15 September 2014 09:09
  html: How does the VLAN to VNI mapping works when a VM migrates to another DC maintaining
    flat layer2 connectivity. I assume the VLAN the VM uses will not change so the
    VLAN to VNI mapping should be the same in the new location. This practically can
    limit the number of VNIs to 4K (the number of VLAN ids)
  id: '5016470524725184048'
  image: https://resources.blogblog.com/img/blank.gif
  name: Anonymous
  profile: null
  pub: '2014-09-15T09:09:25.349+02:00'
  ref: '9134711645352440280'
  type: comment
- comments:
  - date: 16 September 2014 20:03
    html: There is no standard solution for that problem. Talk to whoever is trying
      to sell you ToR VTEP ;)
    id: '7302962070369273309'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2014-09-16T20:03:44.770+02:00'
    ref: '3319927749631181799'
    type: comment
  date: 16 September 2014 11:02
  html: This works if the VTEP is in the hypervisor. What happens if the VTEP is in
    the TOR? Is the port group visible to the TOR switch?
  id: '3319927749631181799'
  image: https://resources.blogblog.com/img/blank.gif
  name: Anonymous
  profile: null
  pub: '2014-09-16T11:02:54.302+02:00'
  ref: '9134711645352440280'
  type: comment
- date: 20 October 2014 18:13
  html: 'Ivan,<br /><br />To Randell Greer&#39;s point above, your statement &quot;VXLAN
    is the least horrible technology&quot; does it have to do with the requirement
    of specialized hardware (Nexus 7k or ASR 1k) or reliance on Cisco for N1v? If
    you ignore the hardware requirements for OTV for a moment for L2 DCI would VXLAN
    still be better bet over OTV? We are not Cisco shop at least not in the data center,
    we are Arista shop so VXLAN (NSX would awesome and we are even considering NSX)
    makes perfect sense for us but if OTV is better point solution to satisfy L2 dependencies
    of few legacy apps we won&#39;t mind spending money for couple pairs of ASR 1ks.   '
  id: '7295582170420358931'
  image: https://resources.blogblog.com/img/blank.gif
  name: Anonymous
  profile: null
  pub: '2014-10-20T18:13:50.772+02:00'
  ref: '9134711645352440280'
  type: comment
- date: 20 October 2014 18:22
  html: Ivan,<br /><br />Please ignore my last post above dated 20 October, 2014 18:13,
    I already found you blogpost specifically addressing Randell&#39;s question. Awesome.
    Thank you sir.
  id: '7887796447944179378'
  image: https://resources.blogblog.com/img/blank.gif
  name: Anonymous
  profile: null
  pub: '2014-10-20T18:22:05.861+02:00'
  ref: '9134711645352440280'
  type: comment
- comments:
  - date: 15 October 2015 08:45
    html: 'Simple answer: No. <br /><br />In my opinion it makes no sense to agglutinate
      so many complex technologies into a single Rube Goldberg construction, regardless
      of what vendors tell you, and have no plans to waste my time trying to figure
      out how to make them work.<br /><br />Workload mobility is a myth and works
      best in vendor PPTs. Get over it and build something that has a chance of being
      operated and supported by average ops people.<br /><br />I apologize if I depressed
      you, but I&#39;m sick-and-tired of the vendor posturing.'
    id: '7418780691786197765'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2015-10-15T08:45:27.199+02:00'
    ref: '411026189214139585'
    type: comment
  date: 15 October 2015 07:00
  html: Dear Ivan, i am planing to design private virtual cloud which include multiple
    data center and want work load mobality on demand to any data center to any.I
    want to use Cisco OTV,LISP,Vmware NSX and VXLAN.I want  to use VXLAN for east
    to west traffic within DC and for noth to south want to use OTV and LISP.Could
    you please provide any use case and  detail technical information for how OTV
    and LISP integrate with NSX
  id: '411026189214139585'
  image: https://lh6.googleusercontent.com/-gar9cvsg9-4/AAAAAAAAAAI/AAAAAAAACRY/9hAYSI8Y9QY/s32-c/photo.jpg
  name: Durgesh Kumar
  profile: https://www.blogger.com/profile/01457223451374946937
  pub: '2015-10-15T07:00:05.329+02:00'
  ref: '9134711645352440280'
  type: comment
- comments:
  - date: 14 June 2017 17:45
    html: No, I haven&#39;t changed my mind. IMHO it&#39;s really hard to change the
      laws of physics (or networking), and whatever glitzy miracle comes out is usually
      just a reiteration of old stuff.
    id: '2405691576179299747'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2017-06-14T17:45:00.838+02:00'
    ref: '836157292920594033'
    type: comment
  - date: 15 June 2017 09:52
    html: Thanks, that&#39;s clear. For the sake of all of us understanding better,
      why &quot;states synchronization&quot; on FWs/LB would not solve the &quot;the
      Traffic trombones generated by stateful appliances&quot; ?
    id: '1512099864236259854'
    image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
    name: MS
    profile: https://www.blogger.com/profile/00138130459251026848
    pub: '2017-06-15T09:52:04.198+02:00'
    ref: '836157292920594033'
    type: comment
  - date: 15 June 2017 17:04
    html: http://blog.ipspace.net/2011/06/stretched-clusters-almost-as-good-as.html<br
      /><br />http://blog.ipspace.net/2011/04/distributed-firewalls-how-badly-do-you.html<br
      /><br />http://blog.ipspace.net/2015/11/stretched-firewalls-across-layer-3-dci.html
    id: '7781989391722901303'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2017-06-15T17:04:10.189+02:00'
    ref: '836157292920594033'
    type: comment
  date: 14 June 2017 16:49
  html: 'Ivan, regarding what you said : &quot;Traffic trombones generated by stateful
    appliances (inter-subnet firewalls or load balancers) are impossible to solve.&quot;<br
    /><br />&gt; Is this still your view? Some Firewalls are capable of synchronizing
    their states (sessions) with other members, yet they are in StandAlone (not in
    cluster), would you say this can resolve the &quot;stretched cluster&quot; problems
    ?<br /><br />IMHO, this may resolve some problems:<br />&gt; The cluster (especially
    the A/P) mode which can be seen as a single failure domain (software problem/bug...)<br
    />&gt; The Asymmetric flow/routing (i.e. no need for LISP if &quot;Traffic trombones&quot;
    is not a problem)<br /><br />So now, we may add as many Firewalls to the topology
    which becomes like a &quot;Firewall Fabric&quot; :)'
  id: '836157292920594033'
  image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
  name: MS
  profile: https://www.blogger.com/profile/00138130459251026848
  pub: '2017-06-14T16:49:41.669+02:00'
  ref: '9134711645352440280'
  type: comment
count: 24
id: '9134711645352440280'
type: post
url: 2014/08/revisited-layer-2-dci-over-vxlan.html
