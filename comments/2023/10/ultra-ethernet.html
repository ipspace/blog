<div class="comments post" id="comments">
  <h4>2 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="1952">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> tmp</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1952" href="#1952">03 October 2023 01:44</a>
              </span>
            </div>
            <div class="comment-content"><p>i think that the amount of reordering caused by packet spraying in data centers is widely overestimated. see also: https://engineering.purdue.edu/~ychu/publications/infocom13_pktspray.pdf
if one finds that the paths are too asymmetrical in delay, flowlets or something more advanced such as hula might be thinkable. 
at that scale though, it might be worth looking into optical circuit switching.</p>
</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="1954">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Minh</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1954" href="#1954">04 October 2023 08:55</a>
              </span>
            </div>
            <div class="comment-content"><p>From what I see, DC is a blanket term that has lost meaning, just like &#39;Cloud&#39;. Different kinds of DC have different kinds of workload and traffic pattern. Flowlets switching, including Cisco&#39;s own solution (forgot its name) are not designed for the scale of HPC, so they&#39;re untested solutions for that kind of environment and likely won&#39;t scale. </p>

<p>Turbulence modeling in particular, is extremely data and network intensive due to the nature of Turbulence -- the number of degrees of freedom scale exponentially with model size, which is why weather forecasting cannot forecast very far, while climate modeling is totally hopeless. These are the ultimate Big Data scenarios, and as usual, almost never get mentioned in mainstream press because they&#39;re super hard and not trendy. But they require as much horsepower as the biggest supercomputer fabrics can muster just to solve a tiny fraction of their problems. So claims that AI/ML require more processing power than what comes before them -- which is the impression I&#39;m getting these days -- don&#39;t stand up to scrutiny.</p>

<p>HPC DCs that work on things like Turbulence often use Dragonfly Fabric Topology -- to minimize network diameter -- with per-packet Adaptive Routing, so asymmetric routing and out-of-order delivery become a big problem the higher the fabric gets utilized. </p>

<p>Circuit switching using optical paths does away with reordering, but it&#39;s physically expensive and therefore doesn&#39;t not get implemented in the big HPC fabrics, and is not mentioned in the Broadcom solution either. </p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1955">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1955" href="#1955">04 October 2023 09:10</a>
              </span>
            </div>
            <div class="comment-content"><p>&gt; Circuit switching using optical paths does away with reordering, but it&#39;s physically expensive and therefore doesn&#39;t not get implemented in the big HPC fabrics</p>

<p>It also requires reasonably-stable traffic distribution to work well. That&#39;s why it works for Google -- if you have enough (somewhat predictable) traffic, the patterns are stable enough at the network core for optical switching to work well.</p>

<p>&gt; and is not mentioned in the Broadcom solution either.</p>

<p>Because Broadcom does not sell anything along those lines?</p>
</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1957">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Minh</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1957" href="#1957">04 October 2023 09:23</a>
              </span>
            </div>
            <div class="comment-content"><p>Looks like even for ML workload, network bottleneck can become severe:</p>

<p>https://blog.apnic.net/2023/08/10/large-language-models-the-hardware-connection/</p>

<p>&quot;But, in many training workloads, GPU utilization hovers around 50% or less due to memory and network bottlenecks.&quot;</p>

<p>&quot;Google trained all its LLM models, LaMDA, MUM, and PaLM, in a TPU v4 pod and they claim very high TPU utilizations (over 55%) for training.&quot;</p>

<p>55% TPU cluster utilization is considered good. So obviously they want to improve. But will UltraEthernet provide the answer?</p>

<p>So I watched &quot;Broadcom Ethernet Fabric for AI and ML at Scale&quot;. They already introduced this concept of cell-spraying fabric a few years back in a paper. Looks like they&#39;re now putting that concept in action. The problem is: scale matters. Inside a xbar switch, high throughput and ECMP are achieved through cell-switching -- the power of a central fabric scheduler like iSlip therefore is vital to xbar performance -- while latency and HOL blocking are achieved with VOQ -- without VOQ, input-buffered switches&#39; performance tops out 58% for the most simple type of traffic, due to HOL blocking. </p>

<p>But when they try to turn it into a network-wide fabric, they don&#39;t have a central scheduler to arbitrate cells efficiently, so what do they rely on? Distributed scheduling at each node from what I understand. But that solution is no longer the simple VOQ xbar like those found in the single-stage Cisco 12000 series (designed by Nick Mckeown) or the multi-stage CRS router. </p>

<p>Memory-less xbar (the xbar itself doesn&#39;t have any buffer) routers don&#39;t have an out of order delivery problem, so output interfaces don&#39;t worry about cell reordering; they only do SAR (segmentation and reassembly) function. Virtual switch built using an aggregation of smaller switches, like the solution Broadcom proposes in their vids, DO. This is the same out-of-order delivery problem that affects buffered-crossbar routers. </p>

<p>How do Broadcom deal with reordering? I don&#39;t see that mentioned -- if I did miss something in their presentation(s), pls point out. Reordering at the destination switch? Damn. That&#39;s a lot of work. They did mention credit-based flow control, which is nonsense. Priority flow control creates HOL blocking, the same problem that stops input-buffered switches&#39; performance at 58% for the most simple type of traffic, for which VOQ was designed to address. Plus, PFC (credit-based FC a variant) makes the circuitry more complex, and therefore harder to produce and test for; all this means higher price for the network devices. Which leads us right to the next problem: &quot;virtual switch that can supposedly have up to 32.000 ports&quot;.</p>

<p>If this kind of chassis is built using VOQ doctrine, I don&#39;t think it&#39;s physically possible. Because in VOQ system, each port, and in this case, it means each physical port on a switch -- any switch in the fabric -- has to have a VOQ for the other 32000 ports in the chassis. Let&#39;s say that leaf switch has 64 ports. That means 64x32000 VOQs. This is just too much. How are you gonna design the physical circuitry for this? How big will the PCB become, and how many layers will it have??? What about the heat this monster will dissipate, will it melt up or otherwise damage the material? And who&#39;s paying for the power bill? Color me skeptical, but I&#39;ll believe it when I see it. </p>

<p>For these reasons, I think their solution will be subpar, just like the others mentioned in the APNIC article.</p>

<p>Also, the solution for this particular kind of problem already exists, in the form of Dragonfly HPC fabrics with Adaptive routing. No need for crappy PFC. Deadlock is avoided with the use of Virtual Channel and some form of valley-free routing.</p>
</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="1960">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1960" href="#1960">04 October 2023 11:44</a>
              </span>
            </div>
            <div class="comment-content"><p>&gt; How do Broadcom deal with reordering? I don&#39;t see that mentioned</p>

<p>Of course not, that&#39;s their secret sauce.</p>

<p>&gt; Reordering at the destination switch? Damn. That&#39;s a lot of work.</p>

<p>Not if you use a trick similar to RDMA -- use fixed-length cells, and copy incoming cells into the right place in the buffer memory (in reality: probably use some scatter/gather trick to avoid copying overhead). The only thing left is to deal with packet losses and retransmissions (or you ignore them like ATM did).</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1961">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Wes Felter</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1961" href="#1961">04 October 2023 06:35</a>
              </span>
            </div>
            <div class="comment-content"><p>I can answer some of this since I worked on a Broadcom Jericho DDC in 2015-2017. Cells are indeed put back into order at the egress ASIC (otherwise packets would be corrupted). I think packets are also kept in order although I&#39;m not sure how. Forwarding logic isn&#39;t duplicated for each port so you don&#39;t need 64x32,000 VOQs, just 32,000 in each ASIC which can be stored in on-chip SRAM. All the ASICs are now 500W monsters and all the PCBs are thicc af (as the kids say) so IMO you might as well use the best ASIC. At the time we found that Jericho+Ramon was actually slightly cheaper and noticeably faster than Tomahawk.</p>

<p>Note that Ultra Ethernet works differently from DNX/Jericho so today&#39;s DNX networks aren&#39;t a preview of how Ultra Ethernet will look (although one&#39;s available today and the other is not). It sounds like Ultra Ethernet will have NIC-to-NIC congestion management and reordering while DNX does everything inside the switch. Mellanox is already selling some flavor of NIC/DPU-based congestion management.</p>

<p>It&#39;s easy to say something like adaptive routing with virtual channels and valley-free routing like all the academic papers but Ethernet ASICs either don&#39;t support those features or they&#39;ve never been turned on (maybe they don&#39;t work). It&#39;s possible that Ultra Ethernet will get those features in a more reliable and standardized way.</p>
</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
