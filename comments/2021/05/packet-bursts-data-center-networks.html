<div class="comments post" id="comments">
  <h4>3 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="577">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Enrique Vallejo</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c577" href="#577">18 May 2021 10:51</a>
              </span>
            </div>
            <div class="comment-content"><p>Note that 200 ms is the default value for the RTOmin parameter, this is, the minimum value that the Retransmission TimeOut can be assigned dynamically, based on the estimation of RTTs. Decreasing this value (instead of the initial RTO) has been reported to hugely improve TCP goodput in presence of incast - because it reduces the dramatical impact of packet losses and retransmissions. See:</p>

<p>https://www.cs.cmu.edu/~dga/papers/incast-sigcomm2009.pdf</p>

<p>This study explores values for RTOmin of 1 ms and lower. Note that, in practice, you can be limited by the kernel clock resolution -- we have found some systems in the past where it prevented you from setting any value lower than 5 ms. In any case, the benefit from the default RTOmin = 200 ms is huge. </p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="578">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Xavier</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c578" href="#578">18 May 2021 02:42</a>
              </span>
            </div>
            <div class="comment-content"><p>Datacenter links can normally support those server bursts, but at the end there is a traffic server to client that cannot support those bursts. Clients are 1G, servers are 10G/25G. Most of access switches can not suport all those servers bursts neither. Is still better drop than use pause frames on access switches? </p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="579">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c579" href="#579">18 May 2021 04:34</a>
              </span>
            </div>
            <div class="comment-content"><p>@Enrique: Thanks a million! I love how much I learn from the comments ;)) Will fix the text and add a link.</p>

<p>@Xavier: As most traffic toward the client is client-generated in the first place, you wouldn&#39;t expect to see a massive incast problem, and as the TCP bursts gradually increase in size as the peers are trying to figure out what works, eventually the network-to-client link will get into packet drop territory and the inbound TCP sessions will reach an equilibrium.</p>

<p>I would strongly suggest you figure out (A) how much buffering there is on your access switches and (B) what&#39;s the percentage of outbound packet drops caused by output queue overflow. You might not have that problem at all.</p>
</div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
