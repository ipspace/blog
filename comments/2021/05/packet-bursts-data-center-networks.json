{
   "comments": [
      {
         "date": "18 May 2021 10:51",
         "html": "<p>Note that 200 ms is the default value for the RTOmin parameter, this is, the minimum value that the Retransmission TimeOut can be assigned dynamically, based on the estimation of RTTs. Decreasing this value (instead of the initial RTO) has been reported to hugely improve TCP goodput in presence of incast - because it reduces the dramatical impact of packet losses and retransmissions. See:</p>\n\n<p>https://www.cs.cmu.edu/~dga/papers/incast-sigcomm2009.pdf</p>\n\n<p>This study explores values for RTOmin of 1 ms and lower. Note that, in practice, you can be limited by the kernel clock resolution -- we have found some systems in the past where it prevented you from setting any value lower than 5 ms. In any case, the benefit from the default RTOmin = 200 ms is huge. </p>\n",
         "id": "577",
         "name": "Enrique Vallejo",
         "pub": "2021-05-18T10:51:38",
         "type": "comment"
      },
      {
         "date": "18 May 2021 02:42",
         "html": "<p>Datacenter links can normally support those server bursts, but at the end there is a traffic server to client that cannot support those bursts. Clients are 1G, servers are 10G/25G. Most of access switches can not suport all those servers bursts neither. Is still better drop than use pause frames on access switches? </p>\n",
         "id": "578",
         "name": " Xavier",
         "pub": "2021-05-18T14:42:02",
         "type": "comment"
      }
   ],
   "count": 2,
   "type": "post",
   "url": "2021/05/packet-bursts-data-center-networks.html"
}
