<div class="comments post" id="comments">
  <h4>7 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="520">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Enrique Vallejo</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c520" href="#520">15 April 2021 10:45</a>
              </span>
            </div>
            <div class="comment-content"><p>My bet for the elephant in the room is congestion delay. Using a congestion control mechanism that keeps buffer utilization (and thus buffer delay) low, such as Datacenter TCP, is probably much more relevant than having a low forwarding latency in the intermediate devices. For example, an average occupancy of 20 packets per input buffer increases latency by 24 &mu;s when using 10G, way larger than typical zero-load forwarding latency.</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="521">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> James</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c521" href="#521">15 April 2021 10:52</a>
              </span>
            </div>
            <div class="comment-content"><p>Buffering delay? Maybe packet size? Hard to guess the elephant.</p>

<p>Some HFTs are looking at using LASERs in space. Speed of light in a vacuum is faster again :) </p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="522">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Tim</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c522" href="#522">15 April 2021 12:45</a>
              </span>
            </div>
            <div class="comment-content"><p>Perhaps elephant flows that delay reception of more latency sensitive mice flows</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="525">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Jean-Baptiste</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c525" href="#525">15 April 2021 09:15</a>
              </span>
            </div>
            <div class="comment-content"><p>There is a really good Cisco Live from Lucien Avramov (BRKDCT-2214) about low latency networking with a few numbers and measurements. He also points out that network latency is way lower than middelware and application latency, which is probably where one should start instead of optimising a few nano-seconds on a switch.</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="526">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Sander Steffann </a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c526" href="#526">15 April 2021 09:20</a>
              </span>
            </div>
            <div class="comment-content"><p>I think the elephant is &quot;but how fast can you actually process the packets when you receive them?&quot; &#x1F642;</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="527">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Daniel Larsson</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c527" href="#527">15 April 2021 10:57</a>
              </span>
            </div>
            <div class="comment-content"><p>Excellent article (you always find interesting topics).
My bet for the elephant will be QoS to lower the latency even further.</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="529">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Minh Ha</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c529" href="#529">16 April 2021 11:59</a>
              </span>
            </div>
            <div class="comment-content">Great topic Ivan : ))! I found Cisco apparently manages to scale port-to-port latency down to 250ns for L3 switching, which is astonishing, and way less (sub 100ns) for L1 and L2, here (page 7):<br />

<p>https://www.cisco.com/c/dam/en/us/products/collateral/switches/nexus-3550-series/esg-white-paper-ultralowlatency.pdf</p>

<p>I don&#39;t know where FPGA fits into this ultra low-latency picture, because FPGA, compard to ASIC, is bigger, and a few times slower, due to the use of Lookup Table in place of gate arrays, and programmable interconnects. In any case, looking at their L2 and L1 numbers, it&#39;s too obvious the measurement was taken in zero-buffer and non-contentious situations. In the real world, with realistic heavily bursty, correlated traffic, they all perform way less than their ideal case. But regardless, L3 switching at 250ns even under ideal condition is highly impressive, given Trident couldn&#39;t achieve it in any of their testing scenarios. </p>

<p>Again, I&#39;m not bashing Broadcom. It&#39;s just I find it laughable reading their apologies in their report you linked to, wrt how they don&#39;t &quot;optimize&quot; for 64-byte packets (love their wording), and how they manage to find a way to make their competitor finish far behind in the tests. Granted, Mellanox was trying the same thing in their test against Broadcom, so they&#39;re all even, and we should only take these so-called vendor-released testing reports with a grain of salt.</p>

<p>The elephant in the room that you alluded to, is most likely endpoint latency. It&#39;s pretty irrelevant to talk about ns middlebox-latency when the endpoints operate in the ms range :p . And endpoint latency gets even worse when features like interrupt coalescing and LSO/GRO are in place. Must be part of the reason why the Cloud&#39;s performance for scientific apps sucks, and funny enough, they actually admit it as I found out recently. </p>

<p>But IMO, that only means the server operating system, the hypervisor, the software switch etc, are the ones that need innovation and up their game, instead of using their pathetic latency figures as an excuse not to keep bettering routers&#39; and switches&#39; performance. Overlay model is notoriously slow because it&#39;s layer on top of layer (think BGP convergence vs IGP convergence), and as mentioned in your previous post, Fail fast is failing fast: &quot;If you live in a small town with a walking commute home, you can predictably walk in the front door at 6:23 every evening. As you move to the big city with elevators, parking garages, and freeways to traverse, it&#39;s harder to time your arrival precisely,&quot;  that kind of overburderned, complex architecture is not deterministic and no good for applications with real-time requirements. Infiniband shied away from TCP/IP for the same reason, and used a minimal-stack model to keep their latency low.</p>

<p>The Cloud and their overlay model is a definitely a step backward in terms of progress. By doing it cheap, they make it slow. Good for their greedy shareholders, sucks for consumers who truly need the numbers. Well, I guess I can stop complaining now that bare-metal instances are a thing. But yeah, taken as a whole, basically echnology winter sems to continue. These days about the only kind of progress we have is corporate-PR progress. </p>

<p>Speaking of HFT, there seems to be a lot of fanfare going on there when it was big some 10 yrs ago. FPGA was often mentioned as the way they sped up their end-to-end latency. But I ran across comments of some of the guys who actually did HFT for a living sometime back, and they said it&#39;s all hot-air, with most of the stuff they try to optimize being on the software level, such as doing away with message queuing (and so, safely getting rid of locks) to unburden their programs of concurrency synchronization, which is a big latency killers. Staying away from language that performs garbage collection is another thing, as there&#39;s no one-size-fit-all garbage collection algorithm that&#39;s optimized for all use case, and regardless, it&#39;s an additional layer compared to explicit memory management, and more layer means slower.</p>

<p>From what I know of RenTech, one of the biggest if not the biggest HFT (they also do other algorithmic trading besides HFT), they rely on software with big-data models, not fancy hardware. </p>
</div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
