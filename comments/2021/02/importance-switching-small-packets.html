<div class="comments post" id="comments">
  <h4>11 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="398">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Andrea Di Donato</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c398" href="#398">11 February 2021 10:38</a>
              </span>
            </div>
            <div class="comment-content"><p>Hello Minh, <br />
Always a pleasure reading your stuff. You and Ivan are are an explosively powerful mix. :) <br />
Totally agree with you on small packets. <br />
A couple of things though for the time being: <br />
I just want to take a stand for once in defense of the high-end vendors as they are asked for hundreds of sometimes pretty exotic features by their big Service Provider customers and therefore the code and the chipset gets as you pointed out extremely populated with stuff. I have the impression it is inevitable and it&#39;s not just made on purpose to make more money as such.  I reckon they&#39;d rather avoid it if they could. <br />
The other thing is if you can open up another blog soon on the interesting. 
statement: &quot;Self-similar traffic also makes big buffer mostly useless,&quot; :)    </p>

<p>Last thing: I might be naive but our market is in need even more urgently now that the scenario is getting fuzzier and fuzzier of an independent testing facility for functionality AND performance.  Universities should be involved and the vendors too of course. Stringent test procedures and well documented and thus reproducible. In short, proper stuff.   </p>

<p>Cheers/Ciao <br />
Andrea  </p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="399">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Piotr Jablonski</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c399" href="#399">11 February 2021 11:08</a>
              </span>
            </div>
            <div class="comment-content"><p>IMIX can also serve as a baseline. It would be better benchmark than for 64B size packets. More important thing is to do multidimensional scale and performance tests on the same OS. Not like unidimensional tests on a tuned OS version per test as some Chinese vendors got used to do it. </p>

<p>In a test with a single feature the performance may not drop significantly. A router OS image packed with many features requires additional CPU cycles to check IF statements and bypass the code, even if it is not turned on but its software module is on the HW line card. Some vendors used a pre-canned OS images to use just the code optimised for a particular tested feature. In reality we turn on many features at the same time and the similar setup should be validated during the test. There are customers who are waiting several years for one official image. Be careful with such vendors.</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="400">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Piotr Jablonski</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c400" href="#400">11 February 2021 11:16</a>
              </span>
            </div>
            <div class="comment-content"><p>One more - It&#39;s better to do test based on IMIX as you can have a higher probability of detecting malfunctions and bad architectures. With a fixed size of packets a vendor can use a simpler dedicated ASICs which perform better for this size but not the other. At the end of the day DDOS is still IMIX.</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="403">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Minh Ha</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c403" href="#403">12 February 2021 08:20</a>
              </span>
            </div>
            <div class="comment-content"><p>@Andrea,</p>

<p>Thx for the kind words :))! Yeah, I too am aware of vendors being asked by certain high-end SP customers to put all sorts of features on to their chipsets, in kitchen-sink style RFPs. There&#39;re always such customers and it&#39;s fine to address their requirements as such. But that&#39;s exactly why vendors have product lines, like Broadcom creates different chipsets for different markets: Trident for Enterprise, Jericho for SP, Tomahawk for Cloud which is light in feature and powerful in forwarding capacity. Hypothetically speaking, if once-great market leaders like Cisco executed well, it&#39;d not be struggling the way it is now. And I do mean struggling, because Cisco&rsquo;s revenue seems to have been stuck at the current level for a few years now, this year slightly worse than 2019. Looks like Cisco&rsquo;s core business is being slowly eaten away by Cloudification and whiteboxing. It&#39;s been trying hard to diversify in recent years, something it should have started 20 yrs ago when its spirit was still vibrant. </p>

<p>I personally think the problem goes deeper than tech, because if it&#39;s just tech, Broadcom should be in the same rabbit hole. The problem, IMO, lies with vendor strategy, allocation of resources, and execution. Let&#39;s dissect Cisco. The company was a pioneer in the golden age of networking, the 90s. Cisco in its young life was prized, among other things, for its innovative strength and its dynamic culture. IOS for ex, was written by high-class programmers. EIRGP was another great invention, a protocol if rightly configured and designed, is superior to link-state protocols in scalability, and downright better in tree topologies, esp. if one wants to implement valley-free routing, without resorting to BGP unnecessarily. </p>

<p>But Cisco couldn&rsquo;t take advantage of them and of its incumbent advantage the way MS did, making Windows the de-facto standard for Desktop OS. IOS got nowhere near that, and instead, got chopped into all sorts of variants, like IOS-XE, IOS-XR etc etc. It&rsquo;s too complicated and slowly customers started to complain about the complexity of it all. That&rsquo;s just plain stupid IMO, and opened the doors for new entrants to come in and attempt to &ldquo;differentiate with their NOS&rdquo;. Cisco dug its own grave on that one. </p>

<p>As for EIRGP, as promising/elegant as it was, Cisco was never able to impose its own weight and make it into a quasi standard either. Terrible execution, due in part to the then mgmt&rsquo;s arrogance and excessive focus on stock price and addressing &ldquo;shareholder value&rdquo;, I must say. Lucent was a prime example of how following such misguided practice could lead to destruction. Cisco is wiser, but just, because right now, its public image is just a tired aging company, instead of a dynamic technology leader it once was in its younger years. At one point, March 2000, Cisco was the most valuable company in the world, bigger than MS; now its market cap is one-eighth of MS&rsquo; size. Is that the result of sound strategy, good prioritization of resources, and excellent execution? Hardly :p.</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="404">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Minh Ha</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c404" href="#404">12 February 2021 08:27</a>
              </span>
            </div>
            <div class="comment-content"><p>And speaking of the market getting fuzzier and in need of indepdendent testing facility, I can&rsquo;t agree with you more! The other day I saw someone mentioned Innovium Teralynx ASIC reaching its 1 million ports on shipment milestone, so I decided to dig around on Teralynx. What I came across was a bunch of superficial whitepapers and articles praising its prowess, no worthwhile architectural info. Here&rsquo;s a sample of those totally worthless articles:</p>

<p>https://www.nextplatform.com/2020/05/11/innovium-stays-on-broadcoms-heels-with-teralynx-8-switch-chips/</p>

<p>I did managed to find one nice piece of info though: &ldquo;As for latency, Khemani says the typical port to port hop is on the order of 500 nanoseconds, but for typical alternatives it is more like 1 microsecond; the important thing is that this number is much lower than what Tomahawk 4 will deliver.&rdquo; So a high-density 400GE switch, offers essentially the same port-to-port latency as 10GE switch? And Tomahawk is worse than that? And I thought the point of having 400G as a standard was so that things could improve on all fronts :p. Looks like the only things that did improve was the Serdes frequency and the serialization speed. This is basically the same as in computing. Intel (and others) comes up with superfast parallel CPUs, only to have them dragged down by memory speed bottleneck, and application latency remains mostly unchanged. </p>

<p>These situations are allowed to happen because the whole networking industry relies on a handful of companies providing them with chipsets/ASICs, the backbone of their products. It stiffens innovation and leads to obfuscation of info as you rightly mentioned, and it doesn&rsquo;t matter since these guys, being the only sources the industry can turn to, make their own rules and get to throw their weight around. </p>

<p>And just like Piotr brought up, tests should be multi-dimensional, because even on hardware levels, there&rsquo;s no chipset architecture that works best for all scenarios. An ASIC may test well with one feature or at a certain level of offered load, only to fall apart as more features are activated or at higher utilizations. Out of order packets for ex, are one outcome that shows up when buffered-crossbar chipsets are stress-tested heavily. Cisco probably learned from this and so, when they designed their CRS platform, they ruled out bit-slicing/cell spraying, sacrificing throughput for in-order port-to-port delivery and better latency:</p>

<p>https://www.cisco.com/c/en/us/td/docs/iosxr/crs/hardware-install/crs-1/8-slot/system-description/b-crs-crs1-8-slot-line-card-chassis-system-description/b-crs-crs1-4-slot-line-card-chassis-system-description_chapter_0100.html  </p>

<p>Re my statement about self-similar traffic and big buffer, basically self-similar/LRD traffic means traffic arrival is bursty on many time scales. And since it&rsquo;s bursty on many time scales, having big buffer helps little with the situation (how much bigger can you make your buffer if the burstiness persists for long), not to mention the bigger the buffer and the more it gets occupied, the larger the latency becomes. And by necessity, by having big buffer, these memories will have to be off-chip, and most likely made of DRAM/RLDRAM, further increase RTT and add more to total device latency.  Even the use of HMC here</p>

<p>https://www.juniper.net/assets/jp/jp/local/pdf/whitepapers/2000599-en.pdf</p>

<p>won&rsquo;t help because HMC trades latency for bandwith. So yes, big buffer has serious latency implications and is best avoided. </p>

<p>For more evidence on the existence of self-similarity in modern network, you can read this one here:</p>

<p>http://conferences.sigcomm.org/imc/2010/papers/p267.pdf</p>

<p>Toward the end, it said &ldquo;Next, we studied the transmission properties of the applications in terms of the flow and packet arrival processes at the edge switches. We discovered that the arrival process at the edge switches is ON/OFF in nature where the ON/OFF durations can be characterized by heavy-tailed distributions.&rdquo; That&rsquo;s the sign of self-similarity, or bursty on different time scales. This paper also mentioned small packets as well, about 50% of the packets they sampled are of the small varieties. </p>

<p>And wrt the futility of using big buffer to address burstiness, esp. Microburst in the DC, you can take a look here, this one involved MS research so its findings are empirical as well:</p>

<p>https://arxiv.org/pdf/1604.07621.pdf </p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="405">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c405" href="#405">12 February 2021 08:41</a>
              </span>
            </div>
            <div class="comment-content"><p>@Minh Ha: Regarding the comparison of Cisco and Microsoft</p>

<p>Microsoft had the guts to effectively rewrite the core operating system when going from 95/98 to XP, and again to rewrite lots of insecure parts with Vista/7.</p>

<p>Cisco never found the willpower to do anything similar with Cisco IOS, so it&#39;s still running as a single-memory-image blob within a Linux process on IOS XE (I&#39;d be super-glad to be corrected) with tons of lipstick applied to that aging piglet. </p>

<p>Cisco also got hooked on acquisitions because they were never able to put their house in order, and the internal overhead made R&amp;D-through-acquisitions a much more palatable approach... and so we got IOS XR and Nexus OS (and a ton of other things).</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="406">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Minh Ha</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c406" href="#406">12 February 2021 09:07</a>
              </span>
            </div>
            <div class="comment-content"><p>@Ivan, Yup, 100% with you there :))!!!!! You remind me so much of the good old days, and that&#39;s definitely part of what makes your writing so invaluable! </p>

<p>I don&#39;t see eye to eye with Bill Gates &amp; MS on quite a few things, but have it to give to them on their execution and the will to try and take great, calculated risk. That dynamic, vibrant spirit is exactly what&#39;s made them into what they are today. They gave up on their old OS code base and forged ahead with the new NT family code, starting with NT 3.5, 4.0, 2000, XP...They came up with Active Directory in Windows 2000 server which was a tsunami that&#39;d taken the world by storm back in those days, totally departing from their flat, NetBIOS-based, centralized directory service in NT 4.0 into the DNS-based, distributed, eventually consistent directory service model. That was a huge move and great risk if it didn&#39;t pan out. But they knew what they did and got the right focus and determination, and managed to put out Novell and its E-directory out of business. And yes, I still remember the security part in Vista/7. And most obviously, MS knew when the software industry was saturated to transition their business quickly enough into a service provider model, like now, even giving away their iconic Windows OS in the process. That&#39;s big-league. </p>

<p>Cisco was much more of a mess :)) . They did tons of M&amp;A in the late 90s with the grand vision of being the one-stop shop for the converged world of data and voice. Among their acquisitions were optical networking companies. AFAIK, this is 2021, and Cisco is still a nobody in optical networking, and in mobile networking as well. Huawei&rsquo;s revenue was 180 billion in 2016, almost 4 times that of Cisco, and it was nowhere to be seen while Cisco reigned supreme back in the late 90s-early 2000s. </p>

<p>If Cisco was well-run and didn&#39;t get obsessed with stock price and &quot;shareholder value&quot;, by now they could probably be too big to fail, to big to worry about the Clouds and all the rest. </p>

<p>And speaking of all the Cisco OSes, you surely would remember CatOS; for a time we&#39;re stuck with running IOS and CatOS because Cisco was having trouble integrating Crescendo IP after acquiring them ;). </p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="407">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Bela Varkonyi</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c407" href="#407">12 February 2021 09:23</a>
              </span>
            </div>
            <div class="comment-content"><p>There is another issue with bad small packet performance. It shows that the architecture is not deterministic. For Web browsing and YouTube it is not a problem, but for a lot of safety critical, industrial, closed-loop applications it is. Most engineers are crying back for TDM and ATM. But because of fashion, they would not get it for any reasonable cost.
The typical solution is a next round on a spiral development, reinventing the wheel in a new form.
DetNet is coming to the rescue... But the youngsters have to rediscover all the old problems. This will take same time.
Instead of just producing more TDM/ATM.
Maybe sometime they will also reinvent PNNI. DetNet would need it... :-)
SDN has already reinvented TDM/ATM management plane. What comes next in reinventions?</p>

<p>BTW, the TDM architecture was created because the digital processing speed was not enough good for the higher physical link speeds. That is why you needed a very simple hardware implemented demultiplexing first and only then looking at the meaning of the bits. 
As we go for terabit speeds, it may happen again. They will hide it under some new names, but there is nothing new under the sun. Just new clothes... :-)</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="410">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Andy</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c410" href="#410">13 February 2021 02:08</a>
              </span>
            </div>
            <div class="comment-content"><p>Hi Ivan
i guess small packets linerate throughput relevancy can become more emergent by the nowadays trends with populating Internet by IoT. Those devices are able to generate small packet flows which has to be aggregated by the backbones. More IoTs to aggregate more need in small packets linerate throughput is obvious.</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="415">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Andrea Di Donato</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c415" href="#415">21 February 2021 04:43</a>
              </span>
            </div>
            <div class="comment-content"><p>@ Minh Ha regarding self-similarity and big buffers. Thanks for the pointers to some very interesting material.   </p>

<p>I just wanted to report a tremendous amount of recent top-quality information @ this 2019 Stanford University&#39;s &quot;Workshop on Buffer Sizing&quot; @ http://bufferworkshop.stanford.edu/. <br />
This is really a workshop fuelled by the 2004 Nick McKeown&#39;s renowned paper &quot;Sizing Router Buffers&quot;.... but 15 years later ... @ https://web.stanford.edu/class/cs244/papers/sizing-router-buffers-redux.pdf  </p>

<p>Having said that, it&#39;s not black and white as with any complex thing;  One of the concluding remarks of the workshop speaks for itself: &quot;We still know very little about buffer size&quot;. <br />
Enjoy the reading !   </p>

<p>It&#39;d be great if this could be a subject for a series of Ivan&#39;s blogs too. It could be a chance (call me naive.. ) for networkers, academics and vendors to exchange ideas/experiences. Major router vendors were in fact missing at such workshop...  </p>

<p>Cheers/Grazie <br />
Andrea Di Donato  </p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="417">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Andrea Di Donato</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c417" href="#417">21 February 2021 04:55</a>
              </span>
            </div>
            <div class="comment-content"><p>Sorry - still me. <br />
Just to say that the working link to the workshop is: <br />
https://buffer-workshop.stanford.edu/ <br />
Cheers/Ciao <br />
Andrea  </p>
</div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
