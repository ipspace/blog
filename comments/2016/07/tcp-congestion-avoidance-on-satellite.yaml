comments:
- date: 21 July 2016 18:42
  html: Pacing should help, but still sadly isn&#39;t a standard feature.
  id: '6518907795688848805'
  image: https://3.bp.blogspot.com/-H2V8oUucSto/VcDOK9ZBBSI/AAAAAAAAAv4/1DNQA1NWqyk/s32/laptop006%2Bas%2Bsouthpark%2Bcharacter.png
  name: Julien Goodwin
  profile: https://www.blogger.com/profile/00108223150670314820
  pub: '2016-07-21T18:42:26.756+02:00'
  ref: '8414821127925297259'
  type: comment
- date: 22 July 2016 00:47
  html: I do look forward to someone publishing some data on the fq_codel algorithm,
    tuned for sats = an interval of 1000ms and 50-100ms target latency.
  id: '7901496604166315120'
  image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
  name: Dave Taht
  profile: https://www.blogger.com/profile/16115281578739979183
  pub: '2016-07-22T00:47:46.753+02:00'
  ref: '8414821127925297259'
  type: comment
- date: 22 July 2016 17:57
  html: 'With link-level traffic shaping you could move the congestion point to your
    own router. If the bandwidth is reserved like a leased-line. If it is changing
    dynamically, then you need a sophisticated controller (e.g. SDN). You could also
    add a Peformance Enhancement Proxy (PEP). Most routers already contain one already.
    You could also use various header and content compressions. And of course, you
    could make multiple parallel threads. '
  id: '322714506767215570'
  image: https://lh4.googleusercontent.com/-t7xwu4fY91Y/AAAAAAAAAAI/AAAAAAAAByc/AStXb-jqQyY/s32-c/photo.jpg
  name: "B\xE9la V\xE1rkonyi"
  profile: https://www.blogger.com/profile/07985346761439657130
  pub: '2016-07-22T17:57:02.237+02:00'
  ref: '8414821127925297259'
  type: comment
- date: 22 July 2016 18:01
  html: 'You could also use cross-layer QoS and admmission control with adaptive coding
    so could accomodate changing weather conditions. And you may also ask for FEC
    for reducing packet drops. This all could be combined with what you have already
    suggested... '
  id: '2492564773755299717'
  image: https://lh4.googleusercontent.com/-t7xwu4fY91Y/AAAAAAAAAAI/AAAAAAAAByc/AStXb-jqQyY/s32-c/photo.jpg
  name: "B\xE9la V\xE1rkonyi"
  profile: https://www.blogger.com/profile/07985346761439657130
  pub: '2016-07-22T18:01:22.701+02:00'
  ref: '8414821127925297259'
  type: comment
- comments:
  - date: 23 July 2016 12:37
    html: That solves just the question of the first RTT, which is important (and
      annoying if you&#39;re sitting at the browser) but there are many more things
      to solve.
    id: '1744700568383275689'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2016-07-23T12:37:01.350+02:00'
    ref: '7906438726551267807'
    type: comment
  date: 23 July 2016 09:45
  html: get some wider support for TFO?  https://www.youtube.com/watch?v=Qo9rFpiLMWI
  id: '7906438726551267807'
  image: https://resources.blogblog.com/img/blank.gif
  name: Anonymous
  profile: null
  pub: '2016-07-23T09:45:27.613+02:00'
  ref: '8414821127925297259'
  type: comment
- date: 24 July 2016 09:11
  html: "J Hand sent me this comment after Blogger failed a few times<br />=============<br\
    \ />Couldn\u2019t the results be just as well or better explained by a combination\
    \ periodic weather fades and the possibility that the SATCOM link provider chose\
    \ a modulation and coding scheme that is insufficiently robust for these fades?\
    \  The additional coding added at the network layer shores up the insufficient\
    \ link layer coding and reduces the residual packet loss rate during the fades\
    \ to a level in which TCP throughput for the link can be maintained.<br /><br\
    \ />If the problem were fades, queue oscillations wouldn\u2019t likely be a significant\
    \ part of the problem.  The queues could be chronically underutilized because\
    \ the TCP senders would be misinterpreting corruption loss as a sign of congestion,\
    \ and slowing down unnecessarily, regardless of the queue levels.<br /><br />And\
    \ as noted in the comments in the original article, if the cause of the packet\
    \ loss *were* congestion/queue oscillations, then the additional coding would\
    \ be masking congestion signals.  The article seems to assume that there is too\
    \ much packet loss (and therefor congestion signals), and is preventing the TCP\
    \ sessions from ramping up.  But too little packet loss and congestion signal\
    \ would still result in queue oscillation.  The TCP sessions would keep ramping\
    \ up until eventually there was enough packet loss that the network coding couldn\u2019\
    t mask it.  The article doesn\u2019t seem to explain why the network coding scheme\
    \ they used got the level of packet loss right.<br /><br />Again, sorry, but please\
    \ set me right on what I\u2019m missing."
  id: '1195452255993724533'
  image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
  name: Ivan Pepelnjak
  profile: https://www.blogger.com/profile/13457151406311272386
  pub: '2016-07-24T09:11:19.827+02:00'
  ref: '8414821127925297259'
  type: comment
- date: 24 July 2016 16:33
  html: forward error correction on satellite link is implemented on L1, why would
    anyone need to make it on L3 too? not sure if it is possible to make it more efficient.
  id: '4999571322499002971'
  image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
  name: "\u0441\u0447\u0430\u0441\u0442\u043B\u0438\u0432\u0447\u0435\u0433"
  profile: https://www.blogger.com/profile/11133937069073997736
  pub: '2016-07-24T16:33:43.335+02:00'
  ref: '8414821127925297259'
  type: comment
- date: 24 July 2016 16:34
  html: and what about TCP-acceleration... forgotten?, but it is there :)
  id: '4700994624611513768'
  image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
  name: "\u0441\u0447\u0430\u0441\u0442\u043B\u0438\u0432\u0447\u0435\u0433"
  profile: https://www.blogger.com/profile/11133937069073997736
  pub: '2016-07-24T16:34:45.824+02:00'
  ref: '8414821127925297259'
  type: comment
- date: 24 July 2016 16:37
  html: '&quot;1 second RTT&quot; :('
  id: '5748910971099512321'
  image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
  name: "\u0441\u0447\u0430\u0441\u0442\u043B\u0438\u0432\u0447\u0435\u0433"
  profile: https://www.blogger.com/profile/11133937069073997736
  pub: '2016-07-24T16:37:48.701+02:00'
  ref: '8414821127925297259'
  type: comment
- date: 17 August 2016 14:16
  html: we have 650+ ms at our links across Yamal 402 satellite and among the IP-telephony
    thing, which is running smooth, the modem TCP-acceleration works pretty good for
    multiple concurrent TCP-sessions, even when there is a significant oversub. When
    the traffic is encapsulated even to basic GRE, the modem can do nothing to it,
    and the key role is granted to an in-path device like Riverbed.
  id: '1143062177735424084'
  image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
  name: Unknown
  profile: https://www.blogger.com/profile/01237403787756994036
  pub: '2016-08-17T14:16:15.319+02:00'
  ref: '8414821127925297259'
  type: comment
count: 11
id: '8414821127925297259'
type: post
url: 2016/07/tcp-congestion-avoidance-on-satellite.html
