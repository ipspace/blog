comments:
- comments:
  - date: 30 May 2016 13:19
    html: You guessed what the next video in the series will be ;)
    id: '719880835314874862'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2016-05-30T13:19:22.053+02:00'
    ref: '2885844746971438364'
    type: comment
  date: 29 May 2016 21:35
  html: I agree having 6 x 1GE links per physical server harkens back to 2004. I remember
    visiting a state of the art DC run by Telus Canada in 2004. We needed 14 servers
    and their sales and solution&#39;s team were showing us around and I remember
    them pitching how rock solid their servers were because they had 8 physical NICs
    to keep the traffic types physically separated. Now DCs such as Rackspace offer
    10G bonded links, and soon 25G interfaces will start showing up. So we are in
    a time where we might have to throw out those old recipes and start experimenting
    to come up with new ones!
  id: '2885844746971438364'
  image: https://lh4.googleusercontent.com/-Q0taauURPZk/AAAAAAAAAAI/AAAAAAAAAaU/QVOK58HC4LQ/s32-c/photo.jpg
  name: Antonio de Sousa
  profile: https://www.blogger.com/profile/11864545777285752230
  pub: '2016-05-29T21:35:36.827+02:00'
  ref: '1997704038084936277'
  type: comment
- comments:
  - date: 30 May 2016 13:25
    html: Thanks for mentioning the Always-On Availability Groups. While I did study
      how database replication works in SQL Server, it must have been before SQL Server
      2012, and the implementation was a bit kludgy. Now (with the Availability Group
      Listener) it makes even more sense.
    id: '5500824554448995021'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2016-05-30T13:25:57.556+02:00'
    ref: '6791927764360472782'
    type: comment
  date: 29 May 2016 21:47
  html: One other thing, its not sufficient to just focus on hardware. I think engineering
    and operations teams need to think about their applications and how they are deployed.
    Case in point, how did we provide high availability in the past? sometimes we
    would use something like Veritas cluster manager and other times we would build
    something similar through various building blocks like Windows Server Failover
    Clustering at the host level, then layering SQL Server Failover Clustering, and
    now layering on Microsoft&#39;s Always On Availability groups which required shared
    storage through a SAN. But now with VMware DRS and HA services and the fact that
    Always On Availability groups no longer requires shared storage we are challenged
    with how to utilize the best parts of these products to build a highly available
    service that&#39;s easy to maintain and provides the best value to the business.
    Interesting times!<br />
  id: '6791927764360472782'
  image: https://lh4.googleusercontent.com/-Q0taauURPZk/AAAAAAAAAAI/AAAAAAAAAaU/QVOK58HC4LQ/s32-c/photo.jpg
  name: Antonio de Sousa
  profile: https://www.blogger.com/profile/11864545777285752230
  pub: '2016-05-29T21:47:02.913+02:00'
  ref: '1997704038084936277'
  type: comment
- date: 31 May 2016 21:06
  html: "Optimize your data center: <br /><br />Ditch the proprietary technologies:<br\
    \ /><br />i.e. software depencies:<br /><br />VMWare VSAN<br />VMware NSX<br />3Par\
    \ SAN<br />:<br /><br />Let\xB4s fill that list...<br /><br /><br />"
  id: '4372066119838169618'
  image: https://resources.blogblog.com/img/blank.gif
  name: Anonymous
  profile: null
  pub: '2016-05-31T21:06:32.153+02:00'
  ref: '1997704038084936277'
  type: comment
count: 5
id: '1997704038084936277'
type: post
url: 2016/05/optimize-your-data-center-ditch-legacy.html
