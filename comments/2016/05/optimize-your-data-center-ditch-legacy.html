<div class="comments post" id="comments">
  <h4>5 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="2885844746971438364">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/11864545777285752230" rel="nofollow">DourCdn</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2885844746971438364" href="#2885844746971438364">29 May 2016 21:35</a>
              </span>
            </div>
            <div class="comment-content">I agree having 6 x 1GE links per physical server harkens back to 2004. I remember visiting a state of the art DC run by Telus Canada in 2004. We needed 14 servers and their sales and solution&#39;s team were showing us around and I remember them pitching how rock solid their servers were because they had 8 physical NICs to keep the traffic types physically separated. Now DCs such as Rackspace offer 10G bonded links, and soon 25G interfaces will start showing up. So we are in a time where we might have to throw out those old recipes and start experimenting to come up with new ones!</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="719880835314874862">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c719880835314874862" href="#719880835314874862">30 May 2016 13:19</a>
              </span>
            </div>
            <div class="comment-content">You guessed what the next video in the series will be ;)</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6791927764360472782">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/11864545777285752230" rel="nofollow">DourCdn</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6791927764360472782" href="#6791927764360472782">29 May 2016 21:47</a>
              </span>
            </div>
            <div class="comment-content">One other thing, its not sufficient to just focus on hardware. I think engineering and operations teams need to think about their applications and how they are deployed. Case in point, how did we provide high availability in the past? sometimes we would use something like Veritas cluster manager and other times we would build something similar through various building blocks like Windows Server Failover Clustering at the host level, then layering SQL Server Failover Clustering, and now layering on Microsoft&#39;s Always On Availability groups which required shared storage through a SAN. But now with VMware DRS and HA services and the fact that Always On Availability groups no longer requires shared storage we are challenged with how to utilize the best parts of these products to build a highly available service that&#39;s easy to maintain and provides the best value to the business. Interesting times!<br /></div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="5500824554448995021">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5500824554448995021" href="#5500824554448995021">30 May 2016 13:25</a>
              </span>
            </div>
            <div class="comment-content">Thanks for mentioning the Always-On Availability Groups. While I did study how database replication works in SQL Server, it must have been before SQL Server 2012, and the implementation was a bit kludgy. Now (with the Availability Group Listener) it makes even more sense.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4372066119838169618">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4372066119838169618" href="#4372066119838169618">31 May 2016 21:06</a>
              </span>
            </div>
            <div class="comment-content">Optimize your data center: <br /><br />Ditch the proprietary technologies:<br /><br />i.e. software depencies:<br /><br />VMWare VSAN<br />VMware NSX<br />3Par SAN<br />:<br /><br />LetÂ´s fill that list...<br /><br /><br /></div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
