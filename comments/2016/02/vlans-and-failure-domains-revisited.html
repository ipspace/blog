<div class="comments post" id="comments">
  <h4>1 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="2155045349610877567">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2155045349610877567" href="#2155045349610877567">26 February 2016 18:06</a>
              </span>
            </div>
            <div class="comment-content">Speaking as one who has worked in the &quot;I will get into trouble&quot; category, there are a lot of issues with lots of macs and ips in a single vlan.<br /><br />1) how switch vendors implement mac table in cam and what happens on table row overflow can be an issue.  one vendor implements cam table as a list of buckets with a set number of entries per bucket.  macs are hashed into buckets and the switch experiences fault when a bucket gets full.  this can be outage inducing for affected macs that cannot be reliably learned.  (not all vendors malfunction, but this is something one should be aware of).<br /><br />2) switch vendors do not engineer switches for extreme scale.  make sure to ask vendors the gritty details of implementation of mac and arp tables when in your environments.  some vendors next hop tables are inefficient when utilizing lag (port-channel) for example, and stated maximums cannot be hit.  some vendors support next hop table reprogramming for shared next hops.  this can be helpful if you have many ips per mac, but of little use if you have many macs.<br /><br />3) as has been commented here and on packet-pushers, nerd nobs aren&#39;t always the best idea.  resist the temptation to turn on ill advised knobs to allow for engineering a larger layer 2; things like BUM disable.  it makes life difficult when new hosts are on the network or in the face of switch reboot.<br /><br />4) mac acls in relation to item 3 do not scale easily unless you have automation going for you.<br /><br />5) network meltdown isn&#39;t always limited to overloading dci or uplink connections; one could easily put in a pps limit for BUM traffic. in the face of network loops, if arp replies are looped through the network, the mac address of the destination host might get programmed out incorrect ports in switching gear.  game over.</div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
