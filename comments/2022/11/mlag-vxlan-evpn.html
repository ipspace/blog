<div class="comments post" id="comments">
  <h4>2 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="1494">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> AW</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1494" href="#1494">09 November 2022 02:16</a>
              </span>
            </div>
            <div class="comment-content"><p>Thanks! This answer some questions I&#39;ve had for a long time.</p>

<p>The other question I have had is how does failover speed compare when a link is lost in EVPN ESI MLAG versus LACP? And is there a control mechanism to detect a bad link that still has link status but is not forwarding like the LACP heartbeats?</p>
</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="1495">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1495" href="#1495">09 November 2022 05:35</a>
              </span>
            </div>
            <div class="comment-content"><p>... and you gave me a topic for another blog post ;) Thank you!</p>

<p>Long story short:</p>

<ul>
<li>You still need LACP, EVPN is a PE-PE control-plane protocol, there&#39;s no change on the PE-CE side.</li>
<li>I found an article (and lost a link to it) saying EVPN is much slower than traditional MLAG, but I see no reason why that would be the case unless you&#39;re dealing with a broken implementation.</li>
</ul>
</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1496">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> TA</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1496" href="#1496">09 November 2022 05:58</a>
              </span>
            </div>
            <div class="comment-content"><p>&quot;However, the forwarding hardware limitations require anycast VTEP IP addresses&quot;</p>

<p>I can&#39;t comment on how other implementations work, but FRR/Cumulus implementation of MAC-ECMP does not fallback on anycast.
What you said about forwarding hardware requiring a single destination for a MAC is accurate, but their implementation achieves MAC-ECMP by pointing the fdb entry (mac) at single destination that is an ECMP container holding the VTEP address of each member of the remote ESI rather than pointing to a single VTEP address.</p>

<p>In Linux, the ECMP container is implemented using &quot;nexthop&quot; objects (one nexthop &quot;group&quot; pointing to several nexthop entries).
FRR populates an ES cache based on &quot;per ES&quot; Type-1 routes, which maintains a list of active VTEP addresses per ESI. One NHG is allocated in the kernel per known ESI and one NHE is allocated per active VTEP. When a MAC is learned via the remote ESI, the VXLAN driver&#39;s fdb entry points to the ID of the nexthop group (&quot;nhid&quot;) for a hash lookup to select which underlay DIP will be used.</p>

<p>In Mellanox ASICs the same principle applies - an ECMP container is allocated based on the kernel NHG and it contains underlay VTEP addresses. So the hardware fdb points to the ECMP container to select a remote underlay DIP for the VXLAN tunnel (not anycast) and then the encapsulated packet goes through the route lookup based on the DIP returned by the ECMP hash lookup.</p>
</div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
