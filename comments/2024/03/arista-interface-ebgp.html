<div class="comments post" id="comments">
  <h4>3 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="2152">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Daniel S</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2152" href="#2152">22 March 2024 10:12</a>
              </span>
            </div>
            <div class="comment-content"><p>Hi Ivan, 
we did a few projects using this method and it works absolutly great and you can use mostly the same configlets in CVP for all switches, that makes it really handy. 
For the command &quot;&zwnj;ip routing ipv6 interfaces&quot;; I learned it during testing for the first project where we used this and its basically a switch to allow routing through your box with IPv4 over IPv6 interfaces. Without that command, we could send data from a leaf to the spine. But the spine did just nothing, it was a blackhole. Only with that command the forwarding would work and then everything was fine. </p>
</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="2154">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2154" href="#2154">22 March 2024 03:28</a>
              </span>
            </div>
            <div class="comment-content"><p>Thanks for the feedback. I think I got it to work without the &quot;ip routing ipv6 interfaces&quot;, but of course, that was in a virtual lab.</p>

<p>Maybe I didn&#39;t make the network big enough (so I had no transit switches), or the Linux TCP/IP stack (cEOS container) accepts IPv4 packets, whereas the forwarding ASIC is not programmed to accept them without that magic nerd knob.</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2333">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Eric D</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2333" href="#2333">10 July 2024 12:41</a>
              </span>
            </div>
            <div class="comment-content"><p>I happened to trip across the Arista TOI that details why this knob exists. Can confirm it&#39;s a forwarding ASIC knob that is only relevant for some hardware platforms. Just in case you need a solid reference:</p>

<p>https://www.arista.com/en/support/toi/eos-4-17-0f/13784-ip-addressless-forwarding-changes-for-bgp-v6-nexthop-for-v4-routes</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2334">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2334" href="#2334">10 July 2024 07:50</a>
              </span>
            </div>
            <div class="comment-content"><p>Thanks a million for confirming that!</p>
</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2153">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Dan Massameno</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2153" href="#2153">22 March 2024 01:54</a>
              </span>
            </div>
            <div class="comment-content"><p>This is some neat config.  Not needing to configure explicit IP addresses on links is a simplification.  KISS.</p>

<p>But it strikes me that the entire industry lost out when we didn&#39;t do SPB or TRILL.  Specifically, I like how Avaya did SPB.</p>

<ol>
<li><p>IS-IS as an interior routing protocol can handle 1,000s of routers.  We don&#39;t need anything more scalable like BGP unless you&#39;re AWS/Microsoft/Google/Facebook.</p></li>
<li><p>IS-IS doesn&rsquo;t need addressing because it&rsquo;s an ISO protocol.  As long as the interface can run Ethernet, an adjacency can form.  No IPv4 or IPv6 addresses needed, link-local or otherwise.</p></li>
<li><p>Keep in mind, all this &ldquo;Interface EBGP Session&rdquo; stuff is needed to bootstrap all the other stuff we will need: multi-protocol BGP, adjusting the NLRI in BGP, VXLAN-GPO, loopbacks for the VTEPs, routing protocols to coordinate with the devices in the overlay (e.g., firewalls), etc. </p></li>
</ol>

<p>Agghh!   Why are we making this so complex?  I&rsquo;m probably preaching to the choir on this forum.  </p>
</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="2157">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Daryll Swer</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2157" href="#2157">23 March 2024 05:33</a>
              </span>
            </div>
            <div class="comment-content"><p>I&#39;m all up for 100% (okay, more like 99.99%) layer-3 eBGP driven networks. SP, DC, Enterprise, Home Lab? Everything 100% (meaning 99%) eBGP Driven networks. Easy to configure, easy to manipulate/traffic engineer with granular route filters with various attributes such as BGP communities, no full-mesh nonsense (or route reflectors) as was/is the case with iBGP. eBGP all the way to the host on DC networks, BGP multipathing included for your network-level load balancing for K8s (or possibly Docker Swarm) clusters etc, augmented with BGP communities to influence paths from host upto the DFZ even. With BGP, you can build unconventional topologies in any shape or form as you see fit. IGPs make the network flat and hence have some limitations.</p>

<p>Here&#39;s an example of why IGPs simply don&#39;t scale for TE properly:
https://anuragbhatia.com/2022/04/networking/isp-column/inefficient-igp-can-make-ebgp-go-wild/</p>

<p>When I say eBGP driven layer 3-only networks, it does not imply that MPLS isn&#39;t in use, it doesn&#39;t imply that VXLAN/EVPN isn&#39;t in use (for DC networking), these &ldquo;transport&rdquo; protocols are very much in use, but they are BGP driven, such as BGP signalled VPLS. It also does <em>not</em> imply IGPs aren&#39;t in use - they are, but they are limited in functionality to the purpose of only establishing loopback learning/adjacency for adjacent peers in a network segment (like say an MPLS cloud) or path.</p>

<p>BGP, at most basic operational use, is very easy to work with and scales if you need it to.</p>

<p>However, currently, there&#39;s not much documentation or blog posts or tutorials on how to design eBGP driven SP networks (which is something I do in production), there is some documentation for DCs, but even that largely assumes a typical Spine/Leaf/Clos topology. I&#39;ve worked in a DC environment where we took some inspiration from the hypercube network topology concept (and therefore it really wasn&#39;t a clos topology) and everything was 100% eBGP, up-to the host, almost everything was interconnected on layer 1 for adjacent devices Spine&lt;&gt;Spine, Leaf&lt;&gt;Leaf etc &mdash; It was more like a mix of SP and DC networking.</p>

<p>The basic visual representation of this eBGP approach:
Vertical paths = eBGP up/down with private ASN numbering and default routes for egress back up. remove-private-as on the edge routers that talks DFZ.
Horizontal paths = IGP + iBGP or IGP/LDPv6 etc as and when required for loopback learning.</p>

<p>So coming to &ldquo;numbering&rdquo;, I would probably be okay with &ldquo;unnumbered&rdquo; (link-local IPv6) interfaces for establishing adjacency for the horizontal paths. However, for the vertical paths, I&#39;d still use route-able IPv6 GUA addressing to help make my life easier when running a traceroute or troubleshooting etc.</p>

<p>But at the same time, life&#39;s easy for numbered IPv6 GUA interfaces if you use something similar to my geographical denomination model for IP(v6) addressing architecture:
https://www.daryllswer.com/ipv6-architecture-and-subnetting-guide-for-network-engineers-and-operators/</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2165">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Daniel S</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2165" href="#2165">28 March 2024 07:58</a>
              </span>
            </div>
            <div class="comment-content"><p>I&#39;m absolutly behind you on. For the folks working with BGP all day, its nice to have it everywhere. For everybody else (and thats 90% of networking guys and girls)  BGP is a hellhole which they don&#39;t want to touch. Those people are really left behind with all the fabrics. Even after multiple trainings and workshops, they still forget what is in the underlay or overlay and don&#39;t know why you would build stuff like that.
And everybody that worked with SPB or Fabricpath will totally agree. I had a few years working with Fabricpath. After understanding how everything worked together, it was so easy. You couldn&#39;t do something wrong. Absolutly perfect for a DC. Would have loved to deploy that in campus if the boxes would have supported it. 
And we know why Cisco dropped it. After many years they officially told us that it was scrapped because they wanted to push ACI. They absolutly knew that Fabricpath was good enough for 90% of enterprises and ACI would never take off. </p>
</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2390">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Shubham</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2390" href="#2390">19 August 2024 08:49</a>
              </span>
            </div>
            <div class="comment-content"><p>thank you for this, helped alot.
Is there a way we don&#39;t have to specify any remote-as ?
external keyword is missing in arista OS?</p>
</div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
