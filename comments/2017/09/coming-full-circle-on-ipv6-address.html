<div class="comments post" id="comments">
  <h4>10 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="837906261115624676">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/17783635023339781751" rel="nofollow">Innokentiy</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c837906261115624676" href="#837906261115624676">26 September 2017 12:22</a>
              </span>
            </div>
            <div class="comment-content">What a wonderful idea! Do all vendors support iBGP over link-local addresses already? Or we&#39;re supposed to use eBGP?</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="9040741334691193156">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Denis Borchev</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c9040741334691193156" href="#9040741334691193156">26 September 2017 14:10</a>
              </span>
            </div>
            <div class="comment-content">What about RIP?<br />Simple RIP should be enough for this purpose (advertise /64, receive a default)</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7588665308462425968">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7588665308462425968" href="#7588665308462425968">26 September 2017 14:22</a>
              </span>
            </div>
            <div class="comment-content">Of course it would do, but RIP is so 1990s ;) ... aka the days when some server admins still understood networking.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1109432651585616258">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/08900264515934620482" rel="nofollow"> HEMANTH RAJ</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1109432651585616258" href="#1109432651585616258">26 September 2017 15:30</a>
              </span>
            </div>
            <div class="comment-content">Hi Ivan<br /><br />We run dynamic ibgp/ebgp peering with servers downstream on both IPv4/IPv6 on tors .<br />Dynamic bgp on ipv4: /26<br />Dynamic bgp on IPv6 : /64 <br />We don&#39;t use link local for this IPv6 peering . We use global addressing for this dynamic range peering.<br />Neighbor 2001::/64  sample config <br /><br />Backend to the servers : dynamic IPv6 ibgp peering for /64. The rest /64 would be eui64 format.<br />Bgppeering on servers runs on static configuration because range cannot form neighborhsip on both sides.<br /><br />Link local is fine but we need dynamic bgp peering and hence needed global addressing and server address  would be in the  same range as on th  vlan /64 address. <br /><br />Seamless running on bgp. <br /><br />Link local is link specific and may not be useful for dynamic peering.<br /><br /><br /><br /><br /></div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="937811453178521533">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/08816918401268619102" rel="nofollow">Alex Savva</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c937811453178521533" href="#937811453178521533">27 September 2017 02:21</a>
              </span>
            </div>
            <div class="comment-content">It&#39;s called Internet Logical Addressing (ILA)<br />https://www.youtube.com/watch?v=AZ1gRPUyklw</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="827510514853092636">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/09023765657674084072" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c827510514853092636" href="#827510514853092636">27 September 2017 05:17</a>
              </span>
            </div>
            <div class="comment-content">The 8+8 split is not unique to ILA, to be fair - the idea has been re-used multiple times in few proposals :)<br /><br />In basic (probably, most common) applicable scenario one does not even need any routing protocol - the ToR switches can be configured with /64 static routes pointing to servers, which, in turn, have static link-local addresses. The ToR does summarize /64&#39;s into shorter block, and so on.<br /><br />The major benefit is being able to allocate IP per process/container/etc. I think one of the Google&#39;s paper was open to admit that going with IP per box for Borg and then juggling available ports per process/container was a major pain.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4681647650843240484">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/08900264515934620482" rel="nofollow"> HEMANTH RAJ</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4681647650843240484" href="#4681647650843240484">27 September 2017 07:37</a>
              </span>
            </div>
            <div class="comment-content">@petr static routes aren&#39;t scalable rite. Tor can configure static routes pointing to server link local address and if we have 20 servers downstream and we need to have 20 static routes on the tor.and tor has to load share traffic downstream based on 20 static routes. <br />Does this affect dynamic bgp based multipathing . <br />Or we have static routes towards control servers and load share it so that actual data content balancing happens on control to data servers.<br /></div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7810624636564779764">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/08900264515934620482" rel="nofollow"> HEMANTH RAJ</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7810624636564779764" href="#7810624636564779764">27 September 2017 07:43</a>
              </span>
            </div>
            <div class="comment-content">@petr bgp downstream peering also shares multipathing towards control servers and control servers takes care of data path forwarding.<br />And also static routes pointing to link local address is bit tedious as it requires the nd  cache population to receives servers link local address which would be fe80::/10 and adds 48 bits + FFFE format . It&#39;s best to have dynamic bgp peering to advertise content blocks upstream from bgp and form bgp peering with control servers</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="514198029945293031">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/09023765657674084072" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c514198029945293031" href="#514198029945293031">28 September 2017 16:53</a>
              </span>
            </div>
            <div class="comment-content">worked fine for us :) we considered using BGP injection, but this adds additional component to deploy and monitor at every server, which is more overhead. there is no scaling issues at all, state is static, pre-configured, and aggregated. management churn was mainly on provisioning side - making sure servers and switches are rebuilt with proper configs, but that was mostly a one-time thing to solve. For link locals - those can be also statically configured, say by encoding the server# within a rack.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="8306325218498730962">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/08900264515934620482" rel="nofollow"> HEMANTH RAJ</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8306325218498730962" href="#8306325218498730962">29 September 2017 09:42</a>
              </span>
            </div>
            <div class="comment-content">Sure petr configuring static link locals on all the servers is time consuming and includes fault mgmt manual provisioning as you said . rather than using plug and play IPv6 link locals. <br />But that&#39;s a good point that you mentioned for bgp overhead which is always a separate control plane component . <br />How many servers are there per rack and how do you provision manual link local on servers starting with FE80/10 and the rest with your own addressing .</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
