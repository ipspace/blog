comments:
- comments:
  - date: 20 November 2017 16:07
    html: And that&#39;s because we can&#39;t treat &quot;software upgrade&quot; as
      business-as-usual, because too many times something fails. People who deploy
      stuff weekly (or even multiple times per day) don&#39;t have that problem ;)
    id: '3954694467577572094'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2017-11-20T16:07:42.785+01:00'
    ref: '1072829814144919968'
    type: comment
  date: 20 November 2017 14:21
  html: CLI, API, in either case most of the time is wasted waiting for the operations
    framework to give network team a green light for the upgrade.  Too many sign-offs,
    conf calls, political posturing, etc.
  id: '1072829814144919968'
  image: //images-blogger-opensocial.googleusercontent.com/gadgets/proxy?url=http://1.bp.blogspot.com/-j3GGfKuoRb4/VYDmEVI9C7I/AAAAAAAAAjs/aj4cvQNi2uk/s151/IMG_1013.JPG&container=blogger&gadget=a&rewriteMime=image/*
  name: Jeff Behrns
  profile: https://www.blogger.com/profile/09771677856264877238
  pub: '2017-11-20T14:21:18.372+01:00'
  ref: '4003859029451692791'
  type: comment
- date: 21 November 2017 00:16
  html: I think that many of us have used the blunt instruments at our disposal (Expect
    etc.) to automate the upgrade of the unfriendly products that we have to work
    with, with varying degrees of success and reliability. So in my experience much
    of the challenge of deploying new code is that our testing approach is usually
    still back in the dark ages, and not sufficiently rigorous to convince the change
    management processes and other stakeholders that we should go ahead.<br /><br
    />Roll on the day when we actually create Ansible playbooks (or the equivalent
    in any other tool) that test out all of the features that we&#39;re actually using
    in a switch/router. Even better being able to spin up a virtual copy of your environment
    and prove the actual software or configuration change in situ and automatically
    test and validate the operation of they system afterwards. Perhaps then we get
    closer to being on a par with our application development colleagues with their
    CICD pipelines and put ourselves in a position where we are trusted to make these
    sorts of changes quickly and frequently.
  id: '9004252148833121369'
  image: https://resources.blogblog.com/img/blank.gif
  name: David Cryer
  profile: http://www.linkedin.com/in/david-cryer
  pub: '2017-11-21T00:16:31.443+01:00'
  ref: '4003859029451692791'
  type: comment
- date: 21 November 2017 15:17
  html: Other side is keeping track of new updates, that can be a full time job. Vendors
    have also done a poor job of this. We need something like WSUS to easily handle
    updates. It should be part of regular operations like it is for server people.
  id: '2898889545395617658'
  image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
  name: Unknown
  profile: https://www.blogger.com/profile/09992235844690768695
  pub: '2017-11-21T15:17:24.197+01:00'
  ref: '4003859029451692791'
  type: comment
- date: 21 November 2017 16:34
  html: Often there is no reason to upgrade if no fixes for bugs/vulnerabities are
    contained that apply to the network and no new features are required.<br />So
    after studying release notes if there is no practical advantage it is often better
    to stay with a proven stable release (and keep rolling out new devices on the
    same software release).<br /><br />Of course when an update is required there
    should be an efficent automated process minimizing the risk and the goal should
    be to have a consistent SW release across all devices again within a reasonable
    time frame.<br /><br />So as I see it network devices often run older releases
    if nothing is to be gained from an update.
  id: '2618832667102260095'
  image: https://resources.blogblog.com/img/blank.gif
  name: Anonymous
  profile: null
  pub: '2017-11-21T16:34:33.369+01:00'
  ref: '4003859029451692791'
  type: comment
- date: 22 November 2017 17:48
  html: An important aspect is the terrible quality of network device software. You
    install a new version and a lot of things are broken. You have a perfect configuration
    in software simulation, but it does not work with hardware optimized devices,
    since the porting is never finished and barely tested by the vendor. The documentation
    is just a bad joke, the support forums are full with unanswered questions.<br
    /><br />There is so much bad experiences that most network engineers are reluctant
    to touch a working system for good reasons. You should change to a better environment
    with fully automated regression testing. However, when you look at the new SDN
    projects, the same problems come back. Everyone is rushing to include new features,
    and the automated testing have less than 10-20% coverage.<br /><br />No one wants
    to pay for quality. Good enough is the target... :-)<br />
  id: '4506258808989959976'
  image: https://lh4.googleusercontent.com/-t7xwu4fY91Y/AAAAAAAAAAI/AAAAAAAAByc/AStXb-jqQyY/s32-c/photo.jpg
  name: "B\xE9la V\xE1rkonyi"
  profile: https://www.blogger.com/profile/07985346761439657130
  pub: '2017-11-22T17:48:13.278+01:00'
  ref: '4003859029451692791'
  type: comment
- date: 23 November 2017 12:04
  html: 'Hi.<br /><br />Thanks for the article.<br /><br />I see different aspects
    of this problem from my SP window:<br /><br />1 - Technical: you covered it in
    the article. Tools did not exist in the past for network devices, and this is
    being adressed/is already adressed on most platforms.<br /><br />2 - Risk culture:
    despite all this new new fancy features to ease and speed software upgrades, it
    still takes ages to upgrade a network (weither it&#39;s 10 device for a small
    entreprise or 1000+ device for a SP backbone). Human factor is important. Telcos
    for example have a strong quality culture and risk control history, and it&#39;s
    hard for them to imagine upgrading several devices (even 5) in parallel, in one
    shot, by something totaly automated. What if it goes wrong? What if this loop
    is not secured? What if the NOC did not restore an IGP metric during the last
    maintenance window?<br /><br />3 - Checks at scale: upgrading is easy. Checking
    the state of the device or the traffic before, after, and compare it at scale
    is a challenge. You need those checks to validate your software ugprade is a success
    or to engage a rollback. Worst: it&#39;s not apple to apple comparison: you have
    churn in your IGP routes (so you end up with a small difference), you might have
    trafic shifting somewhere else because BGP<br />Worst: most routers deep health
    check are vendor dependant, platform dependant and software dependant. It&#39;s
    a tough one to manage. From past experiences, you add more and more checks, and
    end up with a crazy list. Again, automation could help. I also think telemetry
    could help: you shoud be able to confidently say you routeur is capable of taking
    production traffic looking at a dashboard containing key metrics.<br /><br />Finally,
    if your network is correctly designed, if your architecture redundancy is regularly
    tested (or you are confident it&#39;s working) and you have correct tools, you
    don&#39;t have any technical excuses to regularly roll out new software releases
    at scale. Now, I think as network professionals we should also adress the human
    factor/education for risk.<br /><br />For the first point you mentioned (why it
    takes so long to validate a software and why new releases are so buggy), I will
    come back in the comments but with my vendor hat this time ;-)<br /><br />Fred'
  id: '7835436839679595473'
  image: https://resources.blogblog.com/img/blank.gif
  name: Frederic Cuiler
  profile: https://twitter.com/fcuiller
  pub: '2017-11-23T12:04:22.503+01:00'
  ref: '4003859029451692791'
  type: comment
- date: 29 November 2017 12:41
  html: 'There is only so much automation can do for a poor monolithic architecture.
    To realize CD for network software, remember we are crossing the vendor-operator
    divide which is greater than the Dev-Ops divide, but I think it is eventually
    possible by taking a page from the architecture that set DevOps and general software
    CD on fire over the past few years: microservices. I&#39;ve recently written about
    it in fact: https://www.linkedin.com/pulse/micro-services-knock-knockin-devnetops-door-james-kelly/ '
  id: '396047941894532147'
  image: https://lh4.googleusercontent.com/-wuZNPqdJNGA/AAAAAAAAAAI/AAAAAAAA8GU/SJDZhjF9IAE/s32-c/photo.jpg
  name: James Kelly
  profile: https://www.blogger.com/profile/00358549302880805285
  pub: '2017-11-29T12:41:50.394+01:00'
  ref: '4003859029451692791'
  type: comment
count: 8
id: '4003859029451692791'
type: post
url: 2017/11/why-does-it-take-so-long-to-upgrade.html
