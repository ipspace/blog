<div class="comments post" id="comments">
  <h4>12 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="5556754104609469041">
          <!--
          <div class="avatar-image-container">
            <img src="https://4.bp.blogspot.com/-ZOXsPp2jWZM/WLFLiMZondI/AAAAAAAADJ4/Ut7WBaNvJIInOF_9feWqAIeZiw3nyuEmwCK4B/s32/en2.jpg">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/04707560608698340062" rel="nofollow">Andras Dosztal</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5556754104609469041" href="#5556754104609469041">07 June 2017 13:20</a>
              </span>
            </div>
            <div class="comment-content">&quot;Large chassis switches are precious, and you don’t want them to fail. Ever. Welcome to the morass of ISSU, NSF, graceful restart.&quot;<br /><br />Well, it depends. :) Even a large enterprise, working 24/7/365, has less busy hours when you can afford losing 16-25% of your bandwidth (with 4-6 chassis switches as spines). In such case, just reload that switch and have a coffee while it&#39;s booting.<br /><br />Disclaimer: large enterprise ≠ public cloud providers (obviously).</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="6639023314129203575">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6639023314129203575" href="#6639023314129203575">07 June 2017 15:25</a>
              </span>
            </div>
            <div class="comment-content">I didn&#39;t say &quot;reload&quot;. I said &quot;fail&quot; ;)) ... and if you have 6 spine switches, you don&#39;t need any of the high-availability mechanisms, but you can&#39;t get rid of them in a chassis switch (of course you can decide not to use them).</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="5235783799148539445">
          <!--
          <div class="avatar-image-container">
            <img src="https://3.bp.blogspot.com/-0yDrxa0sfWI/V5sF6eo4q6I/AAAAAAAAHAs/n3VkBY82SbgXVnHCcCDSY7_sOZaHvufEwCK4B/s32/avatar.jpg">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/10268349264835307217" rel="nofollow">Donatas Abraitis</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5235783799148539445" href="#5235783799148539445">07 June 2017 13:23</a>
              </span>
            </div>
            <div class="comment-content">I 200% agree, that it doesn&#39;t matter how many switches do you manage if it&#39;s already automated. I prefer small devices over big chassis.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1849515777713988734">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Attilla</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1849515777713988734" href="#1849515777713988734">07 June 2017 18:13</a>
              </span>
            </div>
            <div class="comment-content">You can use a chassis with all the downsides you mentioned. The Facebook Backpack or the similar model from Accton which are basically a CLOS in a box, would take away most of those arguments. <br /><br />What would you think of using those chassis? <br /><br /></div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="444515762781378050">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c444515762781378050" href="#444515762781378050">07 June 2017 18:38</a>
              </span>
            </div>
            <div class="comment-content">Have you read the whole blog post and followed the links?</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6766775450628515198">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Gunter Van de Velde</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6766775450628515198" href="#6766775450628515198">08 June 2017 14:59</a>
              </span>
            </div>
            <div class="comment-content">I agree... smaller switches tend to result in smaller failure domains, simpler connectivity issues and increased overal standardised behaviour... when automating all provisioning &amp; maintenance operations, then even the length of each patch cable in the DC could be pre-provisioned and its length pre-calculated etc... Its how i know some (really) big DCs run their DC Fabrics rather effectively. To me, bigger chassis for switching tends to give bigger problems... smaller pizza box type of components seems the IKEA style of DC switch fabrics and delivers its job perfectly while at same time give benefit in cost and quality and understanding in components used...</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2473710391201817832">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Roman Romanyak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2473710391201817832" href="#2473710391201817832">09 June 2017 16:23</a>
              </span>
            </div>
            <div class="comment-content">What&#39;s your opinion about management network? We build a spine and leaf network, but every switch is still connected to one big layer-2 management switch. Until recently we didn&#39;t have stp and storm control enabled in management network, and we accidentally created a l2 loop while adding a virtual chassis member to the management network. This l2 loop brought down RE on all ip fabric switches, some REs even dumped core. After that we enabled rstp and storm control, retested the loop and everything is fine. But we are wondering whether we should break down this l2 management network into smaller domains. Not sure what is the best practice...</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="5757457903258398878">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5757457903258398878" href="#5757457903258398878">09 June 2017 16:29</a>
              </span>
            </div>
            <div class="comment-content">I really don&#39;t understand why you&#39;d use layer-2 across multiple management switches (unless layer-3 switches were too expensive ;). After all, wiring is fixed, addresses are fixed, DHCP relaying is usually available on decent switches...</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="5389837766880231064">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Roman Romanyak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5389837766880231064" href="#5389837766880231064">09 June 2017 20:37</a>
              </span>
            </div>
            <div class="comment-content">thanks for your feedback Ivan, I really appreciate it. <br /><br />We have layer-2 across multiple management switches partially due to the legacy reasons. We are using juniper EX copper switches bonded in virtual chassis, so there is no problem with layer-3, or DHCP support. VC size is limited up to 10 switches, so we have a couple of VC clusters. Each cluster is a separate layer-3 domain. <br />The alternative solution would be having a dedicated small management network per rack. It has some drawbacks, such as - additional complexity (will have to write additional ansible templates for management switches), subnetting existing management subnet or introducing new management subnets. </div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1905914115943331807">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/11059947665554553037" rel="nofollow">Pere Camps</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1905914115943331807" href="#1905914115943331807">01 December 2017 00:39</a>
              </span>
            </div>
            <div class="comment-content">Hello!<br /><br />Don&#39;t know if this is the right blog post to comment this on, but this seems relatively appropiate and it is far newer than the rest. :)<br /><br />I&#39;m considering deploying Juniper&#39;s Virtual Chassis Fabric in my core and I&#39;m facing a dilemma<br /><br />I&#39;ve never used VCF before and I don&#39;t know how stable it is during operations, how do upgrades really work and what happens when individual switches fail.<br /><br />I&#39;m so unsure of it all that I&#39;m thinking that I should consider a VCF a single failure domain (even if it is multiple discrete switches) and if we end up going that way then we really need 2x VCFs setup in the datacentre (with all that it entails -- reminds me of FC)<br /><br />If we move around the issue a little we could say: EVPN VXLAN and an overlay... could I then consider having a single &#39;fabric&#39;? <br /><br />In summary: given the tons of different &#39;fabric&#39; options that we have these days, which ones could be considered a &quot;single failure domain&quot; and which ones not?<br /><br />Any thoughts?</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="5982943575273182702">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5982943575273182702" href="#5982943575273182702">01 December 2017 08:44</a>
              </span>
            </div>
            <div class="comment-content">I actually have a blog post written on the subject, just have to publish it. And yes, you&#39;re correct, VCF is a single failure domain.<br /><br />I know a very large customer who&#39;s using two QFabric fabrics per data center (very much like SAN-A/SAN-B), so your idea of using two VCFs is not exactly outlandish.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3413528222314841189">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/11059947665554553037" rel="nofollow">Pere Camps</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3413528222314841189" href="#3413528222314841189">01 December 2017 09:18</a>
              </span>
            </div>
            <div class="comment-content">I&#39;ll wait for the blogpost then! :)<br /><br />My guess:<br /><br />MC-LAG/VC/VCF/QFabric/JunOS Fusion: single<br />IP Fabric/EVPN VXLAN: not a single<br />NSX (not really the same thing but you get the idea I hope): I don&#39;t know enough, I hope not single!<br /><br />At the end of the day I guess that if the devices are able to work completely indepedently of each other for all operations (except exchanging routes to the neighbours and forwarding &amp; receiving frames) then its not a single failure domain</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
