comments:
- comments:
  - date: 14 November 2018 12:22
    html: When everyone is talking about shiny new hammers, all your problems start
      to resemble nails... ;)
    id: '9019411257786245573'
    image: https://lh3.googleusercontent.com/-ZIhwz6bLuK0/AAAAAAAAAAI/AAAAAAAAFtg/mLtCQ3p4_0E/s32-c/photo.jpg
    name: Ivan Pepelnjak
    profile: https://www.blogger.com/profile/13457151406311272386
    pub: '2018-11-14T12:22:00.836+01:00'
    ref: '5584002837560844766'
    type: comment
  - date: 14 November 2018 12:51
    html: '... which you could all knock in at a single blow :D gorgeous!'
    id: '6509837212119550903'
    image: https://resources.blogblog.com/img/blank.gif
    name: Anonymous
    profile: null
    pub: '2018-11-14T12:51:41.520+01:00'
    ref: '5584002837560844766'
    type: comment
  date: 14 November 2018 12:07
  html: Thought that containers were originally developed for specific functions (micro
    services, distributed systems comes to mind) not server virtualization. So it&#39;s
    the &quot;right tool for the right job&quot; problem.
  id: '5584002837560844766'
  image: https://resources.blogblog.com/img/blank.gif
  name: Anonymous
  profile: null
  pub: '2018-11-14T12:07:48.473+01:00'
  ref: '9210189763043140542'
  type: comment
- date: 14 November 2018 15:25
  html: Well, to be honest, the (A) problem is not that difficult to solve. Just connect
    your containers to IPVLAN/MACVLAN interfaces and all of a sudden you factored
    out all possible virtual NATs and bridges. The (B) problem is also easy. The current
    generation of VNFs are simply BNFs (physical servers) wrapped as VMs, so they
    will use the same service discovery mechanism they used before, which usually
    is statically assigned IPs with maybe something like DNS SRV on top, but again
    nothing new and definitely not container-native service discovery. The (C) problem
    is solvable with a combination of SR-IOV, MACVLAN and DPDK inside the container
    or various smart NICs with hardware offloads.<br />In my experience, the biggest
    issue with the whole VNF story is that they still use the same (legacy) assumptions
    and HA mechanisms they did in the baremetal world. So things like VRRP between
    container/VMs is a common thing. One of the worst things you can see though is
    some dataplane VNFs requiring dynamic routing peering with the network underlay.
    Think OSPF+BFD with BGP on top that need to peer with your TOR switch. In the
    end, after you&#39;ve satisfied all their requirements, the VNF gets pinned to
    a single server, which effectively turns it back into a baremetal NF, with a few
    intermediate container and VM layers in between. Let&#39;s call this 5G.
  id: '5809141278194785882'
  image: https://resources.blogblog.com/img/blank.gif
  name: Anonymous
  profile: null
  pub: '2018-11-14T15:25:23.703+01:00'
  ref: '9210189763043140542'
  type: comment
- date: 14 November 2018 15:29
  html: Sure, it makes sense that doing things on commodity hardware is cheaper than
    doing things on bespoke hardware. But in practice, NFV purists in general (and
    Telcos in particular) often (incorrectly) translate this into &quot;everything
    should be done in software on general purpose CPUs&quot;. There are many things
    that can be done orders of magnitude more efficiently and cheaply in hardware
    specificically designed for that task rather than in general purpose hardware.
    Forwarding packets is an obvious example. Machine learning is a more recent one.
    That said, the non-general-purpose hardware designed specifically for the task
    can still be commodity. &quot;Commodity hardware&quot; does not necessarily imply
    &quot;general purpose CPUs&quot;.
  id: '7571795544980944737'
  image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
  name: Bruno Rijsman
  profile: https://www.blogger.com/profile/03852194681637032116
  pub: '2018-11-14T15:29:08.323+01:00'
  ref: '9210189763043140542'
  type: comment
- date: 14 November 2018 23:32
  html: Just use carrier-grade k8s with a /24 of public IPs on each host!
  id: '7525108891426345766'
  image: https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35
  name: Wes Felter
  profile: https://www.blogger.com/profile/01395217775195260835
  pub: '2018-11-14T23:32:48.281+01:00'
  ref: '9210189763043140542'
  type: comment
count: 6
id: '9210189763043140542'
type: post
url: 2018/11/vnfs-and-containers-heptagonal-pegs-and.html
