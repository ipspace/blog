<div class="comments post" id="comments">
  <h4>11 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="6444301996655398271">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6444301996655398271" href="#6444301996655398271">28 March 2018 12:56</a>
              </span>
            </div>
            <div class="comment-content">Whether it&#39;s VXLAN (probably BGP EVPN) or VPLS (probably Kompella) or PBB or what have you, you still suffer the full mesh scale problem. In my opinion you can&#39;t fix that with a route server because it would become the central chokepoint. Especially with 1 Terabit/s links.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2163280466966970964">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2163280466966970964" href="#2163280466966970964">28 March 2018 16:50</a>
              </span>
            </div>
            <div class="comment-content">The premise here is not correct, most large IXP operators have deployed VXLAN or VPLS for their Layer-2 domain already. EVPN may be in use in newer IXPs as well but I haven&#39;t seen any specific cases of this myself.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="4869283745443516376">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4869283745443516376" href="#4869283745443516376">28 March 2018 17:12</a>
              </span>
            </div>
            <div class="comment-content">VPLS - agreed, many.<br /><br />VXLAN - would love to hear about more of them. Any pointers you can share?</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6233802019565582696">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6233802019565582696" href="#6233802019565582696">28 March 2018 18:29</a>
              </span>
            </div>
            <div class="comment-content">So it&#39;s time to create some value for the community. I just did a 5 minutes Google research. INEX migrated to VXLAN, see here: http://docs.ixpmanager.org/features/layer2-addresses/ . They also created a so called IXP Manager with Saltstack (NAPALM) and it has also a nice Web GUI https://www.ixpmanager.org/media/2017/201709-nlnog2017-automation-with-ixp-manager.pdf. So we can now create our won IXP.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4741447354521153311">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4741447354521153311" href="#4741447354521153311">28 March 2018 18:32</a>
              </span>
            </div>
            <div class="comment-content">&quot;I just did a 5 minutes Google research.&quot; &lt;&lt; touche ;)<br /><br />Love the ixpmanager you found. Thanks a million!</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4679024670228295780">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://l33.fr" rel="nofollow">Blake</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4679024670228295780" href="#4679024670228295780">29 March 2018 17:32</a>
              </span>
            </div>
            <div class="comment-content">It&#39;s well known that the LoNAP IXP fabric is VXLAN on Arista R-series (but provisioned via automation, not BGP EVPN):<br />e.g.<br />http://www.trefor.net/2016/05/25/lonap-ripe/</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1607539390323833939">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.lonap.net" rel="nofollow">Will Hargrave</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1607539390323833939" href="#1607539390323833939">30 March 2018 10:52</a>
              </span>
            </div>
            <div class="comment-content">LONAP CTO here!<br /><br />We&#39;re a mid-sized IXP (~200 networks connected, ~3Tbit connected capacity) who have been running VXLAN on Arista for around two years now, with great results. This is in a &#39;flood and learn&#39; config with Head-End-Replication (HER) - i.e we are replicating BUM at the edge to all other edge nodes. We are doing some testing with EVPN-on-VXLAN although it is worth noting it doesn&#39;t have some of the compelling advantages for an IXP as it does for a L2/L3 datacentre network. <br /><br />Our friends over at INEX are in a similar setup for their primary LAN, which I think they deployed during 2017.<br /><br />We started down this road in mid-2015 after a failed deployment of VPLS/MPLS with another vendor, and it swiftly became clear that a &#39;datacentre class&#39; leaf-spine architecture with something like VXLAN was the way to go for a growing IXP of our size. ECMP has let us scale easily from n*10G to n*100G in the core and with VXLAN, the imposition of entropy on the source UDP port means intermediate network elements can effectively loadbalance the traffic. <br /><br />As regards the topic of large l2 networks &#39;spanning the globe&#39;, I think we need to take a step back from technology and look at human and commercial factors. By far the most popular model for IXP charging is a low flat-rate per-port model. It is more difficult to keep a control on costs if you have expensive leased capacity there, which is why successful IXPs keep to the metro where they can scale easily and avoid competing with their own members. <br /><br />Moreover there is an expectation among network operators that the endpoint of their BGP session across the fabric is relatively nearby. Long-stretched L2 domains are unpopular among many as they mess up this assumption, cause hairpinning and thus bad enduser experience. There is a role for stretched IXP model - i.e. &#39;reseller&#39; programs and the like, under controlled conditions. But most operators prefer to meet over a fast, local fabric in the metro. <br /><br />LONAP in her 21 years of existence has seen many such &#39;global IX&#39; operators come and go. :)</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="1566183053135902432">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1566183053135902432" href="#1566183053135902432">30 March 2018 11:19</a>
              </span>
            </div>
            <div class="comment-content">Thanks a million for your feedback - and the business perspective of why long-distance IXPs make little sense.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3612791223725221704">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.foobar.org" rel="nofollow">Nick Hilliard</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3612791223725221704" href="#3612791223725221704">30 March 2018 10:53</a>
              </span>
            </div>
            <div class="comment-content">vxlan generally works better for ixps than vpls. There are some major wins in terms of compexity reduction, including no requirement for lsp management and out-of-the-box load-balancing over parallel links in the ixp core. This is messy to handle in vpls because most silicon out there won&#39;t inspect L4 headers when creating n-tuple hashes for load-balancing. So you end up either having to use expensive hardware or else building multiple lsps between each PE, with traffic load-balanced by the PE on a per-LSP basis. This doesn&#39;t scale well because you end up with O(PE^2) LSPs on your network<br /><br />EVPN control plane for vxlan isn&#39;t ready for production networks yet.  Hopefully soon.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="4599754377651762238">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4599754377651762238" href="#4599754377651762238">30 March 2018 11:21</a>
              </span>
            </div>
            <div class="comment-content">Hi Nick! So nice to hear from you after a long long time.<br /><br />Thanks for the feedback (and yet again: I love your software).</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2054211891924054100">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.six.sk" rel="nofollow">Marian Ďurkovič</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2054211891924054100" href="#2054211891924054100">15 April 2018 11:27</a>
              </span>
            </div>
            <div class="comment-content">Exactly those reasons lead us to build SIX.SK on top of TRILL back in 2014. Simple, straightforward and stable for almost 4 years. One bonus point - BUM traffic is in TRILL distributed natively, without the need for central replication. </div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
