{
  "comments": [
    {
      "comments": [
        {
          "date": "27 September 2018 13:49",
          "html": "&quot;If you lose reachability to C1 from L1 just because a single link fails, then let&#39;s hope L1 isn&#39;t the switch where your management workstation/Nagios host/et.c is connected.&quot; &lt;&lt; Correct. In most data center fabrics you&#39;d have an out-of-band management network (oftentimes configured as isolated management VRF by default).",
          "id": "3404953438905295976",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2018-09-27T13:49:46.698+02:00",
          "ref": "2609429769238202837",
          "type": "comment"
        }
      ],
      "date": "27 September 2018 11:37",
      "html": "If you lose reachability to C1 from L1 just because a single link fails, then let&#39;s hope L1 isn&#39;t the switch where your management workstation/Nagios host/et.c is connected.  Because then you won&#39;t be able to ssh to C1, or talk SNMP to C1, to see what&#39;s wrong with it...",
      "id": "2609429769238202837",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Bellman",
      "profile": null,
      "pub": "2018-09-27T11:37:26.950+02:00",
      "ref": "3710626195755245011",
      "type": "comment"
    },
    {
      "comments": [
        {
          "date": "27 September 2018 13:50",
          "html": "This time it&#39;s not about convergence, it&#39;s about reachability. If L1 cannot reach C1 after a link failure, having BGP session between directly-connected interfaces or between loopbacks makes absolutely no difference (apart from one being more complex than the other).",
          "id": "6248171198846902549",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2018-09-27T13:50:53.909+02:00",
          "ref": "5852044186495044611",
          "type": "comment"
        },
        {
          "date": "27 September 2018 14:06",
          "html": "Why should L1 reach C1? C1 is only in the data plane not in the control plane for EBGP underlay, isn&#39;t it?",
          "id": "6969105643479917670",
          "image": "https://resources.blogblog.com/img/blank.gif",
          "name": "Anonymous",
          "profile": null,
          "pub": "2018-09-27T14:06:52.286+02:00",
          "ref": "5852044186495044611",
          "type": "comment"
        },
        {
          "date": "27 September 2018 14:13",
          "html": "Underlay = physical transport network. Every device is in the control plane for underlay routing protocol (which in this particular case is assumed to be EBGP because RFC 7938).",
          "id": "6940365716498165324",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2018-09-27T14:13:13.463+02:00",
          "ref": "5852044186495044611",
          "type": "comment"
        },
        {
          "date": "27 September 2018 14:53",
          "html": "So your ideal solution has:<br /><br />- An EBGP session interface-to-interface<br />- Use this session to advertise IP connectivity (i.e. act as the IGP)<br />- Use this session to advertise EVPN routes<br /><br />In this case, what do you expect the BGP next hop for the EVPN routes to be? I think it&#39;s got to be the loopback address so that the other leaf nodes can reach it via ECMP across C1 and C2. Is the reason that some vendors want to run a separate EBGP session loopback-to-loopback for EVPN because they can&#39;t advertise the EVPN routes with a different next hop to that of the IP routes? ",
          "id": "6111279251117085122",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Unknown",
          "profile": "https://www.blogger.com/profile/07947810603415969811",
          "pub": "2018-09-27T14:53:14.705+02:00",
          "ref": "5852044186495044611",
          "type": "comment"
        },
        {
          "date": "27 September 2018 15:47",
          "html": "I knew there was another gotcha ;))<br /><br />Yes, the EVPN next hop must always remain the VTEP (loopback) IP address of the egress leaf. You just gave me another reason why some vendors insist so adamantly on using BGP sessions between loopbacks...",
          "id": "133780656200964678",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2018-09-27T15:47:48.350+02:00",
          "ref": "5852044186495044611",
          "type": "comment"
        }
      ],
      "date": "27 September 2018 13:26",
      "html": "I don&#39;t understand your concerns about EVPN underlay. Normally you would have ECMP for the loopbacks. So in the case of a link failure the reconvergence time depends on:<br />1) How fast the device detects the failure<br />2) How long does it take to recompute a backup path<br />3) How long does it take to propagate the changes to the neighbors<br />4) Time to install the backup path in hardware<br /><br />So with directly connected links and backup paths already installed in hardware, I don&#39;t see a big problem or am I overlooking something?",
      "id": "5852044186495044611",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Anonymous",
      "profile": null,
      "pub": "2018-09-27T13:26:02.337+02:00",
      "ref": "3710626195755245011",
      "type": "comment"
    },
    {
      "comments": [
        {
          "date": "27 September 2018 15:45",
          "html": "You&#39;re absolutely right. See also <br /><br />https://blog.ipspace.net/2018/05/is-ospf-or-is-is-good-enough-for-my.html<br />https://blog.ipspace.net/2018/08/is-bgp-good-enough-with-dinesh-dutt-on.html<br /><br /><br />Unfortunately this industry is brimming with lemmings... and what was good enough for Microsoft data center must be good enough for my two switches, right? RIGHT? RIGHT???",
          "id": "6780470655972444411",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2018-09-27T15:45:13.796+02:00",
          "ref": "3442406751483848150",
          "type": "comment"
        }
      ],
      "date": "27 September 2018 15:06",
      "html": "I pains me to see all the discussion about the details of using BGP in the underlay (fabric). Why so complex ? 20-25 Years ago we already established that the best routing design for networks is: an IGP in the underlay, to discover the topology, and BGP in the overlay to carry reachability for large numbers of destinations.<br /><br />I would think this is still the simplest and most elegant solution. Use IS-IS in the fabric, and EVPN in the overlay. Why isn&#39;t this the most popular design still ? Is IS-IS not good enough ? Are IS-IS implementations not good enough these days ?<br /><br />If that is the case, improve IS-IS. Don&#39;t misuse BGP. Using BGP as an IGP is like using assembly to build a website. It works, but it is ugly. Fix the shortcomings in the IS-IS protocol. Fix IS-IS implementations. Is the industry really unable to do this ? Rift, LSVR, openFabric, they all seem overkill to me. Just fix what&#39;s broken, don&#39;t re-invent the wheel.",
      "id": "3442406751483848150",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Henk",
      "profile": null,
      "pub": "2018-09-27T15:06:21.353+02:00",
      "ref": "3710626195755245011",
      "type": "comment"
    },
    {
      "date": "27 September 2018 19:38",
      "html": "Couple of comments:<br /><br />1) One can put the Spine switches in different ASNs - Is a bit of extra I/O but does the trick<br />2) IS-IS in the underlay would be a better solution as it can be deployed with existing implementation  -<br />a bit of mesh-group config on the leafs and you can control the flooding explosion of vanilla IS-IS implementations - finally UUNets top scaling feature is been used again after almost 20 years of hibernation ;-)",
      "id": "3835784471036990088",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Hannes Gredler",
      "profile": null,
      "pub": "2018-09-27T19:38:48.431+02:00",
      "ref": "3710626195755245011",
      "type": "comment"
    },
    {
      "date": "28 September 2018 05:46",
      "html": "\u201camen\u201d<br />everything could be made work with infinite efforts of turning all possible knobs one could imagine OR let\u2019s make eBGP behave like iBGP?!?! Why going so far if the solution is that near?<br />",
      "id": "8094679408083064212",
      "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
      "name": "Unknown",
      "profile": "https://www.blogger.com/profile/07774968935660590770",
      "pub": "2018-09-28T05:46:14.186+02:00",
      "ref": "3710626195755245011",
      "type": "comment"
    },
    {
      "comments": [
        {
          "date": "28 September 2018 12:56",
          "html": "When you spent three decades developing a hammer, every sandwich (and tin can) looks like a nail :D<br /><br />However, you have to solve fundamental challenges like failure detection, path checks, fast rerouting/convergence, minimization of FIB rewrites... so in the end it&#39;s not exactly a 10K line-of-code problem either as some (religiously correct) SDN vendors discovered a while ago.",
          "id": "3371065195624182021",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2018-09-28T12:56:09.109+02:00",
          "ref": "208436532269380250",
          "type": "comment"
        }
      ],
      "date": "28 September 2018 10:29",
      "html": "At the risk of heresy, given that this is a well known leaf spine configuration within a data center, wouldn&#39;t it be far simpler to avoid the protocols entirely and simply calculate the forwarding tables of the underlying ASICs directly, a la an InfiniBand solver?<br /><br />Yes, I understand the link and switch failure/repair cases need to be dealt with, and no I&#39;m not talking about the theoretical SDN case so popular a decade ago.  <br /><br />This is a 10,000 line of code problem at the switch level, not a 10,000,000 line of code problem.  Just saying.",
      "id": "208436532269380250",
      "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
      "name": "Steve Chalmers",
      "profile": "https://www.blogger.com/profile/03172563417086934763",
      "pub": "2018-09-28T10:29:09.360+02:00",
      "ref": "3710626195755245011",
      "type": "comment"
    }
  ],
  "count": 14,
  "id": "3710626195755245011",
  "type": "post",
  "url": "2018/09/implications-of-valley-free-routing-in.html"
}