<div class="comments post" id="comments">
  <h4>12 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="8720966634893782302">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/07931582409793748608" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8720966634893782302" href="#8720966634893782302">25 February 2015 00:11</a>
              </span>
            </div>
            <div class="comment-content">From the linked article:  &quot;Virtualization of addresses does not need to interfere with that, if we simply use a service that implements private namespaces on top of public IP addresses, there is no need even for tunnels (Russian doll encapsulation).&quot;<br /><br />Isn&#39;t he basically describing NAT/PAT without using those terms?  Am I missing something here?</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="3055029082736658347">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/01395217775195260835" rel="nofollow">Wes Felter</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3055029082736658347" href="#3055029082736658347">25 February 2015 23:23</a>
              </span>
            </div>
            <div class="comment-content">I had the same interpretation. Overlays are an abomination so let&#39;s replace them with... NAT.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1212814185334312799">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/02344251820597347343" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1212814185334312799" href="#1212814185334312799">26 February 2015 19:38</a>
              </span>
            </div>
            <div class="comment-content">Need some more coffee but think he was just suggesting multi-tenancy should be enforced with other things besides L2 and the network should focus on routing traffic to endpoints. The interwebs works because it focuses on L3, why all the duct tape and bandaids inside the datacenter. However, if everything was truly peer-to-peer on a shared L3 medium, multi-tenancy would require encryption at the endpoints (ex. SSL vs. L2 vlan). i.e. EndpointA in Tenant Group 1 in DC1 needs to securely communicate with Endpoint B also in Tenant Group 1. Industry came close to a *full* peer-to-peer world with IPV6 as one of goals was to increase address space and reduce need for multiplexing with PAT/SNAT (i.e. let go of idea of end nodes in tenant domains sharing same address space ... they all get their own unique address which are ephemeral as mac addresses).  However, until the holy grail where all endpoints (client/server apps) let go of L2, assume L3 world and use encryption on all their communication (both intra-tenant and public),  PAT/SNAT (which requires the &quot;dreaded&quot; state) is a pretty nice fenced house with one way door. Although I have to say, as a tenant, even if I have my own firewall (iptables) and diligently communicate securely with all my peers (SSL), being bare on exposed on the internet taking 10G of L7 attacks on my own front door doesn&#39;t sound so fun :-). As the old saying goes, the internet is unfortunately a lot nastier than most neighborhoods so even though a lock on your door is good,  sometimes funneled ( or dreaded &quot;state&quot; )  access through a gated community is certainly nice.  back to coffee++  </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1186718323053688542">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1186718323053688542" href="#1186718323053688542">02 March 2015 17:29</a>
              </span>
            </div>
            <div class="comment-content">You have to ensure that a tenant retains its privacy (which can be done with packet filters), not that it gets private IP addresses (which would require NAT or some sort of tunnels).<br /><br />Like Mark wrote in his essay, you cannot dictate what your room# will be in the hotel. We should stop assigning overloaded meanings to IP addresses.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="375100040402657374">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/02344251820597347343" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c375100040402657374" href="#375100040402657374">06 March 2015 01:12</a>
              </span>
            </div>
            <div class="comment-content">True. Side effect of multiplexing.  The point was really more agreeing to the premise that application owners have come around and want less L2 (spanning), not more.  They’ve practiced, taken off their training wheels and quickly adapted to the stateless L3 chaos monkey AWS environments and are looking for network as simple transit. <br /> <br />http://thenewstack.io/docker-acquires-sdn-technology-startup-socketplane-io/<br /><br />See you are definitely not alone<br /><br />Will only be a matter of time until they self service their own tenancy/privacy/group membership up the stack  (ex. whether peer-to-peer encryption or identity based/certificate trust domains/etc.). By the time everyone finally deploys overloaded L2 architectures, app-owners will probably have moved on. <br /><br />Anyway, exciting times.  As always, thanks for sharing! <br /></div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4807064828298380568">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4807064828298380568" href="#4807064828298380568">25 February 2015 00:40</a>
              </span>
            </div>
            <div class="comment-content">Mark Burgess&#39;s blog seems to be a tirade against overlays and slavishly virtualizing the physical network, whereas your blog seems to suggest that overlays might the solution with L2 only going to the vswitch, with presumably L3 in physical network (and the overlay slavishly virtualizing the physical)-- so these are completely opposite conclusions!<br /><br />Or am I missing something?<br /></div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6425928342582942663">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Bryan</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6425928342582942663" href="#6425928342582942663">25 February 2015 01:09</a>
              </span>
            </div>
            <div class="comment-content">Imagine if we could just get rid of L2. Every network device did L3. No need to ARP for your gateway, just put the packet on the wire and let the next device figure it out. </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2880796505821629132">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Marian Ďurkovič</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2880796505821629132" href="#2880796505821629132">25 February 2015 11:06</a>
              </span>
            </div>
            <div class="comment-content">Well, your article as well as Mark Burgess&#39;s blog both point to a serious failure of the networking industry to deliver ubiquitous state-of-the art L2 technology.<br /><br />Back in 2001 (i.e. long before VPLS), the group of IXP operators proposed to redesign L2 according to L3 best-practices - by replacing thick yellow cable emulation and all Spanning tree stuff with IS-IS based routing of ethernet packets. Guess what - no vendor was interested. When Radia Perlman in 2004 presented the first TRILL proposal to IEEE, it was - rejected.<br /><br />Several years later, two next-gen L2 standards were finalized - TRILL (based on L3 principles) and SPB (enhanced STP). Yet worse, every major vendor implemented its own next-gen L2 solution, of course totally incompatible with any of the standards. In the meantime, hacks like M-LAG (vPC) were developed to workaround apparent defficiences of outdated L2 technology.<br /><br />In such a mess, it&#39;s no surprise that people consider L2 unusable and try to avoid it whereever possible. Hypervisor vendors decided to fix the problem in their own domain by yet another method (VXLAN, NVGRE,...) but this requires new NIC hardware and only works in DC environment. As such it&#39;s no solution to the main problem, since advanced L2 is needed in every LAN to get rid of thick yellow cable emulation and STP limitations.<br /><br />Just FYI, in September 2014 we implemented TRILL-based infrastructure in the Slovak Internet eXchange. After 5 months of production, our experience shows that even though TRILL delivers standard L2 interface on the edge ports, inside it operates on exactly the same principles as any L3 network, utilizing field-proven IS-IS protocol for ethernet frame routing and TTL &amp; RPF checks to prevent network meltdown.<br /><br />So decent L2 technology definitely exists today - but the main problem is that the networking industry is unable to converge on single technical solution due to commercial reasons. This couldn&#39;t be fixed by resorting to L3.<br /></div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="5460600276972247512">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/08793477579744395999" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5460600276972247512" href="#5460600276972247512">25 February 2015 19:00</a>
              </span>
            </div>
            <div class="comment-content">Wasn&#39;t LISP an attempt to separate the IP address from the Location Identifier?</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6945482257461962730">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.jeffbehrns.com" rel="nofollow">Jeff Behrns</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6945482257461962730" href="#6945482257461962730">26 February 2015 02:49</a>
              </span>
            </div>
            <div class="comment-content">Best quote from the essay:<br /><br />&quot;I see people arguing for a dynamic infrastructure. That is wrong thinking. Infrastructure and foundations are meant to be stable. What you build on top of that can be dynamic.&quot;</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7080563467096795687">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/00999352568102477737" rel="nofollow">Phil Bedard</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7080563467096795687" href="#7080563467096795687">27 February 2015 02:47</a>
              </span>
            </div>
            <div class="comment-content">I wrote a much longer post which got lost but to summarize.  <br /><br />L2 overlays came from VMs moving or being spun up wherever there was free compute.   It needed L2 because somewhere else another application or network element like a FW or LB was setup based on that VM/service having a specific IP.  That&#39;s the crux of the issue.   <br /><br />The L2 overlays are getting better.  Vendors are solving tromboning using anycasted default GWs, VXLAN can work with L3 directly into a VRF instead of just building a L2 overlay.  VXLAN-GPE supports direct v4/v6 encapsulation.  We have moved the underlay from L2 to L3.  <br /><br />However it will take an orchestration system to redirect endpoints as needed, or at least reprogram DNS entries if that&#39;s a valid option.  Contextream has a solution based on NVO3 overlays coupled with LISP.   So LISP takes care of the endpoint moving behind another IP address.  However LISP doesn&#39;t have great support, so maybe DNS is the answer, along with more intelligent upstream devices which don&#39;t care what IP something is at.   Junos Contrail is a L3 overlay, not a L2 overlay, and does so by using host routing over tunnels with a VNID/MPLS label as an identifier.  A firewall instance doesn&#39;t need to be in the same subnet as the end host, it just needs to know the tunnel to get to it.   Now it would be easier without tunnels altogether, but we aren&#39;t there yet.   <br /></div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="9162556380739491076">
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/08672736030841781375" rel="nofollow">Unknown</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c9162556380739491076" href="#9162556380739491076">11 March 2015 09:19</a>
              </span>
            </div>
            <div class="comment-content">Hi, <br />your post intrigues me... <br />How can you get rid of L2 when you have remote sides that need DHCP over public internet .. or when you run hotspots ? <br /></div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
