<div class="comments post" id="comments">
  <h4>10 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="2216742472564509397">
          <!--
          <div class="avatar-image-container">
            <img src="https://3.bp.blogspot.com/-H2V8oUucSto/VcDOK9ZBBSI/AAAAAAAAAv4/1DNQA1NWqyk/s32/laptop006%2Bas%2Bsouthpark%2Bcharacter.png">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/00108223150670314820" rel="nofollow">Julien Goodwin</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2216742472564509397" href="#2216742472564509397">04 August 2015 13:58</a>
              </span>
            </div>
            <div class="comment-content">Even more if you consider pps-per-tco$<br /><br />A recent (even five year old) asic-based vendor router is almost certainly using less power for the same traffic. This might not be as significant or matter that much if you don&#39;t need terabits of performance though.<br /><br />I do think it&#39;s a shame that there&#39;s not a vendor (at least that I&#39;m aware of) making a box which is a nice Xeon server with a fully-plumbed EZchip (one of the higher end ones capable of doing internet scale routing) with a decent SW plumbing layer on top. The software to do useful carrier internet routing on linux is finally getting complete enough you could consider deploying it.<br /><br />The pluribus ones come closest of those I&#39;m aware of, but have the downside of a second switch chip, and needing to run their OS.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="2012209774118120713">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2012209774118120713" href="#2012209774118120713">04 August 2015 15:04</a>
              </span>
            </div>
            <div class="comment-content">Xeon+EZChip would be an awesome combo, particularly with modular OS on top of it (Cumulus comes to mind). We just need someone who wants to buy thousands of these boxes ;))<br /><br />As for Pluribus - if I got it right (and I have no idea, because they never got to the technical details in their Tech Field Day presentations), all they have in their proprietary hardware is extra 10GE lanes to the Xeon CPU, making it possible to do more than what you can squeeze on the PCI bus between Trident-2 and CPU. Obviously that advantage goes away the moment you deploy their SW on whitebox HW.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="288851721976954836">
          <!--
          <div class="avatar-image-container">
            <img src="https://3.bp.blogspot.com/-H2V8oUucSto/VcDOK9ZBBSI/AAAAAAAAAv4/1DNQA1NWqyk/s32/laptop006%2Bas%2Bsouthpark%2Bcharacter.png">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/00108223150670314820" rel="nofollow">Julien Goodwin</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c288851721976954836" href="#288851721976954836">04 August 2015 16:49</a>
              </span>
            </div>
            <div class="comment-content">Cumulus do seem best placed on the software side.<br /><br />For the hardware the best I&#39;ve seen is what I have in my personal lab, a 2 slot ATCA chassis with a Xeon box in one slot, and an EZchip based switch in the other. Of course this is all ancient kit, but current gen stuff does exist and is probably feasible.<br /><br />Shame there doesn&#39;t seem to be any vendors really looking to roll this up, would be a fun thing to build.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7085032526398307113">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.hazard.maks.net" rel="nofollow">Vladimir Ivashchenko</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7085032526398307113" href="#7085032526398307113">04 August 2015 14:10</a>
              </span>
            </div>
            <div class="comment-content">Hosting routers on VM poses the same risks as doing any other things in a shared resource environment. I&#39;ve seen one VM influencing performance and causing network interruptions to other VMs on the same hypervisor. Also latency is generally higher in case of VM routers.</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="8000510549152353254">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8000510549152353254" href="#8000510549152353254">04 August 2015 15:01</a>
              </span>
            </div>
            <div class="comment-content">Agreed on both counts. However:<br /><br />* If you want to have reliable NFV deployment, you _SHOULD_ deploy VNFs (fancy names for VMs) on dedicated infrastructure and carefully manage the oversubscription;<br /><br />* While software-based forwarding always incurs more latency than hardware-based forwarding, I don&#39;t think it matters then moment the traffic hits the first WAN link.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4081842787140131007">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.hazard.maks.net" rel="nofollow">Vladimir Ivashchenko</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4081842787140131007" href="#4081842787140131007">04 August 2015 18:18</a>
              </span>
            </div>
            <div class="comment-content">The latency impact will be mostly felt when Virtual Router is handling local traffic that didn&#39;t originate or terminate into VMs. One has to be careful to consider which flows will traverse the VR when replacing physical with virtual. Virtualized environments are generally not great with handling of tasks that require real-time scheduling.<br /><br />And for the sake of example, Juniper VSRX (Firefly) adds latency of 5-10 ms on very light loads. E.g. if it serves some lonely VoIP call late at night, quality will suffer.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="5498144650766712226">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5498144650766712226" href="#5498144650766712226">04 August 2015 19:30</a>
              </span>
            </div>
            <div class="comment-content">5-10 msec latency just for traversing a VM is ridiculous, and has (IMHO) nothing to do with virtualization and all to do with suboptimal implementations.<br /><br />Thanks for the data point - it will definitely come handy ;)<br />Ivan</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="5004201706131204487">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/12675510409950425811" rel="nofollow">RPM</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5004201706131204487" href="#5004201706131204487">04 August 2015 23:07</a>
              </span>
            </div>
            <div class="comment-content">With regards to SSL termination... &quot;openssl speed rsa2048&quot; does 829 private-key ops (equivalent to RSA sig) per core per second on my 3-year-old laptop.<br /><br />So, let&#39;s round and guess 1500 *new* TLS connections per core per second on a modern server. Modern Xeon servers have at least 16 cores...<br /><br />Any application that is connecting and disconnecting that frequently is broken by design. The user experience would be terrible even without TLS overhead. Use keep-alive connections for HTTP, along with session resumption, and it really isn&#39;t a problem.<br /><br />We run a mid-size SaaS application doing SSL termination on just four Xeon cores spread across two load balancing nginx instances. They hover around 15%, and that includes handshakes and bulk crypto.<br /><br />CloudFlare, Google, Faceboox, etc. do NOT use hardware for SSL acceleration, because it just doesn&#39;t matter if you have HTTP keep-alive and session cache/ticketing enabled. I believe Google said turning on SSL increased their front-end server load by something like 2-3% overall.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="34996159128652135">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/09163909255125326094" rel="nofollow">liiwi</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c34996159128652135" href="#34996159128652135">06 August 2015 13:31</a>
              </span>
            </div>
            <div class="comment-content">Two key things are AES-NI support in processor and modern TLS library that has good support for AES-NI. Without either of those, you&#39;re in slow train.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2823514675788376953">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.amilabs.com" rel="nofollow">jsicuran</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2823514675788376953" href="#2823514675788376953">25 August 2015 15:02</a>
              </span>
            </div>
            <div class="comment-content">Interesting I wonder how this will change  with more use of HTTPV2 or SPDY.</div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
