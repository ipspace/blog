comments:
- date: 09 February 2011 14:12
  html: I&#39;m always interested in a better network design.  What would you recommend
    that still achieves server portability?
  id: '5381511150258904229'
  image: https://resources.blogblog.com/img/blank.gif
  name: lcg
  profile: null
  pub: '2011-02-09T14:12:20.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 09 February 2011 14:46
  html: As I wrote - there is nothing, because nobody was working on this problem
    for the last 5+ years.<br /><br />LISP in Nexus 1000V might be the answer, but
    I don&#39;t like the extra layer of encapsulation it introduces.
  id: '995690887920511518'
  image: https://resources.blogblog.com/img/blank.gif
  name: Ivan Pepelnjak
  profile: null
  pub: '2011-02-09T14:46:53.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 09 February 2011 14:49
  html: I must admit that the scale at which I am thinking is in the range of dozens
    of servers at most, but what is wrong with visualizing the first hop router? For
    every workload that needs mobility for outside of an ethernet domain, virtualize
    the default gateway.<br /><br />Your gateway would need VLAN interfaces for the
    VMs that it routes for, and an interface for some kind of &#39;OSPF adjacency&#39;
    VLAN in each datacenter. As your workload migrates from one datacenter (or cluster)
    to another one, once the virtualized router is migrated OSPF adjacencies are formed
    on the appropriate OSPF VLAN, and new routes to the workload are propagated to
    the network. Keep in mind that when your router is in one cluster or DC and your
    workload is in the other then no traffic flows.<br /><br />Problems:<br /> How
    do you keep your virtual router from advertising the routes for datacenter OSPF
    networks that it is not connected to? How does this scale beyond a workload that
    needs 1 Gbps of network throughput? How do you get access to the storage? Does
    VMware SRM take care of the second two?
  id: '5416508256698285708'
  image: https://resources.blogblog.com/img/blank.gif
  name: Anon2
  profile: null
  pub: '2011-02-09T14:49:24.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 09 February 2011 15:10
  html: Then I&#39;m not sure I understand the issue.  If there are no alternatives,
    then we&#39;re doing the best we can with the technologies available to implement
    desired capabilities that have immediate benefits.  Should we do nothing simply
    because it&#39;s not optimal, or because at some future time it will no longer
    scale under a set of particular assumptions?
  id: '5818208100224366525'
  image: https://resources.blogblog.com/img/blank.gif
  name: lcg
  profile: null
  pub: '2011-02-09T15:10:10.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 09 February 2011 15:59
  html: 'Solutions do exist: you can use load balancers or (even better) a more optimized
    application architecture. <br /><br />But all you&#39;re willing to do is &quot;move
    this VM to the other end of the world&quot;, then we have a problem ;) LISP can
    solve it, but (as I said) introduces yet another layer of encapsulation.'
  id: '2534666075205317561'
  image: https://resources.blogblog.com/img/blank.gif
  name: Ivan Pepelnjak
  profile: null
  pub: '2011-02-09T15:59:25.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 09 February 2011 16:05
  html: Load balancers require more integration with the application install and configuration.  That
    is much harder and more time consuming, and increases the ongoing operational
    maintenance activities (more servers = more work).  And not all applications can
    support it.  Again, we&#39;re dealing with the capabilities available now, not
    what we wish we had.
  id: '4811014296166538007'
  image: https://resources.blogblog.com/img/blank.gif
  name: lcg
  profile: null
  pub: '2011-02-09T16:05:54.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 09 February 2011 16:28
  html: It also increases costs because you have to license the additional server
    OS and application, as well as the load balancer.
  id: '8609650517217992361'
  image: https://resources.blogblog.com/img/blank.gif
  name: lcg
  profile: null
  pub: '2011-02-09T16:28:32.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 09 February 2011 17:36
  html: Ivan, the problem of clusters, security and other interesting stuff almost
    always can be solved with a good design in the application layer, and a little
    help from operating system, network &amp; storage.<br /><br />Nowadays, most applications  have
    bad designs and seek for a *a lot* of help from the operating system, network
    &amp; storage.<br /><br />The fact that most engineers in the last 10+ years do
    not have a broad view of the above areas, has led to the problems that you describe.<br
    /><br />It&#39;s the application (&amp; protocol) design that needs to be fixed!<br
    /><br />ps. Tell to the server admin to configure the application to perform all
    the network stuff from a loopback address and you can take care of the rest easily.
  id: '2323914923086232254'
  image: https://resources.blogblog.com/img/blank.gif
  name: John
  profile: null
  pub: '2011-02-09T17:36:46.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 09 February 2011 18:49
  html: I always thought that LAM failed because IOS wasn&#39;t able to hold enough
    routes in memory. The idea that /32 routes could exist in large volumes and be
    constantly updated meant the Cisco hardware was incapable of scaling to sufficient
    size.  (see TCAM, Memory, and undersized CPUs). <br /><br />Is that your view
    as well ?
  id: '5067675096924143599'
  image: https://resources.blogblog.com/img/blank.gif
  name: Etherealmind
  profile: null
  pub: '2011-02-09T18:49:49.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 10 February 2011 03:05
  html: Nicely timed post from Brad Hedlund...<br /><br />http://bradhedlund.com/2011/02/09/emergence-of-the-massively-scalable-data-center/
  id: '3298511912624462772'
  image: https://resources.blogblog.com/img/blank.gif
  name: lcg
  profile: null
  pub: '2011-02-10T03:05:30.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 10 February 2011 04:14
  html: '&gt; ps. Tell to the server admin to configure the application to perform
    all the network <br />&gt; stuff from a loopback address and you can take care
    of the rest easily.<br /><br />I&#39;ll second that. So often network engineering
    is an effort to solve problems of crappy application development and/or server
    deployment practices that could be easily fixed if app/server people could think
    just a little bit outside of their domain.'
  id: '8131633358684392540'
  image: https://resources.blogblog.com/img/blank.gif
  name: Ulan Mamytov
  profile: null
  pub: '2011-02-10T04:14:37.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 10 February 2011 08:04
  html: 'Absolutely. Love it. Did you notice how both proposals he finds sensible
    modify existing L2 or L3 behavior? Proves my point: we&#39;ve been too complacent
    for too long.'
  id: '4781358403997024980'
  image: https://resources.blogblog.com/img/blank.gif
  name: Ivan Pepelnjak
  profile: null
  pub: '2011-02-10T08:04:27.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 10 February 2011 14:06
  html: How does Cisco&#39;s OTV play into this scenario?
  id: '2416478260705148861'
  image: https://resources.blogblog.com/img/blank.gif
  name: chris j
  profile: null
  pub: '2011-02-10T14:06:09.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 10 February 2011 15:23
  html: Of course it wasn&#39;t *that* long ago that server OSes shipped with a routing
    daemon running by default (Solaris &amp; gated anyone?) and could advertise a
    /32 route (my employer still has that for one legacy &quot;cluster&quot;).<br
    /><br />Still doesn&#39;t scale nicely of course!  :)
  id: '862794636156717660'
  image: https://resources.blogblog.com/img/blank.gif
  name: Jon Still
  profile: null
  pub: '2011-02-10T15:23:05.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 10 February 2011 17:27
  html: IMHO, the whole idea behind what vMotion thinks it is trying to solve is suboptimal.
    If a service is so critical that one needs very high availability, put a load
    balancer in front of those servers. Requiring the network to be overly complicated
    or potentially unstable across an entire datacenter seems pretty crazy.<br /><br
    />Believe me when I say that I do not love load balancers. They are temperamental
    and expensive black boxes. They do provide a much more scalable solution than
    vMotion. My biggest problem with vMotion is that it allows application owners
    to be lazy. They will develop their software assuming that the network will always
    allow them to shift their services around. It won&#39;t challenge them to think
    about how to scale their service by orders of magnitude.<br /><br />There are
    all sorts of &quot;great&quot; protocols out there, like otv, that allow network
    engineers to come up with &quot;creative solutions&quot; to suboptimal service
    requirements. IMHO
  id: '3148957173381113964'
  image: https://resources.blogblog.com/img/blank.gif
  name: Peter John Hill
  profile: null
  pub: '2011-02-10T17:27:17.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 11 February 2011 08:56
  html: LAM sucks.  That&#39;s why it didn&#39;t succeed.  How can something based
    upon ARP/RARP be considered a viable solution?<br /><br />The meta-issue here
    isn&#39;t layer-2 vs. layer-3, it&#39;s a) the overloading of the IPv4 (and now
    IPv6) addresses with locator/EID information, b) the policy overloading of IPv4
    (and now IPv6) addresses with policy information via ACLs, firewall rules, et.
    al., and c) the continued worst practice of application developers further overloading
    IPv4 (and now IPv6) addresses by directly hardcoding IP addresses into their applications/platforms/services,
    instead of abstracting this away via a naming service (e.g., DNS, at least for
    now).
  id: '3180933601556719747'
  image: https://resources.blogblog.com/img/blank.gif
  name: Roland Dobbins
  profile: null
  pub: '2011-02-11T08:56:26.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 11 February 2011 10:46
  html: OTV is a slightly better bridging. Still doesn&#39;t scale (although at least
    they got rid of unknown unicast flooding).
  id: '3551672886171020582'
  image: https://resources.blogblog.com/img/blank.gif
  name: Ivan Pepelnjak
  profile: null
  pub: '2011-02-11T10:46:59.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 11 February 2011 10:48
  html: vMotion is not necessarily solving high-availability issues. It also provides
    load distribution / adjustment capabilities.<br /><br />As for the appdev laziness,
    I couldn&#39;t agree more with you ;)
  id: '8209566245045803156'
  image: https://resources.blogblog.com/img/blank.gif
  name: Ivan Pepelnjak
  profile: null
  pub: '2011-02-11T10:48:40.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 11 February 2011 10:51
  html: 'I absolutely agree with everything you wrote. However, you&#39;re missing
    an important point: live VM migration for load distribution purposes. It would
    be tough to implement persistent connections in that scenario ... unless we would
    have a robust session layer that would survive transport layer failures (and a
    very quick failure detection mechanism).'
  id: '2618387539010974267'
  image: https://resources.blogblog.com/img/blank.gif
  name: Ivan Pepelnjak
  profile: null
  pub: '2011-02-11T10:51:32.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 15 February 2011 21:22
  html: We&#39;re not waiting anymore.  We bought L2 service from a pair of national
    L2 service providers (their VPLS service) with large MTUs (4400 bytes) at all
    data centers and we are moving forward with VPLS.  Its there, its vendor interoperable.  It
    can be a pain in the ass, but it works.  We already have MPLS in our WAN core
    so it seems like the natural thing to do.
  id: '1609074720892247198'
  image: https://resources.blogblog.com/img/blank.gif
  name: ccie15672
  profile: null
  pub: '2011-02-15T21:22:28.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 15 February 2011 21:56
  html: Will you do L2 or L3 DCI? If you go for L2, what technology will you use?
    Just bridging with STP over (provider-delivered) VPLS or something fancier?
  id: '8672833181682628091'
  image: https://resources.blogblog.com/img/blank.gif
  name: Ivan Pepelnjak
  profile: null
  pub: '2011-02-15T21:56:34.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 16 February 2011 03:17
  html: Sorry for being ambiguous..  <br /><br />We&#39;re buying large MTU CoS-enabled
    multi-point VPLS from two different providers (for redundancy).  Over top of this
    service, we run our own MPLS infrastructure.  We terminate the access circuits
    on P nodes that we manage.  Looking at the header of a packet in one of the two
    service-provider&#39;s networks you would see  something like ETH|MPLS|MPLS|ETH|MPLS|MPLS|ETH.    With
    the rightmost ethernet header being one of our customers (internal or external),
    the left two MPLS tags being our own VPLS and transport tags, the middle ethernet
    header belonging to one of our own P nodes... then everything to the right of
    that belonging to one of the two service providers (and therefore invisible to
    us).<br /><br />So we are running our own L3VPN and L2VPN/VPLS services for one
    of many internal L2 or L3 networks.  Think many lines of business each with their
    own web tier, app tier, storage tier, etc...  Some components are shared, many
    are not.  Multiple network teams with a fair degree of autonomy (because business
    units themselves are marketable things that can broken off and sold whole).  Even
    some of the web tiers within individual lines of business are so large they are
    broken into multiple logically isolated networks.  <br /><br />We have piles of
    L2 and L3 DCI requirements.  We have multiple vendors in the network and server
    spaces, so we looked at the problem as if we were a service-provider ourselves
    and decided to turn our network into a service rather than what it is/was... which
    was many parallel circuits poorly utilized owned by different groups and in total
    costing us outrageous amounts of money.  <br /><br />Which is more info than what
    you were looking for.  From my team&#39;s perspective OTV would be something that
    one or some of these lines-of-business might buy into and we would provide a multipoint
    VPLS service in support of that.  I think we are a pretty good case study on why
    its just wrong to compare OTV and VPLS like they are competing technologies.
  id: '9078882725914769905'
  image: https://resources.blogblog.com/img/blank.gif
  name: ccie15672
  profile: null
  pub: '2011-02-16T03:17:03.000+01:00'
  ref: '6663754495548952529'
  type: comment
- date: 16 February 2011 07:29
  html: Thanks for an extensive answer. You&#39;re doing exactly what I would recommend
    someone to do (which is nice to see; seems like I&#39;m too far off the mark ;)<br
    /><br />I was trying to figure out how someone would use SP-delivered VPLS service
    for L2 DCI and the only viable use I could see was to turn it into an IP(+MPLS)
    subnet, which is what you did.
  id: '2491205779809797132'
  image: https://resources.blogblog.com/img/blank.gif
  name: Ivan Pepelnjak
  profile: null
  pub: '2011-02-16T07:29:55.000+01:00'
  ref: '6663754495548952529'
  type: comment
count: 23
id: '6663754495548952529'
type: post
url: 2011/02/layer-3-gurus-asleep-at-wheel.html
