{
  "comments": [
    {
      "date": "14 June 2011 07:40",
      "html": "The other day guys from ipanema technology popped up to talk about their solution to WAN optimisation (which is notably different from what Riverbed does, for example). Not sure if this is a 100% match, but maybe worth a look: http://www.ipanematech.com/en/autonomic-network-system<br /><br />Disclaimer: I have not used this myself and don&#39;t personally know anybody who does. My opinion is that it does look good on paper, though.",
      "id": "4753326618284551530",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Dmitri Kalintsev",
      "profile": null,
      "pub": "2011-06-14T07:40:04.840+02:00",
      "ref": "7368228753176606358",
      "type": "comment"
    },
    {
      "date": "14 June 2011 08:02",
      "html": "Seems to be something like Packeteer, but distributed/coordinated. Definitely looks great in HTML  8-)<br /><br />The &quot;emulated teleengines&quot; concept is interesting, but works only if you have well-behaving traffic. A single UDP flood and the remote site is dead.",
      "id": "90671672002891525",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Ivan Pepelnjak",
      "profile": null,
      "pub": "2011-06-14T08:02:50.038+02:00",
      "ref": "7368228753176606358",
      "type": "comment"
    },
    {
      "date": "14 June 2011 08:16",
      "html": "It&#39;s more than just packeteer. They do:<br />- App QoS (distributed/coordinated) (~Packeteer)<br />- WAN optimisation (compression/protocol optimisation) (~Riverbed)<br />- Automatic WAN link selection (haven&#39;t seen anybody do this before)<br /><br />The &quot;emulated teleengines&quot; should work with any traffic, as long as that traffic *originates* at a site with an actual appliance.",
      "id": "6125178318528390246",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Dmitri Kalintsev",
      "profile": null,
      "pub": "2011-06-14T08:16:16.703+02:00",
      "ref": "7368228753176606358",
      "type": "comment"
    },
    {
      "date": "14 June 2011 09:24",
      "html": "The first solution is completely not scalable, as there are limits to max 256 ACLs per policy-map. The second solution is the best one, as long as you do not use the almigty ASR 1000, where QoS is said to be the state-of-the-art :-). Per-Tunnel-QoS in DMVPN is not supported there and as far as I know will NOT be in this year. The only solution left is Remote Ingress Shaping. Works well if you traffic is mostly TCP-based.<br /><br />Cheers,<br />Krzysztof",
      "id": "8055947077000988862",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Krzysztof",
      "profile": null,
      "pub": "2011-06-14T09:24:27.130+02:00",
      "ref": "7368228753176606358",
      "type": "comment"
    },
    {
      "date": "14 June 2011 10:21",
      "html": "#1 - Didn&#39;t know about 256 ACL limit. Thank you!<br />#2 - Yeah, ASR Allmighty is a great box, isn&#39;t it (well, it might be eventually  :-P )<br />#3 - Remote Ingress shaping: thanks for reminding me. need to fix the article.",
      "id": "1619344660688970962",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Ivan Pepelnjak",
      "profile": null,
      "pub": "2011-06-14T10:21:16.001+02:00",
      "ref": "7368228753176606358",
      "type": "comment"
    },
    {
      "date": "14 June 2011 10:23",
      "html": "WAN optimisation: nice to hear they have it, but obviously it works only if you have appliances on both ends (which defies the whole &quot;emulated teleengines&quot; advantage)<br /><br />Automatic WAN link selection: OER on Cisco routers (caveat: I have no real-life experience).<br /><br />&quot;... as long as that traffic ORIGINATES at a site with an actual appliance&quot; &lt;-- BINGO!",
      "id": "3339969441336910087",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Ivan Pepelnjak",
      "profile": null,
      "pub": "2011-06-14T10:23:41.606+02:00",
      "ref": "7368228753176606358",
      "type": "comment"
    },
    {
      "date": "14 June 2011 10:57",
      "html": "&gt; defies the whole &quot;emulated teleengines&quot; advantage<br /><br />This feature, as I understood, was designed to take care of coordinated controlling of traffic flow originated at large/fast sites (HO/DC/whatever), without the need to have appliances at small crappy offices.<br /><br />&gt; OER on Cisco routers<br /><br />Cool, thank you - didn&#39;t know about it!<br /><br />&gt; BINGO!<br /><br />Typical deployment would see appliances at all sites with significant uplink bandwidths. Small remote sites would often have something like ADSL with relatively small uplink pipes, so it may well not matter at all.",
      "id": "6550845390963096251",
      "image": "https://resources.blogblog.com/img/blank.gif",
      "name": "Dmitri Kalintsev",
      "profile": null,
      "pub": "2011-06-14T10:57:58.966+02:00",
      "ref": "7368228753176606358",
      "type": "comment"
    },
    {
      "comments": [
        {
          "date": "13 July 2012 09:12",
          "html": "Based on what I know about how QoS works in Cisco IOS, I would expect to have per-tunnel shaping queues (and queuing within those queues) and separate queues on physical interfaces where you can yet again queue based on properties of IP packets being sent over the serial interface (obviously, those would be GRE+IPsec-encapsulated payloads).<br /><br />A quick lab test would provide a definitive answer, don&#39;t you think so?",
          "id": "4569138996534297977",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2012-07-13T09:12:46.753+02:00",
          "ref": "778061784832607956",
          "type": "comment"
        },
        {
          "date": "13 July 2012 15:20",
          "html": "I set up a GNS lab this morning but am having a hard time finding a way to generate appropriate traffic.  It&#39;s Friday though so I can slack off looking for one.<br /><br />What&#39;s got me is this from Cisco&#39;s per-tunnel docs:<br /><br />QoS on a physical interface is limited only to the class default shaper on the physical interface. No other QoS configurations on the physical interface are supported when two separate QoS policies are applied to the physical and tunnel interfaces.<br />Addition of a QoS policy with a class default shaper on a physical interface is not supported when multiple QoS policies are utilized. <br /><br />Maybe if I source the tunnel from a loopback instead of the WAN interface.  I&#39;ll post my lab results when I get something definitive.",
          "id": "9134129174881141779",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Unknown",
          "profile": "https://www.blogger.com/profile/00853231209584935904",
          "pub": "2012-07-13T15:20:54.399+02:00",
          "ref": "778061784832607956",
          "type": "comment"
        }
      ],
      "date": "12 July 2012 22:33",
      "html": "I realize this post is a year old, but here goes:<br /><br />We&#39;re implementing a dual-hub dual-DMVPN with per-tunnel QoS.  The aggregate bandwidth of all spoke sites is greater than that available for either hub and is close to the aggregate BW of the hubs.  We&#39;re hoping EIGRP&#39;s per-flow balancing will help even things out in that regard.  The WAN provider gives us a BGP handoff to their publicly addressed MPLS cloud with two classes of service).<br /><br />The per tunnel policy is being setup as advised:  child policy is the same for all sites; there&#39;s one parent policy per remote bandwidth (only two).  The child policy has three classes:  EF priority bw 70%; CS3 and AF31 bw 5%; ACL of IPs precedence 3 (maps mgmt station traffic to highest priority vendor queue) and class-default fair queue.  Prior to this implementation, the child policy was directly applied as a service policy to the WAN serial interface.<br /><br />The question:  before per tunnel, all EF traffic got up to 70% of the outbound bandwidth.  However, once per-tunnel is applied, the only QoS you can apply to the serial interface is a class-default shaper.  Ok, so within each tunnel the EF traffic is prioritized, but what happens when total outbound load exceeds serial interface bandwidth?  Yes, the tunnels will prioritize the EF, but that if there&#39;s a ton of overall traffic how does the serial interface know to prioritize the EF traffic on delivery to the WAN?  If there&#39;s one or two really loud tunnels that exceed outbound bw, will EF traffic from other tunnels be dropped since it&#39;s per tunnel and not per interface?<br /><br />Or to rephrase:  is there one set of queues for the Tunnel interface which is then shaped for each dynamic tunnel or are sets of queues created for each dynamic tunnel?  Former situation would always make sure EF is prioritized at the serial iface but the latter could result in dropped priority packets.<br /><br />Or am I over thinking it again?",
      "id": "778061784832607956",
      "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
      "name": "Unknown",
      "profile": "https://www.blogger.com/profile/00853231209584935904",
      "pub": "2012-07-12T22:33:33.970+02:00",
      "ref": "7368228753176606358",
      "type": "comment"
    },
    {
      "date": "27 July 2012 17:13",
      "html": "It is as I was afraid it would be:  queueing policies are not allowed on the WAN interface when per-tunnel is applied via NHRP.  When attempting to apply an output service policy on the serial interface I get this error:<br /><br />&quot;service-policy with queueing features on sessions is not allowed in conjunction with interface based&quot;<br /><br />And yes, that is the complete error message, not a truncated paste on my part.<br /><br />So, how do I ensure EIGRP packets sourced from the tunnel interface get prioritized on the serial interface?",
      "id": "4215701627017132880",
      "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
      "name": "Unknown",
      "profile": "https://www.blogger.com/profile/00853231209584935904",
      "pub": "2012-07-27T17:13:26.548+02:00",
      "ref": "7368228753176606358",
      "type": "comment"
    },
    {
      "comments": [
        {
          "date": "03 August 2012 09:50",
          "html": "You should not use GTS but shaping within MQC. GTS has been obsolete for years.",
          "id": "3752847536748789820",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2012-08-03T09:50:40.437+02:00",
          "ref": "9162079507392667445",
          "type": "comment"
        }
      ],
      "date": "02 August 2012 21:42",
      "html": "One more thing to watch out for when implementing per-tunnel QoS:  Generic Traffic shaping is process switched.<br /><br />Alot of ink is spent making sure that your hub router can handle all the IPSEC traffic but very little is spent on the impact of GTS.  In my lab testing, both in GNS3 and live lab, if your hub egress is congested and you have only two tunnels configured for traffic shaping then the hub router will go to 100% CPU and stop sending out IGP packets across the tunnel.  In my GNS3 case this happened with a 7200 router and in the lab it happened with a 2800.  More than 2 GTS instances uses up all CPU.",
      "id": "9162079507392667445",
      "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
      "name": "Unknown",
      "profile": "https://www.blogger.com/profile/00853231209584935904",
      "pub": "2012-08-02T21:42:47.091+02:00",
      "ref": "7368228753176606358",
      "type": "comment"
    },
    {
      "date": "07 December 2012 15:50",
      "html": "An interesting article, thanks for the concise summary Ivan.<br /><br />I&#39;ve hit on the same limitation as described by Unknown 27 July, 2012 17:13, albeit I am trying to group a series of spoke sites and apply a shape to the group. Got that same message, dang.<br /><br />I posted a cisco support forum entry here if anyone has any other solution/workaround to this issue:<br /><br />https://supportforums.cisco.com/message/3801831",
      "id": "7158027986273254536",
      "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
      "name": "phileas",
      "profile": "https://www.blogger.com/profile/03813442859004836423",
      "pub": "2012-12-07T15:50:49.772+01:00",
      "ref": "7368228753176606358",
      "type": "comment"
    }
  ],
  "count": 14,
  "id": "7368228753176606358",
  "type": "post",
  "url": "2011/06/qos-in-large-scale-dmvpn-networks.html"
}