<div class="comments post" id="comments">
  <h4>34 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="8226849641938620734">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">caskings</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8226849641938620734" href="#8226849641938620734">03 November 2011 11:28</a>
              </span>
            </div>
            <div class="comment-content">To quote the Joker: &quot;It simple, we kill the Spanning Tree&quot;<br /><br />Use some cheap mpls switches (so !cisco) to build a multi path routed core and run vlps/vll over that as required.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1730801131732209375">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1730801131732209375" href="#1730801131732209375">03 November 2011 12:32</a>
              </span>
            </div>
            <div class="comment-content">Although I&#39;m a total MPLS fan, I heartily disagree with your comment. You have no idea how much complexity you&#39;ve just introduced (without solving the original problem: detecting VMs with bridged NICs).</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4188690324160021884">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">DanielG</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4188690324160021884" href="#4188690324160021884">03 November 2011 13:52</a>
              </span>
            </div>
            <div class="comment-content">Ivan, <br />According to this (http://www.cisco.com/en/US/prod/collateral/switches/ps9441/ps9902/guide_c07-556626.html)<br /><br />&quot;Because the Cisco Nexus 1000V Series does not participate in Spanning Tree Protocol, it does not respond to Bridge Protocol Data Unit (BPDU) packets, nor does it generate them. BPDU packets that are received by Cisco Nexus 1000V Series Switches are dropped.&quot;<br /><br />The way I&#39;m reading that (and they have a nifty diagram above) is bpdu packets are dropped and not forwarded on to the physical switch.<br /><br />Not sure if Kurt was running the 1000v or not...if this is the case though at the very least Cisco needs to clear this up.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4538526620578646855">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4538526620578646855" href="#4538526620578646855">03 November 2011 14:10</a>
              </span>
            </div>
            <div class="comment-content">Kurt was not running NX1KV ... but the document you quote indicates NX1KV has BPDU filter (BPDU guard definitely cannot be configured, I checked the configuration guides). Time to involve experts ;)</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4920326693644064729">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">caskings</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4920326693644064729" href="#4920326693644064729">03 November 2011 14:52</a>
              </span>
            </div>
            <div class="comment-content">I must admit, I didn&#39;t think it though that much. The places where I have worked (Multi lateral IXs) took the sledge hammer approach. Filtering everything bar blessed mac addresses and etherypes.<br /><br />While you could pre populate blessed macs at provisioning time in a hosted VM environment. I doubt that would fly in the enterprise arena.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="9024156146958413546">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Pablo Carlier</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c9024156146958413546" href="#9024156146958413546">03 November 2011 16:04</a>
              </span>
            </div>
            <div class="comment-content">If no BPDUs are passed through the N1kv, I guess the only challenge you can still have is the configuration of bridging between two VMs at the back-end, not via N1kv... and that has to be pretty intentional to become a problem. Am I missing something here? :)<br /><br />Disclaimer: I am a Cisco SE.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6128263748025308283">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">K</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6128263748025308283" href="#6128263748025308283">03 November 2011 16:05</a>
              </span>
            </div>
            <div class="comment-content">Filter BPDUs on the virtual switch, such that the VMs can&#39;t influence L2 topology.<br /><br />There&#39;s still the risk that VM &lt;-&gt; VM can loop traffic between themselves, but this is no difference than two physical servers doing the same.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2001272193159415709">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Pablo Carlier</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2001272193159415709" href="#2001272193159415709">03 November 2011 16:42</a>
              </span>
            </div>
            <div class="comment-content">Exactly. If you want to actively configure bridging between two servers, be them virtual or physical, I don&#39;t think the network should prevent this from happening. This is pretty hard to achieve by accident (unlike wrongly patching switch uplinks). Network equipment should not patronize the administrator, it should protect from accidents.<br /><br />I would rephrase the title to &quot;Virtual switches should prevent VMs from impacting the network topology&quot;. BPDU guard is just one way to do so. Nice to bring this into discussion though.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="813875205211932155">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c813875205211932155" href="#813875205211932155">03 November 2011 16:48</a>
              </span>
            </div>
            <div class="comment-content">#1 - Still waiting for confirmation on NX1KV dropping BPDU frames<br />#2 - BPDU filter @ NX1KV does not prevent forwarding loops through two VMs. While being pretty hard to configure, they could happen.<br /><br />The missing bit (maybe I should include that as well) is that Kurt runs an IaaS environment and has no control over stupidities his customers want to make; he has to protect his network.<br /><br />There is a something you can do with VM-FEX though - configure BPDU guard on Nexus 6100. Will insert that in the article.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="992951521070544328">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c992951521070544328" href="#992951521070544328">03 November 2011 16:50</a>
              </span>
            </div>
            <div class="comment-content">Disagree. If the server admin is stupid enough to misconfigure the server (not impossible), the network has to survive.<br /><br />Actually, I&#39;ve seen a MSCE configuring bridging between two Hyper-V interfaces in a bad-hair moment. Result: total network meltdown (yeah, BPDU guard was disabled and something probably filtered BPDUs).</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="8194005810264835610">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Andy G</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8194005810264835610" href="#8194005810264835610">03 November 2011 16:56</a>
              </span>
            </div>
            <div class="comment-content">Would the Cisco ASA 1000V prevent this using -  access-list id ethertype deny bpdu ?</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="530485899539589452">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c530485899539589452" href="#530485899539589452">03 November 2011 17:12</a>
              </span>
            </div>
            <div class="comment-content">You could use vASA or VSG to filter BPDUs. VSG would make more sense, as it sits directly in front of vNIC (not yet sure how vASA interacts with vPath API).<br /><br />In both cases, BPDUs would be dropped before they would hit the physical link. You&#39;d still need &quot;reject forged transmits&quot; to prevent forwarding loops.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1327902574840697681">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Reggle</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1327902574840697681" href="#1327902574840697681">03 November 2011 17:42</a>
              </span>
            </div>
            <div class="comment-content">I know this is not a solution the moment it happens, but you can disable BPDU generation in this case using a Windows registry key (see http://msdn.microsoft.com/en-us/library/ee494722.aspx).<br />Going over all possible solutions, there is nothing that will cover every possible situation. Know your environment and act accordingly?</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7468665951701736343">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">K</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7468665951701736343" href="#7468665951701736343">03 November 2011 18:04</a>
              </span>
            </div>
            <div class="comment-content">But my point was that it&#39;s a L3 loop, constrained by the uplink speed of the devices in question - far more manageable than a STP loop.<br /><br />Really, it&#39;s no different to a server just maxing out it&#39;s interface by pulling random data from another source on the network.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="8420623565554782111">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">DanielG</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8420623565554782111" href="#8420623565554782111">03 November 2011 18:24</a>
              </span>
            </div>
            <div class="comment-content">Agree with you on #2. In a &quot;what could go wrong&quot; moment, the server admin tries to solve *some application problem* by creating a bridge/etc. It doesn&#39;t work using the NX1K port profiles so he manually goes into vCenter and goes around it.<br /><br />In a typical public cloud environment I don&#39;t think this would be a problem since your customers should most likely have only a menu based system for ordering VMs, and not direct access to vCenter. Although you still have the sysadmin issue. :)</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6097630162015581889">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">vSerge</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6097630162015581889" href="#6097630162015581889">04 November 2011 01:14</a>
              </span>
            </div>
            <div class="comment-content">Another problem w/ the BPDU filter option is that most of the ports facing vSphere have portfast configured and receipt of a BPDU w/ BPDU filter enabled with disable portfast - something people often forget. <br /><br />The basic rule of thumb is you can drop BPDUs only in a guaranteed loopfree topology...</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1172374992470151892">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">vSerge</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1172374992470151892" href="#1172374992470151892">04 November 2011 01:23</a>
              </span>
            </div>
            <div class="comment-content">Another thought is if you implemented BPDU guard in the vSwitch, that&#39;s also not ideal because you have prevented the use case where someone wants to bridge a VPN to a vNIC, like they have done in Ivan&#39;s example. BPDU guard functionality doesn&#39;t imply just dropping the BDPUs, it also implies shutting down the virtual port of the vSwitch connected to that VM. <br /><br />The primary use case is that virtual machines are not Ethernet bridges, so the current implementation works well for the common use case. However, where there are advanced use cases like this where VM is a bridge running STP - the admin has to do a little more, like either disable bridge code in Windows via registry (too complex and doesn&#39;t work in Cloud environments since management can be delegated but viable in non-Cloud use cases) or use products from VMware and partners to drop the BPDUs. For example, vShield App has a L2 firewall capability - you can drop all BPDUs sent by VMs at will with a point of enforcement being on every vNIC of VMs on the ESX host. If you do that, you have to create a loopfree topology. <br /><br />Will VMware do something interesting in vSwitch top to address this? Stay tuned, Ivan would be the first to know :-)</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3758847691021454220">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">vSerge</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3758847691021454220" href="#3758847691021454220">04 November 2011 01:28</a>
              </span>
            </div>
            <div class="comment-content">Reject forged transmit option is enabled by default on VMware side...</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="8183586940081290029">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8183586940081290029" href="#8183586940081290029">04 November 2011 09:11</a>
              </span>
            </div>
            <div class="comment-content">Not what the documentation says.  :-E</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="4285523233879688534">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Pablo Carlier</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c4285523233879688534" href="#4285523233879688534">04 November 2011 11:52</a>
              </span>
            </div>
            <div class="comment-content">Oh but the network does survive, as it&#39;s isolated from these mistakes through BPDU Filtering at the virtual switch. It&#39;s just the VMs themselves that will go crazy.<br /><br />Great rewrite on the article, by the way, offers much more visibility into the challenges and possible solutions. Kudos.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6390793260594778575">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Pablo Carlier</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6390793260594778575" href="#6390793260594778575">04 November 2011 12:09</a>
              </span>
            </div>
            <div class="comment-content">#1- Public deployment guide states so: http://www.cisco.com/en/US/prod/collateral/switches/ps9441/ps9902/guide_c07-556626.html - &quot;Because the Cisco Nexus 1000V Series does not participate in Spanning Tree Protocol, it does not respond to Bridge Protocol Data Unit (BPDU) packets, nor does it generate them. BPDU packets that are received by Cisco Nexus 1000V Series Switches are dropped.&quot;<br /><br />#2- That forwarding loop between VMs cannot come from the outside, as Nexus 1000v will drop local source MAC address frames on ingress. It must happen another way.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1365118354122795393">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1365118354122795393" href="#1365118354122795393">04 November 2011 12:25</a>
              </span>
            </div>
            <div class="comment-content">#1 - confirmed by the PM.<br /><br />#2 - You&#39;re almost right, but for a wrong reason ;) A bridging VM would forward an externally-generated broadcast/multicast. To stop that, you have to use &quot;reject forged transmits&quot; to catch a flooded packet existing the VM.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1973645243598752844">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Yakov Shtoots</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1973645243598752844" href="#1973645243598752844">04 November 2011 13:48</a>
              </span>
            </div>
            <div class="comment-content">Ivan, with regards to your VM-FEX offer, as far as i know all interfaces on N5K/N7K and UCS-FI that considered as HIF (host interfaces) on the FEX (2K/IOM/VM-FEX) have BPDU Guard on by default and you actually can&#39;t remove it. so assuming that a logical interface on the UCS-FI (vEthernet) receives a bpdu it will err-disable that interface.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6748618554724877093">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Brad Hedlund</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6748618554724877093" href="#6748618554724877093">04 November 2011 14:48</a>
              </span>
            </div>
            <div class="comment-content">Ivan,<br />By default, the N1K performs a deja vu check on packets received from uplinks, preventing any loops.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7240952848962624817">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7240952848962624817" href="#7240952848962624817">04 November 2011 16:00</a>
              </span>
            </div>
            <div class="comment-content">I know it does a lot of loop prevention checks, including source- and destination-MAC checks. Are you implying it does more than that?</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7763826766503111349">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">vSerge</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7763826766503111349" href="#7763826766503111349">04 November 2011 22:29</a>
              </span>
            </div>
            <div class="comment-content">I stand corrected, Ivan - user has to configure this.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7363486415291883269">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">vSerge</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7363486415291883269" href="#7363486415291883269">05 November 2011 01:01</a>
              </span>
            </div>
            <div class="comment-content">Hi Folks, played around in the lab today, here is a workaround: <br />I&#39;d recommend configuring BPDU-filter and disable BPDU-guard on the upstream switch. In order to retain the portfast mode for the ports facing the ESX, it’s also important to set these parameters on a per switch port basis – not globally, which has the behavior of moving the switch port out of portfast mode once a BPDU is received… <br /><br />Carlos and I did some testing on a 6506 w/ fairly recent IOS code: <br /><br />PRME-BL-6506-J06#show run interface g1/31<br />Building configuration...<br /><br />Current configuration : 178 bytes<br />!<br />interface GigabitEthernet1/31<br />switchport<br />switchport mode access<br />no ip address<br />spanning-tree portfast  <br />spanning-tree bpdufilter enable  <br />spanning-tree bpduguard disable  <br />end<br /><br />Before doing this, we’d see the BPDU guard kick in: <br /><br />PRME-BL-6506-J06#show log | i 1/31<br />6w2d: %SPANTREE-SP-2-BLOCK_BPDUGUARD: Received BPDU on port GigabitEthernet1/31 with BPDU Guard enabled. Disabling port.<br />6w2d: %PM-SP-4-ERR_DISABLE: bpduguard error detected on Gi1/31, putting Gi1/31 in err-disable state<br />PRME-BL-6506-J06#<br /><br />Then we went to the configuration show above w/ portfast enabled, filter enabled, guard disabled and the port moved from blocking to forwarding as per portfast definition and BDPU counters are at zero… The key thing is to do this on a per-port basis and not globally. <br /><br />PRME-BL-6506-J06#show spanning-tree int g1/31 portfast<br />VLAN0001         enabled<br /><br /><br />PRME-BL-6506-J06#show spanning-tree int g1/31 detail<br />Port 31 (GigabitEthernet1/31) of VLAN0001 is forwarding<br />   Port path cost 4, Port priority 128, Port Identifier 128.31.<br />   Designated root has priority 0, address 0004.961e.6f70<br />   Designated bridge has priority 32769, address 0007.8478.8c00<br />   Designated port id is 128.31, designated path cost 14<br />   Timers: message age 0, forward delay 0, hold 0<br />   Number of transitions to forwarding state: 1<br />   The port is in the portfast mode<br />   Link type is point-to-point by default<br />   Bpdu filter is enabled<br />   BPDU: sent 0, received 0</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3741682403568881407">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">ccie15672</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3741682403568881407" href="#3741682403568881407">05 November 2011 14:51</a>
              </span>
            </div>
            <div class="comment-content">The host can also tag a frame and the vSwitch will just forward to switch (if the vSwitch is tagging, it adds a tag).  vSwitch will block double-tagged frames on ingress, but it will gladly forward them.<br /><br />I like some of vGW&#39;s (Juniper&#39;s host firewall solution) but at this time it can&#39;t block BPDUs or improperly tagged frames...</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="7438256537647756839">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Frank</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c7438256537647756839" href="#7438256537647756839">19 November 2011 03:32</a>
              </span>
            </div>
            <div class="comment-content">I have tried to replicate this by sending bpdu&#39;s from a vm, but bpdu-guard never kicks off. It seems the vSwitch is dropping the BPDU&#39;s (not forwarding them to pSwitch). I&#39;m using vSphere 4.1. pSwitch is 3750X. Generating bpdu&#39;s w/ http://www.perihel.at/sec/mz/</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3818394428237608981">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Jonathan Topping</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3818394428237608981" href="#3818394428237608981">25 January 2012 15:10</a>
              </span>
            </div>
            <div class="comment-content">BPDUfilter, only when enabled globally, can prevent BPDUguard from triggering if a user/customer bridges two vNICs in ESX.<br /><br />Assumption: vSwitch truly provides loop-free forwarding as Ivan has mentioned/proven in other blog posts. (with the prevent forged option enabled)<br /><br />BPDUfiltering, enabled globally, filters outbound BPDUs on all portfast/edge ports. It also sends &quot;a few&quot; at link up to prevent STP race conditions and an ugly loop as a result. If it does receive BPDUs, it causes the port to fall out of portfast/edge mode.<br /><br />So, if a vNIC in ESX is bridged, the BPDUs never leave the pSwitch after the initial linkup to cause them to loop around in the vSwitch and reflected back to the pSwitch. This way, you get the following benefits:<br /><br />a) One bad VM won&#39;t trigger BPDUguard, thereby isolating a hypervisor (or a cluster in Ivan&#39;s example)<br />b) A miscabled host attached to a pSwitch port will fall out of portfast mode if BPDUs are seen from it. Protecting you from a bad sysadmin/cable-job with a non-loopfree (non vSwitch) looping the network.<br /><br /><br />Basically, enabling BPDUfilter globally circumvents Ivan&#39;s concern in the above blog about a non-ESXi being plugged into the network causing a loop. If one of these does get plugged in and has a loop, the switch will see the BPDUs at link up and move the ports out of portfast/edge.<br /><br />The only situation where this breaks down is a non-ESX hypervisor that has a vswitch that does not guarantee loop-free. In this situation, the pSwitch sees the uplinks as up and online, so no BPDUs have been sent in awhile, so a loop in the non-ESX vSwitch could be a devastating take down of your datacenter. Then, I&#39;m afraid, storm-control is your only friend.<br /><br />Outside of my Virtual-facing pSwitches, I would never do BPDUfilter, even globally....BPDUguard is a must for the rest of my network.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3923659320656544680">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3923659320656544680" href="#3923659320656544680">26 January 2012 08:01</a>
              </span>
            </div>
            <div class="comment-content">What would happen if you start the bridging VM __after__ the physical links have been up for quite a while?</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1246994283427435154">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/04027782213790024771" rel="nofollow">HeyNert</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1246994283427435154" href="#1246994283427435154">22 June 2012 16:58</a>
              </span>
            </div>
            <div class="comment-content">Just thought about this topic once more....<br /><br />so what happen&#39;s if we use L2 Filters on the phy port incoming to drop all bpdu packets ?<br /><br />e.g. <br /><br />mac access-list extended BPDU<br />  ! deny IEEE STP <br /> deny any any lsap 0x4242 0x0<br />  ! deny CISCO RSTP<br /> deny any any lsap 0xAAAA 0x0<br />permit any any<br /><br />int g0/1<br />mac access-list BPDU in<br /><br />IMHO this would drop incoming frames whith bpdu&#39;s<br /><br />But maybe im wrong</div>
              <div class="comment-replies">
                <div class="comment-thread inline-thread">
                  <span class="thread-count"><a>Replies</a></span>
                    <ol>
      <div>
        <li class="comment" id="8436869257936066821">
          <!--
          <div class="avatar-image-container">
            <img src="https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="https://www.blogger.com/profile/13457151406311272386" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c8436869257936066821" href="#8436869257936066821">06 July 2012 20:13</a>
              </span>
            </div>
            <div class="comment-content">... and how will you detect a loop? You know, bridges (including the bridging functionality in Linux or Windows) use BPDUs for a good reason.</div>
          </div>
        </li>
      </div>
  </ol>

                </div>
              </div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="3919135357362936222">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="http://www.rickardnobel.se" rel="nofollow">Rickard Nobel</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c3919135357362936222" href="#3919135357362936222">30 August 2012 10:59</a>
              </span>
            </div>
            <div class="comment-content">In VMware ESXi 5.1 a BPDU guard like feature has been introduced:<br /><br />http://rickardnobel.se/archives/1461</div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
