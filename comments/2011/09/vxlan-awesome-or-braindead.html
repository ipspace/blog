<div class="comments post" id="comments">
  <h4>6 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="1490290614077326740">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Will</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1490290614077326740" href="#1490290614077326740">28 September 2011 00:52</a>
              </span>
            </div>
            <div class="comment-content">Ivan,<br /><br />I couldn&#39;t comment on searchnetworking so I&#39;ll do it here.  That was a great post on a new product that I know nothing about.  <br /><br />Thanks again, bloggers like you make my job that much more fun.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6658005445726936392">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">of_jay</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6658005445726936392" href="#6658005445726936392">06 October 2011 05:48</a>
              </span>
            </div>
            <div class="comment-content">Great post here at Search networking talking about VXLAN.  Clearly, this is great for massive data centers.  Being able to tunnel from VEM to VEM not needing to tag 1000s of VLANs from physical switch to ESX host is great...keeping the DC on a solid proven L3 design...even better.  Now my question is, is fabric path really going to go anywhere?  The whole point was to increase the size L2 domains to allow for VM mobility, right?  How about those Cisco F1 cards required for fabric path?  I think VXLANs could make for a better overall DC solution assuming there is an easier way to exit that particular VXLAN/subnet.  <br /><br />What do you think?</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="5836586541281880265">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c5836586541281880265" href="#5836586541281880265">06 October 2011 08:47</a>
              </span>
            </div>
            <div class="comment-content">As I wrote in the original VXLAN post (http://blog.ioshints.info/2011/08/finally-mac-over-ip-based-vcloud.html) - good bye, large scale bridging (including FP) and EVB.<br /><br />Of course, we have to wait for physical device termination (at least in enterprise data centers) and for the technology to mature, but at least the path forward is clear. I don&#39;t think you&#39;ll see to many VLANs in a state-of-the-art DC in a few years.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="1823566088708669730">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Anonymous</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c1823566088708669730" href="#1823566088708669730">06 October 2011 14:43</a>
              </span>
            </div>
            <div class="comment-content">Great, I read that article too, but just wanted clarification.  When you say not too many VLANs in the data center in a few years, what exactly are you saying is driving that?  That was happening with FP/EVB anyway, right?  With technologies like VXLAN, as many VLANs as there are today could still exist since there will need to be an SVI of some sort for each VLAN and there would not be a need to reduce the number of VLANs to accomplish server mobility due to a potential L2 full mesh between all virtual switches (and associated physical switches for exit points).<br /> New item from Ivan Pepelnjak on Cisco IOS Hints and Tricks: VXLAN: awesome or braindead?<br />        As I wrote in the original VXLAN post (http://blog.ioshints.info/2011/08/finally-mac-over-ip-based-vcloud.html) - good bye, large scale bridging (including FP) and EVB.<br />Of course, we have to wait for physical device termination (at least in enterprise data centers) and for the technology to mature, but at least the path forward is clear. I don&#39;t think you&#39;ll see to many VLANs in a state-of-the-art DC in a few years.<br /> To respond to this item, you may simply reply to this email or visit the page.<br /> ---<br /> You can unsubscribe or<br /> update<br /> your notification settings at any time.<br /> If you believe you have received this message in error, or you are<br /> experiencing other technical difficulties, please contact<br /> support@js-kit.com,<br /> we will contact you shortly.<br /> Social Networking powered by Echo</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="6668141435515520126">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c6668141435515520126" href="#6668141435515520126">06 October 2011 15:15</a>
              </span>
            </div>
            <div class="comment-content">EVB simplifies 802.1Q VLAN provisioning.<br /><br />FP enables large-scale bridging.<br /><br />VXLAN removes the need for physical VLANs because virtual segments are no longer created with VLANs but transported over IP.<br /><br />Too bad you didn&#39;t attend yesterday&#39;s webinar.</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="2642007861755330139">
          <!--
          <div class="avatar-image-container">
            <img src="https://resources.blogblog.com/img/blank.gif">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="None" rel="nofollow">of_jay</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c2642007861755330139" href="#2642007861755330139">06 October 2011 22:11</a>
              </span>
            </div>
            <div class="comment-content">Too bad, Ivan!  Understand all of that...I think I was just having trouble conceptualizing terminating VXLANs terminating on L3/physical devices or maybe it&#39;s still a lack of understanding :).  One question I always ask as topics like this (and OF) are discussed - where will the default gateway reside?  With VXLANs, will it be the virtual switch or physical switch that terminates VXLANs?  Will VXLANs terminate on two switches for HA?  What&#39;s your take?<br />Thanks.</div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
