{
  "comments": [
    {
      "comments": [
        {
          "date": "27 February 2020 06:31",
          "html": "Piotr,<br /><br />It seems to me we&#39;re having the same discussion in various disguises for at least a decade (from the times you were working at Cisco when we first met at PLNOG), and they always go along the same lines:<br /><br />* Someone makes a ridiculous claim using the magic technologies of L2DCI and vMotion;<br />* I point out why it&#39;s ridiculous (and it&#39;s usually pretty simple to do that);<br />* You find a corner case where it might work with a lot of assumptions, proper engineering etc.<br /><br />I honestly don&#39;t care if you managed to implement a solution that should better be left in PowerPoint to solve a particularly pressing business need... after all, I did design a network with 20+ parallel EIGRP processes and route redistribution between them... but there&#39;s difference between:<br /><br />* doing something that needs to be done;<br />* talking about that in public without clearly stating all the assumptions, prerequisites and limitations;<br />* marketing that as the best thing since sliced bread.<br /><br />When you&#39;re making comments in public, you&#39;re influencing the thinking of other people, so please (at the very minimum) do no harm. See also https://blog.ipspace.net/2016/01/whatever-happened-to-do-no-harm.html",
          "id": "5823587027012622324",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2020-02-27T06:31:07.328+01:00",
          "ref": "2480938585169532544",
          "type": "comment"
        },
        {
          "date": "27 February 2020 10:07",
          "html": "Ivan,<br /><br />In this topic in the comment section:<br />https://blog.ipspace.net/2020/02/live-vmotion-into-vmware-on-aws-cloud.html<br /><br />I wrote: &quot;Stretching workload belonging to the same traffic group and a subnet should be avoided as much as possible&quot;.<br /><br />This is a clear statement that we want both do what needs to be done with no harm.<br /><br />What I would like to avoid is an overgeneralization. Every technology can become a corner case even EVPN with BGP in a data center (without IGP). Especially with the advent of new solutions. The same applies to EIGRP, IP LFA, L2 DCI etc. I discussed with you on one topic about &quot;all the assumptions, prerequisites and limitations&quot;. Then you stopped and moved to the other blog post. Naturally, all assumptions become dispersed. Taking a snippet of my statement, moving to the next page, saying that it is a typical $vendor&#39;s claim is another overgeneralization but put in the context of a person. That is not fair. As a workaround, I will try to copy all the assumptions in any public post in discussions with you. I hope it will be ok.",
          "id": "8934349047268597911",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Piotr Jablonski",
          "profile": "https://www.blogger.com/profile/06074343110093815035",
          "pub": "2020-02-27T10:07:46.238+01:00",
          "ref": "2480938585169532544",
          "type": "comment"
        },
        {
          "date": "27 February 2020 14:49",
          "html": "Piotr, you just proved my point. <br /><br />Sometimes I get tired of comment thread format, so I write a new blog post going into more details, but I always link back to the source comment, so anyone interested in the context can figure it out. I used that same link, checked what you wrote, and you never ever mentioned &quot;latency&quot;. Now that I bring it up, your answer is &quot;but of course I considered that, and you got it wrong, because latency across a firewall is higher than the latency across a switch&quot;. Whatever.<br /><br />As for overgeneralization, the &quot;drive slowly, the road is icy&quot; advice is also an overgeneralization, as it clearly does not apply to Finnish rally drivers. Does that mean that it doesn&#39;t apply to the rest of us?<br /><br />I&#39;m stopping my side of this debate right here, as it&#39;s clear we&#39;re not getting anywhere, and wish good luck to whoever wants to try out cloudbursting ideas in real life.",
          "id": "5413706331066440303",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Ivan Pepelnjak",
          "profile": "https://www.blogger.com/profile/13457151406311272386",
          "pub": "2020-02-27T14:49:42.390+01:00",
          "ref": "2480938585169532544",
          "type": "comment"
        },
        {
          "date": "27 February 2020 16:09",
          "html": "The claim that &quot;workloads are contained&quot; means &quot;latency&quot; is not the main point here. You could think about different reasons like security/compliance, packet fragmentation performance issues, monitoring, storage replication, cost, fast convergence, throughput. I did not know that. This is why I asked: &quot;Do you think a VPN/interconnect/DCI kills benefits of the scale-out?&quot; In my opinion, latency does not kill this use case for small distances. You call it a corner case. I called it &quot;real-life projects are full of corner cases&quot;. <br /><br />I have nothing against moving a discussion to a new blog post. My only objection is that, meantime, based on our unfinished conversation, you composed a message of &quot;a typical explanation of the enterprise-focused $vendor evangelist&quot;. Agree, such a conclusion can be an effect of the unfinished conversation. That&#39;s why I tried to explain my point of view giving as precise latency numeric values as possible. Someone who doesn&#39;t think about latency doesn&#39;t have them in mind, isn&#39;t it? <br /><br />I think the networking community needs technical discussions even if there are some temporary grudges. Thank you for your blog posts and interesting topics! All the best! :)",
          "id": "3134982564244777563",
          "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
          "name": "Piotr Jablonski",
          "profile": "https://www.blogger.com/profile/06074343110093815035",
          "pub": "2020-02-27T16:09:04.435+01:00",
          "ref": "2480938585169532544",
          "type": "comment"
        }
      ],
      "date": "26 February 2020 22:03",
      "html": "Ivan, &quot;end-to-end latency in a data center is measured in microseconds&quot;. <br /><br />For the switching network -&gt; yes, it can be a single digit microseconds. But when we include a FW then we have 50+ usecs additionally, over 200 usecs if a cluster of FW is there. Next when we add OSs it can be another hundreds of usecs, and when the app reads the data from SSD disks, it becomes miliseconds (1MB takes 1ms). If a local data center is close to the public cloud data center, like 20km, it is just about 55 microseconds on top of the end-to-end latency. So scaling out is possible as the latency tax is comparable to one router e.g. Cisco ASR9k. <br /><br />You cited me &quot;For a production use case, if workloads are contained, then scaling-out a particular app layer is a viable option.&quot; <br />Here is the important part -&gt; &quot;if workloads are contained&quot;. This helps to keep latency at the minimum level and avoid tromboning effects or even a single passing of data across VPN within the application. Just for storage replication. This is simple math, not a typical $vendor&#39;s evangelist explanation. ;)<br /><br />Of course, a tax latency increases quickly, so scaling out becomes possible for fully contained applications only.",
      "id": "2480938585169532544",
      "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
      "name": "Piotr Jablonski",
      "profile": "https://www.blogger.com/profile/06074343110093815035",
      "pub": "2020-02-26T22:03:02.798+01:00",
      "ref": "7846516340060610246",
      "type": "comment"
    },
    {
      "date": "26 February 2020 22:06",
      "html": "Public cloud data centers do not mean AWS in Frankfurt, London or US automatically. In Central/Eastern Europe you can have an IaaS from a Service Provider locally.",
      "id": "1649037166549582536",
      "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
      "name": "Piotr Jablonski",
      "profile": "https://www.blogger.com/profile/06074343110093815035",
      "pub": "2020-02-26T22:06:36.877+01:00",
      "ref": "7846516340060610246",
      "type": "comment"
    },
    {
      "date": "16 March 2020 17:04",
      "html": "When web applications (with server generation of HTML) were migrated to client-side applications (JavaScript with separate requests for data) - resulting quality and user-experience become worse. <br /><br />- Asynchronous approach (in opposite to synchronous one) - is not so deterministic. Any request could finish in different order, and in result - you will get very different UI experience even in similar initial conditions.<br /><br />- Instead on focusing on determinism and optimizations, better protocol and infrastructure - you follow initially limited design.<br /><br />- If you want scalability and quality of solution - you should scale your database, because database is the most bottleneck. Proper sharding can give you maximum performance and quality (ACID) for most application cases. If done properly - you still have to implement ACID manually - for rare set of operations that accept latency/rollback.<br /><br />- For best performance and user-experience - you should plan data-center &amp; application architecture. The statement - Just move to cloud - doesn&#39;t solve scalability issues.",
      "id": "7263415462492567990",
      "image": "https://lh3.googleusercontent.com/zFdxGE77vvD2w5xHy6jkVuElKv-U9_9qLkRYK8OnbDeJPtjSZ82UPq5w6hJ-SA=s35",
      "name": "Unknown",
      "profile": "https://www.blogger.com/profile/17498737545574565046",
      "pub": "2020-03-16T17:04:29.095+01:00",
      "ref": "7846516340060610246",
      "type": "comment"
    }
  ],
  "count": 7,
  "id": "7846516340060610246",
  "type": "post",
  "url": "2020/02/the-myth-of-scaling-from-on-premises.html"
}