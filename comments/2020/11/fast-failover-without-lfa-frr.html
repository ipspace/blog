<div class="comments post" id="comments">
  <h4>6 comments:</h4>
  <div class="comments-content">
    <div class="comment-thread">
        <ol>
      <div>
        <li class="comment" id="201">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Jan</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c201" href="#201">04 November 2020 09:57</a>
              </span>
            </div>
            <div class="comment-content">I have done real lab tests with IOS-XR based routers in the following scenario:<br />
- ECMP links running IS-IS<br />
- IS-IS + Segment Routing + TI-LFA<br />

<p>Topology: 4 x ECMP link between two routers</p>

<p>This is what happens:
You loose link #1: ECMP is still available: Minimal traffic loss (&lt;10ms) as traffic is simply re-distributed onto other ECMP links
You loose link #2: Same happens as for link #1
You loose link #3: Fast failover to last remaining link. BUT since ECMP is gone, TI-LFA will now calculate a backup path
You loose link #4: TI-LFA will provide fast failure, assuming there is another path available.</p>

<p>I <em>think</em> the ECMP behavior is independent of the routing protocol, because it is implemented in CEF / hardware. But have not tested it properly with LDP / BGP etc. myself.</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="202">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c202" href="#202">04 November 2020 11:13</a>
              </span>
            </div>
            <div class="comment-content"><p>@Jan: Thanks for the data! </p>

<p>However, 10 msec loss could still be caused by CPU reprogramming the ECMP buckets. Have you experienced any difference in how long the outage was based on whether you had pure ECMP or LFA on top of it?</p>

<p>Thank you! Ivan</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="203">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow"> Bellman</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c203" href="#203">04 November 2020 11:38</a>
              </span>
            </div>
            <div class="comment-content"><p>One thing to note is that in a pure spine-and-leaf network, you can, or perhaps even <em>will</em>, get loops when a link goes down, until the routing protocol has converged.</p>

<p>Consider a network with two spines (S1,S2) and three leafs (L1, L2, L3).  A host connected to L1 send a packet to a host on L2.  L1 decides to send it to spine S1, but unbeknownst to the leafs, the link between S1 and L2 has gone down.  S1 has realized this, and reprogrammed itself, so when it receives the packet that needs to go to L2, it will try to send that to one of the other leafs, L1 or L3, and hope that they will send it to the <em>other</em> spine, S2, since it is the remaining path to L2.</p>

<p>But, since L1 and L3 have not yet realized that S1 no longer has a link to L2, they may decide to send the packet back to S1.  In particular, L1 will almost certainly hash the packet the same way as when it got it the first time, and send it to S1 again.  Which will hash it the same way <em>it</em> did previously, and send it to L1.  Loop.</p>

<p>Until the routing protocol converges a second or two later.</p>

<p>This is inherent in a pure spine-and-leaf network, and the only way to avoid it is to have a less pure network design.  For example:</p>

<ul>
<li>Have multiple links between each spine and leaf.  If there had been two links between S1 and L2, the problem would not have happened, as S1 would just send the packet over the other direct link to L2.</li>
<li>Connect the spines in a ring.  S1 would then have a shorter backup path towards L2 available (via S2) than by sending the packet back to some leaf.  (I personally like this design.)</li>
</ul>

<p>Whether you <em>need</em> that fast rerouting in your network, or if you can wait until the routing protocol converges, is of course a different question.  And likely depends on how <em>often</em> you have link failures. In the datacenter network I&#39;m managing, where links fail almost never, we would be OK with a convergence time of a minute or more; but our OSPF converges in a second or two, so no problem there.  (We still have the spines connected to each other, but for other reasons.)</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="204">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Ivan Pepelnjak</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c204" href="#204">04 November 2020 11:44</a>
              </span>
            </div>
            <div class="comment-content"><p>@Bellman: the behavior you describe depends on whether you designed a <a href="https://blog.ipspace.net/2018/09/valley-free-routing-in-data-center.html">valley-free routing topology</a> (in which case you&#39;ll experience packet drops until the routing protocol does its job, and a <a href="https://blog.ipspace.net/2018/09/implications-of-valley-free-routing-in.html">few other interesting things</a>) or not (in which case you&#39;ll experience path hunting and temporary loops).</p>

<p>Even LFA wouldn&#39;t help in a leaf-and-spine fabric, you&#39;d need remote LFA to get to another spine switch.</p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="205">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Andrea Di Donato</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c205" href="#205">04 November 2020 01:17</a>
              </span>
            </div>
            <div class="comment-content"><p>@Jan: thanks for your contribution. It&#39;s interesting as we&#39;re seeing a different behaviour. In our IOSXR, by default, LFA is calculated for ECMP&#39;ed prefixes and thus it kicks in even if just one link fails (e.g. your link #1). What&#39;s your configuration ? Have you excluded somehow via CLI the LFA computation for ECMP&#39;ed prefixes ? </p>
</div>
          </div>
        </li>
      </div>
      <div>
        <li class="comment" id="206">
          <!--
          <div class="avatar-image-container">
            <img src="">
          </div>
          -->
          <div class="comment-block">
            <div class="comment-header">
              <cite class="user"><a href="" rel="nofollow">Bellman</a></cite>
              <span class="datetime secondary-text">
                <a rel="nofollow" id="c206" href="#206">04 November 2020 04:07</a>
              </span>
            </div>
            <div class="comment-content">Ivan:<br />

<p>Yes, you can certainly configure your network so the spines drop packages instead of trying to route around the broken link.</p>

<p>However, will you be <em>happier</em> because the spine is now dropping 100% of the traffic it receives destined for L2, instead of looping (and then dropping) a fraction of that same traffic?  This is in the context of wanting very quick failovers, faster than the routing protocol can react, so presumably you you want as small outages as possible.</p>

<p>(And if you [generic you, not specifically you, Ivan] prefer valley-free routing, remember to consider what happens if the broken link is the one to the leaf where your monitoring and/or management stations are connected.  Suddenly you have no way of managing and monitoring that spine...  Unless those stations are dual-homed to two leaf routers.  A physically separate management network just moves the problem to that network; or are valley-free proponents OK with a valleyed management network?)</p>

<p>&gt; Even LFA wouldn&#39;t help in a leaf-and-spine fabric, you&#39;d need
&gt; remote LFA to get to another spine switch.</p>

<p>Yes, that was exactly the point I was trying to make!  But I could obviously have been clearer about that.  A pure leaf-and-spine network inherently does not <em>have</em> a Loop-Free Alternative from the spines.  You need to break the topology somehow.  Tunnels to the other spines are one way of doing that, physical links to neighbouring spines another (the one I personally like best), and so on.</p>

<p>(This was all a bit of a side-note to your main post.  I hope I have not derailed the discussion too much.)</p>
</div>
          </div>
        </li>
      </div>
  </ol>

    </div>
  </div>
</div>
