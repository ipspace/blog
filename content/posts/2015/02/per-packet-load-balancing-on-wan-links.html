---
url: /2015/02/per-packet-load-balancing-on-wan-links.html
title: "Per-Packet Load Balancing on WAN links"
date: "2015-02-12T14:37:00.000+01:00"
tags: [ load balancing,WAN ]
---

<p>One of my readers got an interesting idea: he’s trying to make the most of his WAN links by doing per-packet load balancing between a 30 Mbps and a 50 Mbps link. Not exactly surprisingly, the results are not what he expected.<!--more--></p>
<h4>The obvious problems</h4><p>Per-packet load balancing on stateless packet-by-packet devices (routers or switches) is inherently a bad idea, as it inevitably results in <a href="/2014/03/per-packet-load-balancing-interferes.html">packet reordering and reduced TCP throughput</a> (I won’t even try to figure out what it could do to some UDP traffic). The only corner case where you might think you need it is when you’re trying to send traffic from a <a href="/2015/01/load-balancing-elephant-storage-flows.html">single (or a few) TCP sessions</a> across multiple WAN uplinks, but even then you might get worse link utilization than if you’d have used a single uplink for the elephant TCP session due to packet reordering.</p>
<p>Doing stateless per-packet load balancing across unequal-bandwidth links is usually a Really Bad Idea. Ignoring the effects of packet reordering on TCP throughput you’ll never get more than N times the bandwidth of the slowest link, unless you’re using tricks that result in unequal-cost load balancing (DMZ Bandwidth with BGP, parallel MPLS-TE tunnels, or EIGRP). The proof is left as an exercise for the reader.</p>
<p>Finally, the <a href="http://en.wikipedia.org/wiki/Bandwidth-delay_product">bandwidth-delay product</a> might further limit the <a href="http://en.wikipedia.org/wiki/TCP_tuning">throughput of a single TCP session</a>. See also Mathis formula and <a href="https://www.switch.ch/network/tools/tcp_throughput/">TCP throughput calculator</a>.</p>
<p class="info">WAN optimization products (recently relabeled as Software Defined WAN) like <a href="http://www.velocloud.com/">VeloCloud</a> (or <a href="https://twitter.com/netmagdave/status/565590404033441793">some</a> <a href="https://twitter.com/BobMcCouch/status/565590614096769025">others</a>) solve the problem by reassembling and reordering the packets before delivering them to the end-host, resulting in pretty decent aggregate bandwidth… and you can always use <a href="/2014/03/ios-uses-multipath-tcp-does-it-matter.html">MP-TCP</a>. </p>
<p><strong>Disclosure</strong>: I totally enjoyed <a href="http://techfieldday.com/appearance/velocloud-presents-at-networking-field-day-9/">VeloCloud presentation</a> @ NFD9 (<a href="http://vimeo.com/album/3257226/video/119396925">this video</a> prompted the previous paragraph). You probably know that presenting companies indirectly cover the travel expenses of NFD delegates, but that never stopped me from having my own opinions ;) <a href="/p/networking-tech-field-day-disclaimer.html">More…</a></p>

