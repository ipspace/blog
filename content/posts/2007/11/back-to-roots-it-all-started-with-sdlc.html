---
url: /2007/11/back-to-roots-it-all-started-with-sdlc/
title: "Back to the roots: it all started with SDLC"
date: "2007-11-06T07:28:00.000+01:00"
tags: [ WAN ]
---

My recent post about problems with old modems has generated a lot of comments with some very useful ideas, but nobody addressed the question “why was a long string of ones not a problem?”, so let's start there. Almost all WAN synchronous protocols in use today are descendants of venerable <acronym title="Synchronous Data Link Control">SDLC</acronym> <a href="http://www.research.ibm.com/journal/sj/132/ibmsj1302D.pdf">invented by IBM</a> more than 30 years ago. SDLC was later extended to support connectionless and balanced modes, resulting in <a href="http://en.wikipedia.org/wiki/High-Level_Data_Link_Control"><acronym title="High-Level Data Link Control">HDLC</acronym></a>. PPP is just an extension of HDLC, adding support for negotiations and standard layer-3 protocol demultiplexing. In SDLC, IBM also solved the frame delimiting and associated <a href="http://www.trailing-edge.com/~bobbemer/ESCAPE.HTM">escape character problem</a> inherent in previous protocols like <a href="http://en.wikipedia.org/wiki/Binary_Synchronous_Communications"><acronym title="Binary Synchronous Communications">BSC</acronym></a> (<acronym title="Data Link Escape">DLE</acronym> was used in BSC) by introducing <a href="http://en.wikipedia.org/wiki/Bit_stuffing">bit stuffing</a>: a <a href="http://en.wikipedia.org/wiki/HDLC#Framing">zero would be inserted after five consecutive ones</a> (and silently removed by the receiver) to differentiate the regular data stream from framing (six consecutive ones) and abort (more than six consecutive ones) sequences. Thus, the HDLC (or PPP) data stream can never contain more than six consecutive ones and the long sequences of ones never cause synchronization loss.<br/><br/>IBM obviously also had problems with bad modems and solved it with the <a href="http://en.wikipedia.org/wiki/NRZI"><acronym title="Non-return-to-zero Inverted">NRZI</acronym></a> encoding that was part of SDLC standard (and a major pain in the <a href="/2007/10/remove-configuration-prompt/">good old days</a> when the appliques on the old Cisco routers did not support it and we've been trying hard to penetrate IBM accounts). You can still configure NRZI encoding on most routers' serial links (it might depend on the actual hardware platform) with the <strong>nrzi-encoding</strong> interface configuration command (<a href="http://www.cisco.com/univercd/cc/td/doc/product/core/cisagspl/agshim/69679.htm#xtocid1810816">you had to do it with jumpers in the AGS+</a>). Incidentally, changing interface encoding to NRZI was really helpful when you had to break things in the preparation for the <a href="http://safari.oreilly.com/1587051478/app03lev1sec1">troubleshooting part of the original CCIE lab</a>).<br/><br/>Enough theory, let's summarize the proposed solutions:<ul><li>The <strong>nrzi-encoding</strong> (if available) is the best one, as it reliably solves the problem, is transparent and does not incur additional overhead.</li>
<li>Compression or encryption are OK, but they result in significant CPU overhead (unless you have hardware encryption/compression modules) and might (at least in theory) still produce a long sequence of zeroes, although with a very low probability. IPSec also introduces overhead due to additional IPSec headers.</li>
<li><acronym title="Link fragmentation and interleaving">LFI</acronym> (effectively multilink PPP over a single link) is also a good solution, as the PPP framing and MLPPP headers break the long sequences of zeroes (you might have to fine-tune the fragment size with <strong>ppp multilink fragment size</strong> configuration command), but it introduces overhead on the WAN link.</li>
<li>IP fragmentation would work, but would be quite bandwidth-consuming. If the fragmentation would be performed by the router, the overhead would be 20 bytes per fragment (IP header), if the sending host performs the fragmentation, the overhead is 40 bytes per fragment for TCP sessions. For example, if we reduce the IP MTU size to 256 bytes, the TCP session overhead is over 18% (and we were scoffing at the ATM designers that made us live with 10% overhead).</li>
</ul>
There were also a few suggestions that would not work very well:<ul><li>The <strong>invert data</strong> command would only help if the modem has problems with long strings of zeroes, not with long strings of the same value.</li>
<li>The <strong>tunnel key</strong> command just sets a 4-byte field in the GRE header but does not affect the encapsulated data at all.</li>
</ul>

