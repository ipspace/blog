---
date: 2016-05-12T12:07:00.001+02:00
tags:
- switching
- data center
title: What Are The Problems with Broadcom Tomahawk? We Don’t Know
url: /2016/05/what-are-problems-with-broadcom.html
---

<p>One of my readers has customers that already experienced performance challenges with Tomahawk-based data center switches. He sent me an email along these lines:</p>
<blockquote class="cite">My customers are concerned about buffer performance for packets that are 200 bytes and under.  MORE IMPORTANTLY, a customer informed me that there were performance issues when running 4x25GE connections when one group of ports speaks to another group.</blockquote>
<p>Reading the <a href="http://www.mellanox.com/related-docs/products/tolly-report-performance-evaluation-2016-march.pdf">report Mellanox published not so long ago</a> it seems there really is something fishy going on with Tomahawk.<!--more--></p>
<p>Let’s be realistic: every chipset has limitations. Every silicon vendor has to make tradeoffs. Every vendor loves to find a chink in another vendor’s product and tries to present it as a glaring abyss.</p>
<p>However, there are vendors that are pretty open about their chipset architectures. Well, make it A Vendor – Cisco has some amazing “a day in the life of a packet” Cisco Live presentations that anyone with an email address can watch (if there’s someone else as open as Cisco is about their internal architectures, please post a comment).</p>
<p>Then there are vendors that document the realistic boundaries of their architectures. For example, when Cisco was selling oversubscribed 10GE linecards for Nexus 7000 they documented which ports share the forwarding bandwidth. Arista was pretty open about the forwarding performance of their 7300 switches (so it was easy to <a href="https://blog.ipspace.net/2014/05/how-line-rate-is-line-rate.html">deduce they are not linerate at small packet sizes</a>). Brocade documented their ASIC limitations in regards to link aggregation.</p>
<p>So what’s the problem with Broadcom chipsets? <strong>We don’t know</strong> what the limitations are because <strong>they’re hiding the information</strong>, and everyone who does know what’s really going on <strong>can’t talk about it</strong>. </p>
<p>Well, the <em>real </em>problem is that Broadcom doesn’t have to care – every major data center switching vendor (apart from Brocade, a few Arista and Cisco switches, and Juniper QFX10K) is using some Broadcom chipset. </p>
<p class="note">Before someone starts listing a dozen reasons why hiding that information makes sense, let me point out that <a href="http://www.intel.com/content/www/us/en/switch-silicon/ethernet-switch-fm5000-fm6000-datasheet.html">Intel publishes all of their documentation</a>.</p>
<p>The only way to get any information on how the stuff that’s sitting inside most of data center switches these days really works is to try to reverse-engineer tidbits from <a href="https://blog.ipspace.net/2014/06/trident-2-chipset-and-nexus-9500.html">various vendor presentations</a> or their <a href="http://www.cisco.com/c/en/us/support/docs/switches/nexus-9000-series-switches/119032-nexus9k-tcam-00.html">configuration guidelines</a>, or rely on Broadcom competitors spilling the beans disguised as a test report. And yet some people call this state of affairs <em>progress</em>.</p>
<p>For a more articulate take on the same topic, read the <a href="http://packetpushers.net/industry-needs-open-source-framework-switching-silicon/">excellent blog post</a> by <a href="http://packetpushers.net/author/carlos-cardenas/">Carlos Cardenas</a>, and if you want to know more about implementing a networking operating system, register for my <a href="http://www.ipspace.net/Building_Next-Generation_Data_Center">online course</a> with <a href="https://blog.ipspace.net/2016/04/first-guest-speaker-in-building-next.html">Russ White as the guest speaker</a>.</p>

