---
url: /2009/11/first-hqf-impressions-excellent-job.html
title: "First HQF impressions: excellent job"
date: "2009-11-11T07:19:00.001+01:00"
tags: [ QoS ]
---

<p>Several readers <a href="https://blog.ipspace.net/2009/11/cb-wfq-misconceptions.html">told me</a> that the <a href="http://www.cisco.com/en/US/docs/ios/qos/configuration/guide/qos_frhqf_support.html">Hierarchical Queuing Framework</a> introduced in IOS releases 12.4(20)T and 15.0 (why do I always have the urge to write 12.5?) works <a href="https://blog.ipspace.net/2009/11/cb-wfq-misconceptions.html">much better than CB-WFQ</a>. After spending several hours trying to break HQF, I have to concur with them: Cisco’s engineers did a splendid job. However, the HQF behavior might be slightly counterintuitive to those that became too familiar with CB-WFQ. </p>
<!--more--><p>For example, faced with this configuration …</p>
<pre class="code">policy-map WAN<br/> class P5001<br/>    bandwidth percent 20<br/>    fair-queue<br/> class P5003<br/>    bandwidth percent 30<br/> class class-default<br/>    fair-queue</pre><p>… one might assume that all three classes will get a proportional part of the remaining bandwidth (50%). Not true. An HQF class with a <strong>bandwidth </strong>allocation gets as much as it’s asked for. It might get more, but if all classes are fully congested, the remaining bandwidth is distributed equally between classes without explicit bandwidth allocation.</p>
<p>When I ran 30 parallel TCP sessions across a 2 Mbps link (10 TCP sessions in each class), I’ve got these results:</p>
<pre class="code">a1#<strong>show policy-map interface serial 0/1/0 | include map|bps</strong><br/>    Class-map: P5001 (match-all)<br/>      30 second offered rate 418000 bps, drop rate 21000 bps<br/>      bandwidth 20% (400 kbps)<br/>    Class-map: P5003 (match-all)<br/>      30 second offered rate 613000 bps, drop rate 15000 bps<br/>      bandwidth 30% (600 kbps)<br/>    Class-map: class-default (match-any)<br/>      30 second offered rate 997000 bps, drop rate 0 bps</pre><p>As you can see, all the remaining bandwidth was used by the best-effort <strong>class-default</strong>.</p>
<h4 id="Testbed">Testbed</h4><p>I was performing the QoS tests on a 2Mbps PPP link between two 2800-series routers running IOS release 15.0(1)M. The relevant parts of the router configuration are shown below.</p>
<p><strong>Access lists</strong> permit TCP and UDP traffic to the same port. I needed a mix of TCP and UDP to test intra-class queuing behavior.</p>
<pre class="code">ip access-list extended P5001<br/> permit tcp any any eq 5001<br/> permit tcp any eq 5001 any<br/> permit udp any any eq 5001<br/> permit udp any eq 5001 any<br/>ip access-list extended P5002<br/> permit tcp any any eq 5002<br/> permit tcp any eq 5002 any<br/> permit udp any any eq 5002<br/> permit udp any eq 5002 any<br/>ip access-list extended P5003<br/> permit tcp any any eq 5003<br/> permit tcp any eq 5003 any<br/> permit udp any any eq 5003<br/> permit udp any eq 5003 any</pre><p>Class maps:</p>
<pre class="code">class-map match-all P5001<br/> match access-group name P5001<br/>class-map match-all P5003<br/> match access-group name P5003<br/>class-map match-all P5002<br/> match access-group name P5002</pre><p>Interface configuration:</p>
<pre class="code">interface Serial0/1/0<br/> bandwidth 2000<br/> ip address 10.0.1.1 255.255.255.252<br/> encapsulation ppp<br/> ip ospf 1 area 0<br/> load-interval 30<br/> !<br/> service-policy output WAN</pre><p>I used <em>iperf </em>to generate TCP load and my own <em>flood.pl </em>to generate UDP load. The following command was used to start <em>iperf</em>:</p>
<pre class="code">$ <strong>iperf -c </strong><strong><em>host</em></strong><strong> -t 3600 -p </strong><strong><em>port</em></strong><strong> -i 60 -P 10</strong></pre>

