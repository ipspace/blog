---
url: /2011/03/data-center-fabric-architectures.html
title: "The Data Center Fabric architectures"
date: "2011-03-03T07:14:00.001+01:00"
tags: [ Link aggregation,switching,Data Center,Workshop ]
---

<p>Have you noticed how quickly <em>fabric </em>got as meaningless as <em>switching </em>and <em>cloud</em>? Everyone is selling you <em>data center fabric </em>and no two vendors have something remotely similar in mind. You know it’s always more fun to look beyond white papers and marketectures and figure out what’s really going on behind the scenes (warning: you might be <a href="http://en.wikipedia.org/wiki/The_Wizard_of_Oz_(1939_film)">as disappointed as Dorothy was</a>). I was able to identify three major architectures (at least two of them claiming to be omnipotent fabrics).</p>
<h4>Business as usual</h4><p>Each networking device (let’s confuse everyone and call them <a href="https://blog.ipspace.net/2011/02/how-did-we-ever-get-into-this-switching.html"><em>switches</em></a>)<em> </em>works independently and remains a separate management and configuration entity. This approach has been used for decades in building the global Internet and thus has proven scalability. It also has well-known drawbacks (large number of managed devices) and usually requires thorough design to scale well.</p>
<!--more--><p>As the long-distance bridging fever spreads across data centers, <em>business-as-usual </em>approach has to replace STP with a more scalable protocol. TRILL and SPB (802.1aq) are the standard candidates; Cisco’s FabricPath is a proprietary alternative.</p>
<p>As long as access-layer switches are not TRILL/SPB-enabled, we need multi-chassis link aggregation (<a href="https://blog.ipspace.net/search?q=MLAG">MLAG</a>) to optimize bandwidth utilization. Those of you that worked with multichassis multilink PPP (MMP) in the past would probably agree with me that MLAG is also <em>business as usual</em>.</p>
<p><strong>Example</strong>: Cisco’s Nexus 7000 with FabricPath and VPC, Brocade’s VCS</p>
<h4>The Borg</h4><p>In the <em>Borg </em>architecture (lovingly known as <a href="https://blog.ipspace.net/2010/10/multi-chassis-link-aggregation-stacking.html"><em>stacking on steroids</em></a>) numerous switches decide to form a collective and elect the central brain (or <a href="https://blog.ipspace.net/2010/11/multi-chassis-link-aggregation-mlag.html">outsource the brainy functions to an external device</a>) that controls the whole hive. The cluster of devices appears as a single control- and management-plane entity to the outside world. It’s managed as a single device, has a single configuration and one set of routing adjacencies with the outside world.</p>
<p><strong>Examples</strong>: stackable switches, Juniper’s virtual chassis, HP’s IRF, Cisco’s VSS</p>
<p>Like the original Borg, the switch cluster architectures cannot cope well with splits from the central brains. Cisco’s VSS reloads the primary switch when it detects a <em>split brain </em>scenario; HP’s IRF and Juniper’s virtual chassis disable the switches that lose cluster quorum.</p>
<p>While vendors like to talk about all-encompassing fabrics, the current implementations <a href="https://blog.ipspace.net/2010/10/multi-chassis-link-aggregation-stacking.html">usually limit the number of high-end devices in the cluster to two</a> (Cisco’s VSS, Juniper’s EX8200+XRE200 and <a href="https://blog.ipspace.net/2011/01/intelligent-redundant-framework-irf.html">HP’s IRF</a>), reducing the <em>Borg </em>architecture to a <em>Siamese twin </em>one.</p>
<p>Furthermore, most implementations of the <em>Borg </em>architecture still limit the switch clusters to devices of the same type. As you cannot combine access- and core-layer switches into the same fabric, you still need MLAG between the access and the core layer.</p>
<p>At the moment, all Borg-like implementations are proprietary. </p>
<h4>The Big Brother</h4><p>Also known as <em>controller-based fabric</em>, this architecture uses dumb(er) switches that perform packet forwarding based on instructions downloaded from the central controller(s). The instructions might be control-plane driven (L3 routing tables downloaded into the switches) or data-plane driven (5-tuples downloaded into the switches to enable per-flow forwarding).</p>
<p>The controller-based approach is ideal for protocol- and architecture prototyping (which is the primary use case for <a href="http://www.openflow.org/">OpenFlow</a>) and architectures with hub-and-spoke traffic flow (wireless controllers), but has yet to be seen to scale in large any-to-any networks.</p>
<h4>Anything else?</h4><p>Is there an architecture that you cannot easily categorize as one of the above? Is there a standard in development for <em>Borg</em> architecture? Have you seen a scalable <em>Big Brother </em>architecture? Please write a comment!</p>

