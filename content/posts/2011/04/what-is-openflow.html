---
date: 2011-04-05T07:12:00.002+02:00
tags:
- SDN
- switching
- data center
- OpenFlow
title: What is OpenFlow?
url: /2011/04/what-is-openflow.html
---

<p>My <a href="https://blog.ipspace.net/2011/03/open-networking-foundation-fabric.html">Open Networking Foundation rant</a> got several thoughtful responses focusing on “<em>what is OpenFlow and what can we do with it</em><em>?</em>” Let’s start with the easy part first: What exactly is OpenFlow?</p>
<p>A typical networking device (bridge, router, switch, LSR ...) has <a href="http://wiki.nil.com/Control_and_Data_plane"><em>control </em>and <em>data </em>plane</a>. The control plane runs all the control protocols (including port aggregation, STP, TRILL, MAC address learning and routing protocols) and downloads the forwarding instructions into the <em>data plane </em>structures, which can be simple lookup tables or specialized hardware (hash tables or TCAMs). In distributed architectures, the control plane has to use a communications protocol to download the forwarding information into data plane instances. Every vendor uses its own proprietary protocol (Cisco uses IPC – <em>InterProcess Communication </em>– to implement distributed CEF); OpenFlow tries to define a standard protocol between control plane and associated data plane elements.</p>
<!--more--><p>The OpenFlow zealots would like you to believe that we’re just one small step away from implementing <a href="http://en.wikipedia.org/wiki/Skynet_(Terminator)">Skynet</a>; the reality is a bit more sobering. You need a protocol between control and data plane elements in all distributed architectures, starting with modular high-end routers and switches. Almost every modular high-end switch that you can buy today has one or more supervisor modules and numerous linecards performing distributed switching (preferably over a crossbar matrix, not over a shared bus). In such a switch, OpenFlow-like protocol runs between supervisor module(s) and the linecards.</p>
<p>Moving into more distributed space, the <a href="https://blog.ipspace.net/2011/03/data-center-fabric-architectures.html">Borg fabric architectures</a> use an OpenFlow-like protocol between the central control plane and forwarding instances. You might have noticed that all vendors link at most two high-end switches into Borg architecture at the moment; this decision has nothing to do with vendor lock-in and lack of open protocols but rather reflects the practical challenges of implementing a high-speed distributed architecture (alternatively, you might decide to believe the whole networking industry is a confusopoly of morons who are unable to implement what every post-graduate student can simulate with open source tools).</p>
<p>Moving deeper into the technical details, the <a href="http://www.openflow.org/wp/documents/"><em>OpenFlow Specs</em></a><em> </em>page on the <a href="http://www.openflow.org/">OpenFlow web site</a> contains a link to the <a href="http://www.openflow.org/documents/openflow-spec-v1.1.0.pdf">OpenFlow Switch Specification v1.1.0</a>, which defines:</p>
<ul class="ListParagraph"><li>OpenFlow tables (the TCAM structure used by OpenFlow);</li>
<li>OpenFlow channel (the session between an OpenFlow switch and an OpenFlow controller);</li>
<li>OpenFlow protocol (the actual protocol messages and data structures).</li>
</ul>
<p>The designers of OpenFlow had to make the TCAM structure very generic if they wanted to offer an alternative to numerous forwarding mechanisms implemented today. Each entry in the <em>flow tables </em>contains the following fields: ingress port, source and destination MAC address, ethertype, VLAN tag &amp; priority bits, MPLS label &amp; traffic class, IP source and destination address (and masks), layer-4 IP protocol, IP ToS bits and TCP/UDP port numbers. </p>
<p class="note">OpenFlow 1.0 does not support MPLS-related fields.</p>
<p>To make the data plane structures scalable, OpenFlow introduces a concept of multiple flow tables linked into a tree (and group tables to support multicasts and broadcasts). This concept allows you to implement multi-step forwarding, for example:</p>
<ul class="ListParagraph"><li>Check inbound ACL (table #1)</li>
<li>Check QoS bits (table #2)</li>
<li>Match local MAC addresses and move into L3/MPLS table; perform L2 forwarding otherwise (table #3)</li>
<li>Perform L3 or MPLS forwarding (tables #4 and #5).</li>
</ul>
<p>You can pass <em>metadata </em>between tables to make the architecture even more versatile.</p>
<p class="note">OpenFlow 1.0 uses a single TCAM (flow table) and is thus totally boring compared to rich OpenFlow 1.1 functionality.</p>
<p>The proposed flow table architecture is extremely versatile (and I’m positive there’s a PhD thesis being written proving that it is a superset of every known and imaginable forwarding paradigm), but it will have to meet the harsh reality before we’ll see a full-blown OpenFlow switch products. You can implement the flow tables in software (in which case the versatility never hurts, but you’ll have to wait a few years before the Moore Law curve catches up with terabit speeds) or in hardware where the large TCAM entries will drive the price up. </p>
<p>OpenFlow 1.0 is close enough to TCAMs implemented in actual products that we might see shipping products in near future; we’ll probably have to wait at least a few years before we’ll see a full-blown hardware product implementing OpenFlow 1.1.</p>
<h4>More information</h4><p>To learn more about modern data center architectures and evolving fabric technologies, watch my <a href="http://www.ioshints.info/DC30">Data Center 3.0 for Networking Engineers</a> webinar (<a href="http://www.ioshints.info/SingleRecording?code=DC30">buy a recording</a> or <a href="http://www.ioshints.info/Subscription">yearly subscription</a>).</p>

