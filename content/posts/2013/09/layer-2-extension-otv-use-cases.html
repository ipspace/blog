---
url: /2013/09/layer-2-extension-otv-use-cases.html
title: "Layer-2 Extension (OTV) Use Cases"
date: "2013-09-19T07:02:00.000+02:00"
tags: [ bridging,Data Center,Workshop,WAN ]
---

<p>I was listening to the fantastic <a href="http://packetpushers.net/pq-show-24-cisco-otv-deep-dive-part-1/">OTV Deep Dive PQ Packet Pushers</a> podcast while biking around the wonderful Slovenian forests. They started the podcast by discussing OTV use cases, Ethan throwing in long-distance vMotion (the usual long-distance L2 extension selling point), but refreshingly some of the engineers said “well, that’s not really the use case we see in real life.”</p>
<p>So what were the use cases they were mentioning?<!--more--></p>
<p>I loved one of them – someone <strong>using OTV to get away from L2 interconnect</strong>. They had a traditional L2 interconnect (and all the <a href="http://blog.ipspace.net/2012/05/layer-2-network-is-single-failure.html">associated “goodies”</a>), decided to convert it to L3 interconnect, but still needed some stretched VLANs in the migration period.</p>
<p>And here are the other use cases I gleaned from the podcast:</p>
<p><strong>External BGP subnets</strong> – you have a single /24 IPv4 prefix that you have to announce from more than one data center, and most people would immediately think about stretching that same subnet (because you can’t advertise two /25s to the Internet) across more than one location hoping that everything works.</p>
<p>Not surprisingly, if the inter-DC WAN link fails, you’ll face a <a href="https://blog.ipspace.net/2012/10/is-layer-3-dci-safe.html">nice split-brain scenario with both data centers advertising the subnet</a>, effectively preventing some users from reaching the correct data center … unless you do some fancy routing, which brings me to the point: you don’t need stretched layer-2 subnet to implement this scenario, you just need proper design and some more intelligent routing.</p>
<p>Now, I totally understand that some customers love to sprinkle another layer of pixie dust over their network instead of investing in <a href="http://www.ipspace.net/Redundant_Data_Center_Internet_Connectivity">proper BGP design and deployment</a>. As a system integrator you usually have to go with what your customers want (and are willing to pay for), but the L2 extension still carries a hefty price tag (particularly if you have to buy the M2 linecards and OTV license for Nexus 7000) which might be a bit higher than attending a BGP course and paying someone to design your DC WAN edge (or <a href="http://www.ipspace.net/ExpertExpress">review your design</a>).</p>
<p class="note">A totally irrelevant side remark: you do know that you can get more than enough IPv6 address space to cover all the data centers you might have anywhere in the solar system, don’t you?</p>
<p><strong>Data Center migration</strong>, which is a perfect use case that even I would support. Do keep in mind that you have to sync a lot of things (including storage), which could make the migration project a bit more complex than a simple shutdown-move-powerup procedure, but if you have to move the data center and cannot agree on a reasonably long maintenance window within the next 6 months, you just might have to use long-distance vMotion hoping nothing crashes in the process.</p>
<p>Also, keep in mind that your migration <a href="https://blog.ipspace.net/2011/09/long-distance-vmotion-for-disaster.html">might not be as fast as you expect it to be</a> – some people <a href="https://blog.ipspace.net/2012/07/long-distance-workload-mobility-in.html">managed to move 30 VMs in a weekend</a>, which was such a phenomenal achievement that EMC simply <a href="http://www.emc.com/about/news/press/2012/20120709-01.htm">had to document it in a press release</a>.</p>
<p>Finally, don’t forget to turn off layer-2 extension when you’re done – you wouldn’t want to turn two data centers into a <a href="https://blog.ipspace.net/2012/05/layer-2-network-is-single-failure.html">single failure domain</a>, would you?</p>
<p><strong>Disaster recovery with SRM</strong> – yet another use case supporting laziness at the cost of network complexity. I totally understand that you have to use the same subnet in both data centers because <a href="https://blog.ipspace.net/2012/01/ip-renumbering-in-disaster-avoidance.html">some craplications simply cannot survive a changed IP address</a>, but I can’t grasp why you wouldn’t use SRM external hooks and <a href="https://blog.ipspace.net/2013/01/long-distance-vmotion-stretched-ha.html">reconfigure the switches</a> with <a href="https://blog.ipspace.net/2012/06/netconf-expect-on-steroids.html">NETCONF</a> (or XMPP or Puppet) during the SRM recovery process to recreate the subnet in the other data center.</p>
<p>BTW, if you’re running anything more complex than an <a href="https://blog.ipspace.net/2012/08/pvlan-vxlan-and-cloud-application.html">SMB web hosting environment</a>, you probably have to <a href="https://blog.ipspace.net/2013/05/simplify-your-disaster-recovery-with.html">migrate firewall and load balancer configurations</a> as well, in which case recreating the lost subnet is the least of your worries … unless you already deployed <a href="https://blog.ipspace.net/2013/04/virtual-appliance-performance-is.html">virtual appliances</a>.</p>
<p><strong>Summary</strong> – I’m <a href="https://blog.ipspace.net/2011/11/busting-layer-2-data-center.html">still looking</a> for a good layer-2 extension use case (apart from the migration ones).</p>
<h4>More Information</h4><p>You’ll find all you never wanted to know about Data Center interconnects (layer-2 and layer-3, including MPLS/VPN) in the <a href="http://www.ipspace.net/Data_Center_Interconnects">DCI webinar</a>, and you really should <a href="http://demo.ipspace.net/get/Enterasys#Videos">watch the downloadable videos</a> in the sponsored <a href="http://www.ipspace.net/Enterasys">Enterasys Robust Data Center Interconnects</a> webinar. The webinar does mention Enterasys technologies, but it also describes numerous generic DCI challenges, including the need for stretched VLANs in live VM mobility environments.</p>

