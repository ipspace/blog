---
date: 2017-11-16T09:12:00.000+01:00
tags:
- data center
- fabric
title: Pluribus Networks… 2 Years Later
url: /2017/11/pluribus-networks-2-years-later.html
---

<p>I first met Pluribus Networks 2.5 years ago during their <a href="http://techfieldday.com/appearance/pluribus-networks-presents-at-networking-field-day-9/">Networking Field Day 9</a> presentation, which <a href="https://vimeo.com/119471817">turned controversial enough</a> that I was advised not to wear the same sweater during NFD16 to avoid jinxing another presentation (I also admit to be a bit biased in those days based on marketing <a href="https://michaelgreenwell.wordpress.com/2017/10/22/deja-moo/">deja-moo</a> from a Pluribus sales guy I’d been exposed to during a customer engagement).</p>
<p>Pluribus NFD16 presentations were better; here’s what I got from them:<!--more--></p>
<p class="warn">The rest of this blog post is based on information Pluribus shared during their NFD16 presentation. If I misunderstood or missed something please write a comment.</p>
<ul class="ListParagraph"><li>They pivoted from “<em>we’re having this great hardware with server-like capabilities on every switch</em>” to “<em>we’re having this fabric solution that can run on whitebox switches</em>”, losing most of their potentially-interesting traffic analysis capabilities (the path between switching ASIC and CPU is laughably slow in most whitebox switches, and the CPUs are most often ridiculously underpowered to get the cheapest possible product);</li>
<li>They are implementing proprietary edge fabric using VXLAN encapsulation on top of a generic layer-3 underlay. Think NSX but implemented in a ToR switch instead of hypervisor (<a href="http://blog.ipspace.net/2011/05/complexity-belongs-to-network-edge.html">where it belongs</a>). Not something that would get me excited when everyone else works on having <a href="http://blog.ipspace.net/2017/02/evpn-all-that-glitters-is-not-gold.html">eventually interoperable</a> EVPN.</li>
<li>As with every proprietary solution (including Cisco ACI, VMware NSX or Juniper Virtual Chassis Fabric or QFabric), it's an all-or-nothing game regardless of how you want to spin it. Either you're using all-Pluribus edge or you need a Pluribus-to-outside gateway. I don’t remember them mentioning any interoperability feature like EVPN gateway.</li>
<li>Control plane architecture is pretty traditional - each device is an independent router/bridge, and they use anycast gateway to support VM mobility (par for the course these days). Nothing to see here (which is a good thing).</li>
<li>The only value-add feature I saw is fabric-wide management and provisioning. That's a really hard problem (Brocade got burned on this one and needed years to get it working with VCS Fabric), and in Pluribus case it requires <a href="https://en.wikipedia.org/wiki/Three-phase_commit_protocol">3-phase commit</a> and puts fabric into read-only mode on partitioning. Compare that to Cisco ACI where <a href="http://blog.ipspace.net/2015/03/cisco-aci-stretched-fabric-that.html">only one part of the fabric goes into read-only mode</a>, and syncs with the read-write part of the fabric once partitioning is removed.</li>
<li>I hated how they tried to avoid answering the "<em>what happens when fabric partitions</em>" question for most of the presentation, and tried to get around it with the "use redundant links" <a href="http://blog.ipspace.net/2012/10/if-something-can-fail-it-will.html">red herring</a>.</li>
</ul>
<p>Why would I want to go down a proprietary path and risk being locked out of the fabric just to get a single-point-of-configuration (which is also a single-point-of-disaster when fat fingers strike)? The only reason I see is because I'm not good at standardizing and automating stuff but want to manage my fabric the traditional way - through manual CLI. That makes them interesting to <a href="http://blog.ipspace.net/2013/01/the-magical-u-curve-and-technology.html">mid-range market</a> (people who can't figure out how to automate while still having more money to spend on boxes than cheap FTEs to burn configuring them), which is also the <a href="http://blog.ipspace.net/2017/11/the-three-paths-of-enterprise-it.html">craziest part of the market</a> in terms of expectations and featuritis, and probably toughest to get into if you're a startup.</p>
<h4>Explore!</h4><p>Interested in different viewpoints? Try these blog posts from fellow NFD16 delegates:</p>
<ul class="ListParagraph"><li><a href="https://thenetworkstack.com/pluribus-networks-whitebox-fabric-nfd16/">Whitebox Fabric from Pluribus Networks</a></li>
<li><a href="http://gestaltit.com/exclusive/tom/pluribus-networks-definition-software-defined/">Pluribus Networks is the definition of Software-Defined</a> (no comments ;)</li>
<li><a href="http://www.fragmentationneeded.net/2017/09/pluribus-networks-wait-where-are-we.html">Pluribus Networks: Wait, where are we again?</a></li>
</ul>
<p>Want to know more about other data center switching vendors? You’ll find an in-depth overview of what the major ones are doing in the <a href="http://www.ipspace.net/Data_Center_Fabrics?utm_medium=blog">Data Center Fabric Architectures</a> webinar.</p>
<p>Want to learn how to build a leaf-and-spine fabric? You’ll find all the details you need, plus a vibrant support community, and hands-on exercises in <a href="http://www.ipspace.net/FabricDesign?utm_medium=blog">Designing and Building Data Center Fabrics</a> online course.</p>
<p>How about mastering more than just data center networking? Check out <a href="http://www.ipspace.net/Building_Next-Generation_Data_Center?utm_medium=blog">Building Next-Generation Data Center</a> online course.</p>
<p>Finally a disclosure: I attended the Pluribus presentation as part of Networking Field Day 16 event. <a href="http://blog.ipspace.net/p/networking-tech-field-day-disclaimer.html">Here's what that means</a>.</p>

