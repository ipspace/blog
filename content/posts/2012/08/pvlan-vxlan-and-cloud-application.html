---
date: 2012-08-21T07:07:00.000+02:00
tags:
- design
- VXLAN
- data center
- workshop
- vMotion
- cloud
- overlay networks
- virtualization
title: PVLAN, VXLAN and cloud application architectures
url: /2012/08/pvlan-vxlan-and-cloud-application.html
---

<p>Aldrin Isaac <a href="https://blog.ipspace.net/2012/07/could-mpls-over-ip-replace-vxlan-or.html?showComment=1344218766617#c3812932304135234188">made a great comment</a> to my <a href="https://blog.ipspace.net/2012/07/could-mpls-over-ip-replace-vxlan-or.html"><em>Could MPLS-over-IP replace VXLAN?</em></a><em> </em>article: </p>
<blockquote class="cite">As far as I understand, VXLAN, NVGRE and any tunneling protocol that use global ID in the data plane cannot support PVLAN functionality.</blockquote>
<p>He’s absolutely right, but you shouldn’t try to shoehorn VXLAN into existing deployment models. To understand why that doesn’t make sense, we have to focus on the typical cloud application architectures.<!--more--></p>
<p class="info">To be more precise, <em>any tunneling protocol that uses global ID in the data plane </em><a href="https://blog.ipspace.net/2011/12/vxlan-ip-multicast-openflow-and-control.html"><strong><em>and uses flooding to compensate for lack of control plane</em></strong></a><em> cannot support PVLAN</em>. <a href="https://blog.ipspace.net/2012/02/nicira-uncloaked.html">Nicira’s NVP</a> has port isolation (which is equivalent to a simple PVLAN); they could do it because the NVP controller(s) <a href="https://blog.ipspace.net/2011/10/what-is-nicira-really-up-to.html">download all MAC-to-IP mappings and MAC forwarding entries into the hypervisor switches</a>.</p>
<h4>SMB LAMP stack</h4><p>Numerous service providers that were previously offering simple web hosting are now selling cloudwashed VM-based services (example: the hosting company I use for one of my private web sites is now offering <a href="http://myhosting.com/virtual-private-server/">Virtual Private Servers</a>). The deployment model is simple: you get a single Linux (or Windows) server with Internet connectivity (hopefully firewalled to stop the script kiddies), and you’d usually install the <a href="http://en.wikipedia.org/wiki/LAMP_(software_bundle)">LAMP stack</a> or <a href="http://en.wikipedia.org/wiki/List_of_AMP_packages">something similar</a> on that server (LAMP = Linux, Apache, MySQL, PHP/Perl/Python). Sometimes the service provider offers hosted database service promising redundancy and backup.</p>
<div class="separator" style="clear: both; text-align: center;"><a href="/2012/08/s1600-LAMP_stack.png" imageanchor="1" style="margin-left:1em; margin-right:1em"><img border="0" height="345" src="/2012/08/s400-LAMP_stack.png" width="400"/></a><br/>Typical LAMP stack</div>
<p>In this environment, each tenant gets a single VM that has Internet connectivity and (optionally) access to some central services. VMs are not supposed to communicate with each other (even though you might buy more than one). </p>
<p>PVLAN is the perfect infrastructure solution for this environment – deploy a PVLAN in each compute pod (whatever that might be – usually a few racks), and use IP routing between pods. You can still use vMotion and HA/DRS within a pod, so you can move the customer VMs when you want to perform maintenance on individual pod components. </p>
<p>Evacuating a whole pod is bit more complex, but then (hopefully) you won’t be doing that every other day. If you really want to have this capability (because restarting customer VMs every now and then is not an option), develop a migration process where you temporarily provision a PVLAN between two pods, move the VMs and shut down the temporary inter-pod L2 connection, thus minimizing the risk of having a large-scale VLAN across multiple pods.</p>
<p><strong>Summary:</strong> you don’t need VXLAN if you’re selling individual VMs. PVLANs work just fine.</p>
<h4>Scale-out application architecture</h4><p>Modern scale-out application architectures are way more complex than a simple non-redundant LAMP stack. You’d have numerous web servers sitting behind a load balancer, you might be using web caches (example: Varnish) or offload servers (example: FastCGI), message queues, batch worker processes, cache daemons, and a bunch of database servers. As <a href="https://twitter.com/DEVOPS_BORAT/status/222837225921060864">@devops_borat wrote</a>:</p>
<p><img src="/2012/08/s400-HelloWorld_cloud.png" style="border: none"/></p>
<p>The servers you’d use in a scale-out application usually belong to different security zones, so you’d want to use firewalls between them. You might also need load balancing between tiers (some programmers don’t grasp the importance of having redundant database connections ... or the stupidity of having hard-coded database connection information), and the servers within a tier might have to communicate with each other (example: database servers or web caches and web servers).</p>
<p>In short – you need multiple isolated virtual network segments with firewalls and load balancers sitting between the segments and between the web server(s) and the outside world.</p>
<div class="separator" style="clear: both; text-align: center;"><a href="/2012/08/s1600-Scale_Out.png" imageanchor="1" style="margin-left:1em; margin-right:1em"><img border="0" height="116" src="/2012/08/s400-Scale_Out.png" width="400"/></a><br/>Simplified scale-out application architecture</div>
<p><a href="https://blog.ipspace.net/2011/09/vxlan-otv-and-lisp.html">VXLAN</a>, <a href="https://blog.ipspace.net/2011/09/nvgre-because-one-standard-just-wouldnt.html">NVGRE</a> or <a href="https://blog.ipspace.net/2012/02/nicira-uncloaked.html">NVP</a>, combined with virtual appliances, are an ideal solution for this type of application architectures. Trying to implement these architectures with PVLANs would result in a total spaghetti mess of isolated and community VLANs with multiple secondary VLANs per tenant.</p>
<h4>Summary</h4><p>MAC-over-IP virtual networking solutions are not a panacea. They cannot replace some of the traditional isolation constructs (PVLAN), but then they were not designed to do that. Their primary use case is an Amazon VPC-like environment with numerous isolated virtual networks <em>per tenant</em>.</p>
<h4>More information</h4><p>If you’re new to virtualized networking and would like to understand what this is all about, start with the <a href="http://www.ipspace.net/Introduction_to_Virtualized_Networking"><em>Introduction to virtualized networking</em></a> webinar. Various virtual networking technologies are described in <a href="http://www.ipspace.net/Cloud_Computing_Networking:_Under_the_Hood"><em>Cloud Computing Networking</em></a> webinar (which now includes a <a href="http://www.ipspace.net/Cloud_Computing_Networking:_Will_It_Scale%3F">1,5-hour long section on IaaS scalability</a>). You can buy individual recordings or get access to both webinars (and <a href="http://demo.ipspace.net/bin/bom/overview">numerous others</a>) with the <a href="http://www.ipspace.net/Subscription">yearly subscription</a>.</p>
<p>Finally, if you’d like me to review of your data center/cloud network design or discuss various technology options, <a href="http://www.ipspace.net/ExpertExpress">ExpertExpress</a> just might be the best option.</p>

